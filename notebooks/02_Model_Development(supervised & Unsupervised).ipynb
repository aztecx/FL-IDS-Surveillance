{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967f1c04-b078-4545-b75e-b20bd82d4a1a",
   "metadata": {},
   "source": [
    "# Notebook 02: Model Development (Supervised & Unsupervised)\n",
    "\n",
    "**Scope.** Build, tune, and evaluate supervised and unsupervised baselines for the FL-IDS (IIoT surveillance). Results here feed later federated experiments and the thesis comparison tables. This notebook reads the processed datasets created earlier and saves reproducible artifacts (metrics, models). It does not upload any data to the repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96bb3a8-6cff-4e6d-b37c-a35d1144a7b5",
   "metadata": {},
   "source": [
    "## Objectives and Structure\n",
    "\n",
    "**Objectives**\n",
    "- Train and evaluate supervised baselines (Logistic Regression, SGD Classifier, Random Forest).\n",
    "- Train and evaluate unsupervised baselines (Isolation Forest, Autoencoder).\n",
    "- Record accuracy, precision, recall, F1, FP/FN (rates and counts), model sizes, and timing.\n",
    "- Save artifacts for later use (metrics CSVs, model binaries, thresholds).\n",
    "\n",
    "**Structure**\n",
    "1) Supervised model development (with and without SMOTE)  \n",
    "2) Unsupervised model development (Isolation Forest tuning, Autoencoder + threshold tuning)  \n",
    "3) Final summary and export of a combined comparison table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f0ee5-26ee-47a9-b2a2-0bb598fb099e",
   "metadata": {},
   "source": [
    "## Reproducibility and Output Folders\n",
    "\n",
    "- All experiments use a fixed `SEED` for `random`, `numpy`, and model initializers when supported.\n",
    "- Output folders (created automatically) keep models and metrics separate for clarity:\n",
    "  - `results/models/supervised/{no_smote|with_smote}/`\n",
    "  - `results/models/unsupervised/`\n",
    "  - `results/*.csv` (experiment metrics and summaries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57f82f-501b-496a-9687-df6422805798",
   "metadata": {},
   "source": [
    "## 1. Supervised Model Development & Evaluation\n",
    "\n",
    "We evaluate three classifiers on two data variants:\n",
    "- **No-SMOTE**: original 80/20 stratified split  \n",
    "- **With-SMOTE**: same split, then SMOTE applied **only on the training set**\n",
    "\n",
    "Features are standardised (`StandardScaler`) per variant to avoid leakage between sets.\n",
    "Metrics are computed on the untouched test set. Models are saved for size measurement and reuse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f74d81-5c97-4c31-b924-623eaab6b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported, Random Seed set, all good\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries and Setting Global Random Seed in order to have the work reproducable\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os \n",
    "import joblib\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,classification_report)\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Setting the random seed for reproducability purposes\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "#Define the model output Directory\n",
    "os.makedirs('results/models/baselines/supervised', exist_ok = True)\n",
    "print(\"Libraries imported, Random Seed set, all good\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8770cd0d-41b3-4263-9ad2-0e481844a22d",
   "metadata": {},
   "source": [
    "### 1.1 Data Loading & Preprocessing (No-SMOTE and With-SMOTE)\n",
    "\n",
    "- Read `no_smote/train.csv` and `test.csv`, then standardise features with a scaler **fit on the training data only**.  \n",
    "- Read `with_smote/train.csv` and `test.csv`, then standardise features again (separate scaler).  \n",
    "- Target column is `Attack_label`. Non-numeric artifacts from earlier steps have already been removed or encoded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d1a714-1ce7-4ff7-b31b-756fece09066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No SMote - Train: (1775067, 42), and for Testing: (443767, 42)\n"
     ]
    }
   ],
   "source": [
    "#Loadind the Preprocessed Data (for No SMOTE)\n",
    "no_smote_path = r\"D:\\August-Thesis\\FL-IDS-Surveillance\\data\\processed\\surv_supervised\\80_20\\no_smote\"\n",
    "train_no_smote = pd.read_csv(f\"{no_smote_path}\\\\train.csv\", low_memory= False)\n",
    "test_no_smote = pd.read_csv(f\"{no_smote_path}\\\\test.csv\", low_memory = False)\n",
    "\n",
    "X_train_ns = train_no_smote.drop(columns = ['Attack_label'])\n",
    "y_train_ns = train_no_smote['Attack_label']\n",
    "\n",
    "X_test_ns = test_no_smote.drop(columns = ['Attack_label'])\n",
    "y_test_ns = test_no_smote['Attack_label']\n",
    "\n",
    "#Checking\n",
    "print(f\"No SMote - Train: {X_train_ns.shape}, and for Testing: {X_test_ns.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4146608-2862-4fec-9476-f2efdf47efb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With SMOTE- Train: (2585028, 42), Test: (443767, 42)\n"
     ]
    }
   ],
   "source": [
    "#Loading the Preprocessed Data ( for SMOTE version)\n",
    "with_smote_path = r\"D:\\August-Thesis\\FL-IDS-Surveillance\\data\\processed\\surv_supervised\\80_20\\with_smote\"\n",
    "train_with_smote = pd.read_csv(f\"{with_smote_path}\\\\train.csv\", low_memory = False)\n",
    "test_with_smote = pd.read_csv(f\"{with_smote_path}\\\\test.csv\", low_memory = False)\n",
    "\n",
    "X_train_ws = train_with_smote.drop(columns=['Attack_label'])\n",
    "y_train_ws = train_with_smote[\"Attack_label\"]\n",
    "\n",
    "X_test_ws = test_with_smote.drop(columns=[\"Attack_label\"])\n",
    "y_test_ws = test_with_smote[\"Attack_label\"]\n",
    "\n",
    "#Checking\n",
    "print(f\"With SMOTE- Train: {X_train_ws.shape}, Test: {X_test_ws.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43a6267-efaf-4afa-8886-5c1e7f355b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Scaling : Applied successfully\n"
     ]
    }
   ],
   "source": [
    "#Using the StandardScaler for both datasets\n",
    "scaler_ns = StandardScaler()\n",
    "X_train_ns_scaled = scaler_ns.fit_transform(X_train_ns)\n",
    "X_test_ns_scaled = scaler_ns.transform(X_test_ns)\n",
    "\n",
    "scaler_ws = StandardScaler()\n",
    "X_train_ws_scaled = scaler_ws.fit_transform(X_train_ws)\n",
    "X_test_ws_scaled = scaler_ws.transform(X_test_ws)\n",
    "\n",
    "print('Feature Scaling : Applied successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981a25d4-b09f-4642-8abe-9551985d028e",
   "metadata": {},
   "source": [
    "### 1.2 Models and Training Setup\n",
    "\n",
    "We train the following baselines with sensible defaults:\n",
    "- **Logistic Regression** (`max_iter=1000`)\n",
    "- **SGD Classifier** (linear baseline)\n",
    "- **Random Forest** (parallel, `n_jobs=-1`)\n",
    "\n",
    "For each model and data variant:\n",
    "- Fit on the training split, predict on the test split.\n",
    "- Record metrics, FP/FN counts, FP/FN rates, model size (MB), train time (s), and inference time (ms/sample).\n",
    "- Save the fitted model under `results/models/supervised/{no_smote|with_smote}/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8dc91f0-2ccd-4661-842d-98fde7a8a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, model_name, X_train, y_train, X_test, y_test, save_dir):\n",
    "    results = {}\n",
    "\n",
    "    #Training Phase\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_train\n",
    "\n",
    "    #Predicting Phase\n",
    "    start_test = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_time = time.time() - start_test\n",
    "    inference_time_per_sample = test_time / len(X_test)\n",
    "\n",
    "    #Defining the metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    fp_rate = 100 * fp / (fp + tn)\n",
    "    fn_rate = 100 * fn / (fn + tp)\n",
    "\n",
    "    #Saving Model for measuring the size and possibly using later on ...etc\n",
    "    os.makedirs(save_dir, exist_ok = True)\n",
    "    save_path = os.path.join(save_dir, f\"{model_name}.pkl\")\n",
    "    joblib.dump(model, save_path)\n",
    "    model_size_mb = os.path.getsize(save_path) / (1024 * 1024)\n",
    "\n",
    "    #Collecting results for the thesis\n",
    "    results.update({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1 Score': f1,\n",
    "        'False Positives': fp,\n",
    "        'False Negatives': fn,\n",
    "        'FP Rate (%)': fp_rate,\n",
    "        'FN Rate (%)': fn_rate,\n",
    "        'Model Size (MB)': model_size_mb,\n",
    "        'Train Time (s)': train_time,\n",
    "        'Inference Time (ms/sample)': inference_time_per_sample * 1000\n",
    "     })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aea0eb1-0d3c-45ba-b788-50707e721ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_expirenments (models_dict, X_train, y_train, X_test, y_test, save_dir):\n",
    "    all_resluts = []\n",
    "    for name, model in models_dict.items():\n",
    "        print(f\"Training {name} in progress . . .\")\n",
    "        result = train_and_evaluate(model, name, X_train, y_train, X_test, y_test, save_dir)\n",
    "        all_resluts.append(result)\n",
    "    return pd.DataFrame(all_resluts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2dd78b5-e640-42d8-adaf-67309f14d412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic_Regressin in progress . . .\n",
      "Training SGD Classifier in progress . . .\n",
      "Training Random_Forest in progress . . .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d11d5_row2_col1, #T_d11d5_row2_col2, #T_d11d5_row2_col3, #T_d11d5_row2_col4 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d11d5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d11d5_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_d11d5_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_d11d5_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_d11d5_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_d11d5_level0_col4\" class=\"col_heading level0 col4\" >F1 Score</th>\n",
       "      <th id=\"T_d11d5_level0_col5\" class=\"col_heading level0 col5\" >False Positives</th>\n",
       "      <th id=\"T_d11d5_level0_col6\" class=\"col_heading level0 col6\" >False Negatives</th>\n",
       "      <th id=\"T_d11d5_level0_col7\" class=\"col_heading level0 col7\" >FP Rate (%)</th>\n",
       "      <th id=\"T_d11d5_level0_col8\" class=\"col_heading level0 col8\" >FN Rate (%)</th>\n",
       "      <th id=\"T_d11d5_level0_col9\" class=\"col_heading level0 col9\" >Model Size (MB)</th>\n",
       "      <th id=\"T_d11d5_level0_col10\" class=\"col_heading level0 col10\" >Train Time (s)</th>\n",
       "      <th id=\"T_d11d5_level0_col11\" class=\"col_heading level0 col11\" >Inference Time (ms/sample)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d11d5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d11d5_row0_col0\" class=\"data row0 col0\" >Logistic_Regressin</td>\n",
       "      <td id=\"T_d11d5_row0_col1\" class=\"data row0 col1\" >0.982667</td>\n",
       "      <td id=\"T_d11d5_row0_col2\" class=\"data row0 col2\" >0.996414</td>\n",
       "      <td id=\"T_d11d5_row0_col3\" class=\"data row0 col3\" >0.939621</td>\n",
       "      <td id=\"T_d11d5_row0_col4\" class=\"data row0 col4\" >0.967184</td>\n",
       "      <td id=\"T_d11d5_row0_col5\" class=\"data row0 col5\" >408</td>\n",
       "      <td id=\"T_d11d5_row0_col6\" class=\"data row0 col6\" >7284</td>\n",
       "      <td id=\"T_d11d5_row0_col7\" class=\"data row0 col7\" >0.126265</td>\n",
       "      <td id=\"T_d11d5_row0_col8\" class=\"data row0 col8\" >6.037899</td>\n",
       "      <td id=\"T_d11d5_row0_col9\" class=\"data row0 col9\" >0.001143</td>\n",
       "      <td id=\"T_d11d5_row0_col10\" class=\"data row0 col10\" >9.686551</td>\n",
       "      <td id=\"T_d11d5_row0_col11\" class=\"data row0 col11\" >0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d11d5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d11d5_row1_col0\" class=\"data row1 col0\" >SGD Classifier</td>\n",
       "      <td id=\"T_d11d5_row1_col1\" class=\"data row1 col1\" >0.975415</td>\n",
       "      <td id=\"T_d11d5_row1_col2\" class=\"data row1 col2\" >0.985634</td>\n",
       "      <td id=\"T_d11d5_row1_col3\" class=\"data row1 col3\" >0.923018</td>\n",
       "      <td id=\"T_d11d5_row1_col4\" class=\"data row1 col4\" >0.953299</td>\n",
       "      <td id=\"T_d11d5_row1_col5\" class=\"data row1 col5\" >1623</td>\n",
       "      <td id=\"T_d11d5_row1_col6\" class=\"data row1 col6\" >9287</td>\n",
       "      <td id=\"T_d11d5_row1_col7\" class=\"data row1 col7\" >0.502276</td>\n",
       "      <td id=\"T_d11d5_row1_col8\" class=\"data row1 col8\" >7.698238</td>\n",
       "      <td id=\"T_d11d5_row1_col9\" class=\"data row1 col9\" >0.001386</td>\n",
       "      <td id=\"T_d11d5_row1_col10\" class=\"data row1 col10\" >5.191004</td>\n",
       "      <td id=\"T_d11d5_row1_col11\" class=\"data row1 col11\" >0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d11d5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d11d5_row2_col0\" class=\"data row2 col0\" >Random_Forest</td>\n",
       "      <td id=\"T_d11d5_row2_col1\" class=\"data row2 col1\" >0.997821</td>\n",
       "      <td id=\"T_d11d5_row2_col2\" class=\"data row2 col2\" >0.999449</td>\n",
       "      <td id=\"T_d11d5_row2_col3\" class=\"data row2 col3\" >0.992531</td>\n",
       "      <td id=\"T_d11d5_row2_col4\" class=\"data row2 col4\" >0.995978</td>\n",
       "      <td id=\"T_d11d5_row2_col5\" class=\"data row2 col5\" >66</td>\n",
       "      <td id=\"T_d11d5_row2_col6\" class=\"data row2 col6\" >901</td>\n",
       "      <td id=\"T_d11d5_row2_col7\" class=\"data row2 col7\" >0.020425</td>\n",
       "      <td id=\"T_d11d5_row2_col8\" class=\"data row2 col8\" >0.746863</td>\n",
       "      <td id=\"T_d11d5_row2_col9\" class=\"data row2 col9\" >1.474755</td>\n",
       "      <td id=\"T_d11d5_row2_col10\" class=\"data row2 col10\" >50.454203</td>\n",
       "      <td id=\"T_d11d5_row2_col11\" class=\"data row2 col11\" >0.001066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cb273f7b30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_to_train = {\n",
    "    'Logistic_Regressin' : LogisticRegression(max_iter = 1000, random_state = SEED),\n",
    "    'SGD Classifier' : SGDClassifier(random_state = SEED),\n",
    "    'Random_Forest' : RandomForestClassifier(n_jobs = -1, random_state = SEED)\n",
    "}\n",
    "\n",
    "results_no_smote = run_expirenments(\n",
    "    models_to_train,\n",
    "    X_train_ns_scaled, y_train_ns,\n",
    "    X_test_ns_scaled, y_test_ns,\n",
    "    \"results/models/supervised/no_smote\"\n",
    ")\n",
    "\n",
    "results_no_smote.to_csv(\"results/supervised_results_no_smote.csv\", index = False)\n",
    "results_no_smote.style.highlight_max(subset=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"], color=\"lightgreen\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "718c9a62-d9e1-4025-860b-fbdc494ee745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic_Regression_SMOTE in progress . . .\n",
      "Training SGD Classifier_SMOTE in progress . . .\n",
      "Training Random_Forest_SMOTE in progress . . .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9e77c_row0_col9, #T_9e77c_row1_col10, #T_9e77c_row1_col11, #T_9e77c_row2_col7, #T_9e77c_row2_col8 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_9e77c_row2_col1, #T_9e77c_row2_col2, #T_9e77c_row2_col3, #T_9e77c_row2_col4 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9e77c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9e77c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_9e77c_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_9e77c_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_9e77c_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_9e77c_level0_col4\" class=\"col_heading level0 col4\" >F1 Score</th>\n",
       "      <th id=\"T_9e77c_level0_col5\" class=\"col_heading level0 col5\" >False Positives</th>\n",
       "      <th id=\"T_9e77c_level0_col6\" class=\"col_heading level0 col6\" >False Negatives</th>\n",
       "      <th id=\"T_9e77c_level0_col7\" class=\"col_heading level0 col7\" >FP Rate (%)</th>\n",
       "      <th id=\"T_9e77c_level0_col8\" class=\"col_heading level0 col8\" >FN Rate (%)</th>\n",
       "      <th id=\"T_9e77c_level0_col9\" class=\"col_heading level0 col9\" >Model Size (MB)</th>\n",
       "      <th id=\"T_9e77c_level0_col10\" class=\"col_heading level0 col10\" >Train Time (s)</th>\n",
       "      <th id=\"T_9e77c_level0_col11\" class=\"col_heading level0 col11\" >Inference Time (ms/sample)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9e77c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9e77c_row0_col0\" class=\"data row0 col0\" >Logistic_Regression_SMOTE</td>\n",
       "      <td id=\"T_9e77c_row0_col1\" class=\"data row0 col1\" >0.970248</td>\n",
       "      <td id=\"T_9e77c_row0_col2\" class=\"data row0 col2\" >0.936100</td>\n",
       "      <td id=\"T_9e77c_row0_col3\" class=\"data row0 col3\" >0.955802</td>\n",
       "      <td id=\"T_9e77c_row0_col4\" class=\"data row0 col4\" >0.945848</td>\n",
       "      <td id=\"T_9e77c_row0_col5\" class=\"data row0 col5\" >7871</td>\n",
       "      <td id=\"T_9e77c_row0_col6\" class=\"data row0 col6\" >5332</td>\n",
       "      <td id=\"T_9e77c_row0_col7\" class=\"data row0 col7\" >2.435869</td>\n",
       "      <td id=\"T_9e77c_row0_col8\" class=\"data row0 col8\" >4.419835</td>\n",
       "      <td id=\"T_9e77c_row0_col9\" class=\"data row0 col9\" >0.001143</td>\n",
       "      <td id=\"T_9e77c_row0_col10\" class=\"data row0 col10\" >10.738022</td>\n",
       "      <td id=\"T_9e77c_row0_col11\" class=\"data row0 col11\" >0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e77c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9e77c_row1_col0\" class=\"data row1 col0\" >SGD Classifier_SMOTE</td>\n",
       "      <td id=\"T_9e77c_row1_col1\" class=\"data row1 col1\" >0.966852</td>\n",
       "      <td id=\"T_9e77c_row1_col2\" class=\"data row1 col2\" >0.934644</td>\n",
       "      <td id=\"T_9e77c_row1_col3\" class=\"data row1 col3\" >0.944081</td>\n",
       "      <td id=\"T_9e77c_row1_col4\" class=\"data row1 col4\" >0.939339</td>\n",
       "      <td id=\"T_9e77c_row1_col5\" class=\"data row1 col5\" >7964</td>\n",
       "      <td id=\"T_9e77c_row1_col6\" class=\"data row1 col6\" >6746</td>\n",
       "      <td id=\"T_9e77c_row1_col7\" class=\"data row1 col7\" >2.464650</td>\n",
       "      <td id=\"T_9e77c_row1_col8\" class=\"data row1 col8\" >5.591936</td>\n",
       "      <td id=\"T_9e77c_row1_col9\" class=\"data row1 col9\" >0.001386</td>\n",
       "      <td id=\"T_9e77c_row1_col10\" class=\"data row1 col10\" >5.864219</td>\n",
       "      <td id=\"T_9e77c_row1_col11\" class=\"data row1 col11\" >0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e77c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9e77c_row2_col0\" class=\"data row2 col0\" >Random_Forest_SMOTE</td>\n",
       "      <td id=\"T_9e77c_row2_col1\" class=\"data row2 col1\" >0.995906</td>\n",
       "      <td id=\"T_9e77c_row2_col2\" class=\"data row2 col2\" >0.985162</td>\n",
       "      <td id=\"T_9e77c_row2_col3\" class=\"data row2 col3\" >1.000000</td>\n",
       "      <td id=\"T_9e77c_row2_col4\" class=\"data row2 col4\" >0.992525</td>\n",
       "      <td id=\"T_9e77c_row2_col5\" class=\"data row2 col5\" >1817</td>\n",
       "      <td id=\"T_9e77c_row2_col6\" class=\"data row2 col6\" >0</td>\n",
       "      <td id=\"T_9e77c_row2_col7\" class=\"data row2 col7\" >0.562314</td>\n",
       "      <td id=\"T_9e77c_row2_col8\" class=\"data row2 col8\" >0.000000</td>\n",
       "      <td id=\"T_9e77c_row2_col9\" class=\"data row2 col9\" >2.156518</td>\n",
       "      <td id=\"T_9e77c_row2_col10\" class=\"data row2 col10\" >69.797611</td>\n",
       "      <td id=\"T_9e77c_row2_col11\" class=\"data row2 col11\" >0.001177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cb274053a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With SMOTE Applied now\n",
    "models_to_train_smote = {\n",
    "    'Logistic_Regression_SMOTE' : LogisticRegression(max_iter = 1000, random_state = SEED),\n",
    "    'SGD Classifier_SMOTE' : SGDClassifier(random_state = SEED),\n",
    "    'Random_Forest_SMOTE' : RandomForestClassifier(n_jobs = -1, random_state = SEED)\n",
    "}\n",
    "\n",
    "results_ws_smote = run_expirenments(\n",
    "    models_to_train_smote,\n",
    "    X_train_ws_scaled, y_train_ws,\n",
    "    X_test_ws_scaled, y_test_ws,\n",
    "    \"results/models/supervised/with_smote\"\n",
    ")\n",
    "\n",
    "results_ws_smote.to_csv(\"results/supervised_results_with_smote.csv\", index = False)\n",
    "results_ws_smote.style.highlight_max(subset=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"], color=\"lightgreen\", axis=0).highlight_min(subset=[\"FP Rate (%)\",\n",
    "                                                                                                                                               \"FN Rate (%)\",\n",
    "                                                                                                                                               \"Train Time (s)\",\n",
    "                                                                                                                                               \"Model Size (MB)\",\n",
    "                                                                                                                                               \"Inference Time (ms/sample)\"],\n",
    "                                                                                                                                       color=\"lightblue\",\n",
    "                                                                                                                                       axis=0\n",
    "                                                                                                                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1edb7d1-eb94-43cc-a119-7124d7ce5bd5",
   "metadata": {},
   "source": [
    "## 2. Unsupervised Baselines\n",
    "\n",
    "This section builds unsupervised anomaly detectors that learn from **normal-only** data and are evaluated on a **mixed** test set.\n",
    "\n",
    "- **Isolation Forest (IF):** tree-based outlier detector with a small hyperparameter sweep.\n",
    "- **Autoencoder (AE):** reconstructs normal traffic; anomalies have higher reconstruction error.\n",
    "- **Threshold tuning:** converts AE reconstruction errors into binary predictions.\n",
    "- **Outputs:** metrics CSVs, trained models, scalers, and the chosen AE threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142570d9-9697-405d-88e3-7802857d4f90",
   "metadata": {},
   "source": [
    "### 2.1 Data for Unsupervised Models\n",
    "\n",
    "- **Train (normal-only):** `train_normal_only.csv`\n",
    "- **Test (mixed):** `test_mixed.csv` (contains both normal and attack)\n",
    "- The label column (`Attack_label`) is used **only** for evaluation on the mixed test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e598a7cc-03db-474b-943c-437aee7b489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Normal Only): (1615643, 41), Test (Mixed): (2218834, 41)\n"
     ]
    }
   ],
   "source": [
    "#Loading the Data for Unsupervised Models\n",
    "# Normal-only training data\n",
    "train_unsup = pd.read_csv(r\"D:\\August-Thesis\\FL-IDS-Surveillance\\data\\processed\\surv_unsupervised\\train_normal_only.csv\", low_memory = False)\n",
    "\n",
    "X_train_unsup = train_unsup.drop(columns=[\"Attack_label\", \"http.request.method\"])\n",
    "y_train_unsup = train_unsup[\"Attack_label\"]\n",
    "\n",
    "#Mixed test data\n",
    "test_unsup = pd.read_csv(r\"D:\\August-Thesis\\FL-IDS-Surveillance\\data\\processed\\surv_unsupervised\\test_mixed.csv\", low_memory = False)\n",
    "X_test_unsup = test_unsup.drop(columns=[\"Attack_label\", \"http.request.method\"])\n",
    "y_test_unsup = test_unsup[\"Attack_label\"]\n",
    "\n",
    "print(f\"Train (Normal Only): {X_train_unsup.shape}, Test (Mixed): {X_test_unsup.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46e54865-35a2-4aef-8f47-c0cc420d7fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling is complete for the Isolation Forest and Autoencoder.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#Standard Scaler for the Isolation Forest\n",
    "scaler_iforest = StandardScaler()\n",
    "X_train_if_scaled = scaler_iforest.fit_transform(X_train_unsup)\n",
    "X_test_if_scaled = scaler_iforest.transform(X_test_unsup)\n",
    "\n",
    "\n",
    "#MinMax Scaler for the Autoencoder\n",
    "scaler_autoencoder = MinMaxScaler()\n",
    "X_train_ae_scaled = scaler_autoencoder.fit_transform(X_train_unsup)\n",
    "X_test_ae_scaled = scaler_autoencoder.transform(X_test_unsup)\n",
    "\n",
    "\n",
    "print(\"Scaling is complete for the Isolation Forest and Autoencoder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b56624-e2d8-4d09-a2d1-d0c0c801f3c7",
   "metadata": {},
   "source": [
    "### 2.2 Isolation Forest — Tuning and Evaluation\n",
    "\n",
    "**Search space (lightweight):**\n",
    "- `contamination ∈ {0.01 … 0.10}`\n",
    "- `max_samples ∈ {256, 1000, 10000, 0.05, 0.1, 'auto', len(train)}`\n",
    "\n",
    "**Protocol**\n",
    "1. Fit IF on **normal-only** train.\n",
    "2. Score the **mixed** test; thresholding is inherent via `decision_function` or `predict`.\n",
    "3. Record: Accuracy, Precision, Recall, F1, FP/FN rates, model size (MB), fit time (s), inference time (ms/sample).\n",
    "4. Save the **best** IF model and full results table.\n",
    "\n",
    "**Artifacts**\n",
    "- Models: `results/models/unsupervised/isoforest/*.pkl`\n",
    "- Metrics: `results/unsupervised_isoforest_results.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "263a0d7b-5e65-41ac-9a86-a09523ee84a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>FP Rate (%)</th>\n",
       "      <th>FN Rate (%)</th>\n",
       "      <th>Train Time (s)</th>\n",
       "      <th>Inference Time (ms/sample)</th>\n",
       "      <th>Contamination</th>\n",
       "      <th>Max Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905499</td>\n",
       "      <td>0.876375</td>\n",
       "      <td>0.759517</td>\n",
       "      <td>0.813773</td>\n",
       "      <td>64626</td>\n",
       "      <td>145057</td>\n",
       "      <td>4.000017</td>\n",
       "      <td>24.04827</td>\n",
       "      <td>111.180085</td>\n",
       "      <td>0.012598</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1615643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1 Score  ...  Train Time (s)  Inference Time (ms/sample)  Contamination  Max Samples\n",
       "0  0.905499   0.876375  0.759517  0.813773  ...      111.180085                    0.012598           0.04      1615643\n",
       "\n",
       "[1 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Isolation Forest: Training + Tuning & Evaluation\n",
    "contamination_values = np.linspace(0.01, 0.10, 10)\n",
    "max_samples_values = [256, 1000, 10000, 0.05, 0.1, 'auto', len(X_train_if_scaled)]\n",
    "\n",
    "tuned_results = []\n",
    "best_f1 = 0\n",
    "best_model = None\n",
    "best_params = {}\n",
    "\n",
    "for contamination in contamination_values:\n",
    "    for max_samples in max_samples_values:\n",
    "        try:\n",
    "            # The Model Training\n",
    "            model = IsolationForest(\n",
    "                n_estimators=100,\n",
    "                contamination=contamination,\n",
    "                max_samples=max_samples,\n",
    "                random_state=SEED\n",
    "            )\n",
    "            start_train = time.time()\n",
    "            model.fit(X_train_if_scaled)\n",
    "            train_time = time.time() - start_train\n",
    "\n",
    "            #The Prediction\n",
    "            start_test = time.time()\n",
    "            y_pred_raw = model.predict(X_test_if_scaled)\n",
    "            # Convert: 1 = normal → 0, -1 = anomaly → 1\n",
    "            y_pred = np.where(y_pred_raw == 1, 0, 1)\n",
    "            test_time = time.time() - start_test\n",
    "            inference_time_per_sample = test_time / len(X_test_if_scaled)\n",
    "\n",
    "            # Metrics for Evaluation\n",
    "            acc = accuracy_score(y_test_unsup, y_pred)\n",
    "            prec = precision_score(y_test_unsup, y_pred, zero_division=0)\n",
    "            rec = recall_score(y_test_unsup, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_test_unsup, y_pred, zero_division=0)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_unsup, y_pred).ravel()\n",
    "            fp_rate = 100 * fp / (fp + tn)\n",
    "            fn_rate = 100 * fn / (fn + tp)\n",
    "\n",
    "            # Saving the Best Model\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_model = model\n",
    "                best_params = {\n",
    "                    'contamination': contamination,\n",
    "                    'max_samples': max_samples,\n",
    "                    'metrics': {\n",
    "                        'Accuracy': acc,\n",
    "                        'Precision': prec,\n",
    "                        'Recall': rec,\n",
    "                        'F1 Score': f1,\n",
    "                        'False Positives': fp,\n",
    "                        'False Negatives': fn,\n",
    "                        'FP Rate (%)': fp_rate,\n",
    "                        'FN Rate (%)': fn_rate,\n",
    "                        'Train Time (s)': train_time,\n",
    "                        'Inference Time (ms/sample)': inference_time_per_sample * 1000\n",
    "                    }\n",
    "                }\n",
    "\n",
    "            # Logging this run\n",
    "            tuned_results.append({\n",
    "                'Contamination': contamination,\n",
    "                'Max Samples': max_samples,\n",
    "                'Accuracy': acc,\n",
    "                'Precision': prec,\n",
    "                'Recall': rec,\n",
    "                'F1 Score': f1,\n",
    "                'False Positives': fp,\n",
    "                'False Negatives': fn,\n",
    "                'FP Rate (%)': fp_rate,\n",
    "                'FN Rate (%)': fn_rate,\n",
    "                'Train Time (s)': train_time,\n",
    "                'Inference Time (ms/sample)': inference_time_per_sample * 1000\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipped params contamination={contamination}, max_samples={max_samples} due to error: {e}\")\n",
    "\n",
    "# Converting the results to DataFrame\n",
    "df_iforest_tuning = pd.DataFrame(tuned_results)\n",
    "df_iforest_tuning.to_csv(\"results/unsupervised_iforest_tuning_results.csv\", index=False)\n",
    "\n",
    "# Saving the Best Model\n",
    "os.makedirs(\"results/models/unsupervised\", exist_ok=True)\n",
    "joblib.dump(best_model, \"results/models/unsupervised/isolation_forest_best.pkl\")\n",
    "\n",
    "# Reporting the Best Model Metrics\n",
    "pd.DataFrame([{\n",
    "    **best_params['metrics'],\n",
    "    'Contamination': best_params['contamination'],\n",
    "    'Max Samples': best_params['max_samples']\n",
    "}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8b85510-c555-441d-a05a-9237ac1ecd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>FP Rate (%)</th>\n",
       "      <th>FN Rate (%)</th>\n",
       "      <th>Model Size (MB)</th>\n",
       "      <th>Train Time (s)</th>\n",
       "      <th>Inference Time (ms/sample)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>2.004250e+06</td>\n",
       "      <td>0.778149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.183924</td>\n",
       "      <td>0.310702</td>\n",
       "      <td>0</td>\n",
       "      <td>492250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.607650</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>154.514615</td>\n",
       "      <td>0.032508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned</th>\n",
       "      <td>1.186191e-03</td>\n",
       "      <td>0.908162</td>\n",
       "      <td>0.981317</td>\n",
       "      <td>0.675027</td>\n",
       "      <td>0.799852</td>\n",
       "      <td>7752</td>\n",
       "      <td>196021</td>\n",
       "      <td>0.479809</td>\n",
       "      <td>32.497335</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>154.514615</td>\n",
       "      <td>0.032508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Threshold  Accuracy  Precision  ...  Model Size (MB)  Train Time (s)  Inference Time (ms/sample)\n",
       "Version                                      ...                                                             \n",
       "Baseline  2.004250e+06  0.778149   1.000000  ...           0.0874      154.514615                    0.032508\n",
       "Tuned     1.186191e-03  0.908162   0.981317  ...           0.0874      154.514615                    0.032508\n",
       "\n",
       "[2 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Autoencoder: Baseline + Threshold Tuning + Evaluation + Model Saving\n",
    "def build_autoencoder(input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(32, activation='relu')(input_layer)\n",
    "    encoded = Dense(16, activation='relu')(encoded)\n",
    "    encoded = Dense(8, activation='relu')(encoded)\n",
    "    decoded = Dense(16, activation='relu')(encoded)\n",
    "    decoded = Dense(32, activation='relu')(decoded)\n",
    "    output_layer = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "# Build and Train the Baseline Autoencoder\n",
    "input_dim = X_train_ae_scaled.shape[1]\n",
    "autoencoder = build_autoencoder(input_dim)\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "start_train = time.time()\n",
    "history = autoencoder.fit(\n",
    "    X_train_ae_scaled, X_train_ae_scaled,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "train_time = time.time() - start_train\n",
    "\n",
    "# Reconstruct Test Set & Compute Errors\n",
    "start_test = time.time()\n",
    "X_test_reconstructed = autoencoder.predict(X_test_ae_scaled, verbose=0)\n",
    "reconstruction_errors = np.mean(\n",
    "    np.square(X_test_ae_scaled - X_test_reconstructed),\n",
    "    axis=1\n",
    ")\n",
    "test_time = time.time() - start_test\n",
    "inference_time_per_sample = test_time / len(X_test_ae_scaled)\n",
    "\n",
    "# Threshold Tuning\n",
    "baseline_threshold = np.percentile(reconstruction_errors, 95)\n",
    "y_pred_baseline = (reconstruction_errors > baseline_threshold).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_unsup, y_pred_baseline).ravel()\n",
    "fp_rate = 100 * fp / (fp + tn)\n",
    "fn_rate = 100 * fn / (fn + tp)\n",
    "\n",
    "# Save Model FIRST\n",
    "os.makedirs(\"results/models/unsupervised\", exist_ok=True)\n",
    "autoencoder.save(\"results/models/unsupervised/autoencoder_baseline.h5\")\n",
    "\n",
    "# Now check Model Size\n",
    "model_size_mb = round(\n",
    "    os.path.getsize(\"results/models/unsupervised/autoencoder_baseline.h5\") / (1024 * 1024),\n",
    "    4\n",
    ")\n",
    "\n",
    "# Collect Baseline Metrics AFTER saving\n",
    "baseline_metrics = {\n",
    "    'Threshold': baseline_threshold,\n",
    "    'Accuracy': accuracy_score(y_test_unsup, y_pred_baseline),\n",
    "    'Precision': precision_score(y_test_unsup, y_pred_baseline),\n",
    "    'Recall': recall_score(y_test_unsup, y_pred_baseline),\n",
    "    'F1 Score': f1_score(y_test_unsup, y_pred_baseline),\n",
    "    'False Positives': fp,\n",
    "    'False Negatives': fn,\n",
    "    'FP Rate (%)': fp_rate,\n",
    "    'FN Rate (%)': fn_rate,\n",
    "    'Model Size (MB)': model_size_mb,\n",
    "    'Train Time (s)': train_time,\n",
    "    'Inference Time (ms/sample)': inference_time_per_sample * 1000\n",
    "}\n",
    "\n",
    "# Threshold Sweep Tuning\n",
    "best_f1 = 0\n",
    "best_threshold = None\n",
    "best_metrics = {}\n",
    "\n",
    "for p in np.arange(80, 99.9, 0.1):\n",
    "    threshold = np.percentile(reconstruction_errors, p)\n",
    "    y_pred = (reconstruction_errors > threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_unsup, y_pred).ravel()\n",
    "    fp_rate = 100 * fp / (fp + tn)\n",
    "    fn_rate = 100 * fn / (fn + tp)\n",
    "    f1 = f1_score(y_test_unsup, y_pred)\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "        best_metrics = {\n",
    "            'Threshold': threshold,\n",
    "            'Accuracy': accuracy_score(y_test_unsup, y_pred),\n",
    "            'Precision': precision_score(y_test_unsup, y_pred),\n",
    "            'Recall': recall_score(y_test_unsup, y_pred),\n",
    "            'F1 Score': f1,\n",
    "            'False Positives': fp,\n",
    "            'False Negatives': fn,\n",
    "            'FP Rate (%)': fp_rate,\n",
    "            'FN Rate (%)': fn_rate,\n",
    "            'Model Size (MB)': model_size_mb,\n",
    "            'Train Time (s)': train_time,\n",
    "            'Inference Time (ms/sample)': inference_time_per_sample * 1000\n",
    "        }\n",
    "\n",
    "# Saving results\n",
    "pd.DataFrame([baseline_metrics]).to_csv(\n",
    "    \"results/unsupervised_autoencoder_baseline_results.csv\", index=False\n",
    ")\n",
    "pd.DataFrame([best_metrics]).to_csv(\n",
    "    \"results/unsupervised_autoencoder_tuned_results.csv\", index=False\n",
    ")\n",
    "\n",
    "# Compare the results\n",
    "pd.concat([\n",
    "    pd.DataFrame([baseline_metrics]).assign(Version=\"Baseline\"),\n",
    "    pd.DataFrame([best_metrics]).assign(Version=\"Tuned\")\n",
    "]).set_index(\"Version\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dd76ba3-f7aa-4be6-a8a9-f2c649b13887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#Checking results directory exists (in case it's missing)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Load  the previously generated CSVs with the results\n",
    "supervised_no_smote = pd.read_csv(os.path.join(\"results\", \"supervised_results_no_smote.csv\"))\n",
    "supervised_with_smote = pd.read_csv(os.path.join(\"results\", \"supervised_results_with_smote.csv\"))\n",
    "unsupervised_iforest = pd.read_csv(os.path.join(\"results\", \"unsupervised_iforest_tuning_results.csv\"))\n",
    "unsupervised_ae_baseline = pd.read_csv(os.path.join(\"results\", \"unsupervised_autoencoder_baseline_results.csv\"))\n",
    "unsupervised_ae_tuned = pd.read_csv(os.path.join(\"results\", \"unsupervised_autoencoder_tuned_results.csv\"))\n",
    "\n",
    "# Adding the category column in order to identify models\n",
    "supervised_no_smote[\"Category\"] = \"Supervised - No SMOTE\"\n",
    "supervised_with_smote[\"Category\"] = \"Supervised - With SMOTE\"\n",
    "unsupervised_iforest[\"Category\"] = \"Unsupervised - Isolation Forest Tuning\"\n",
    "unsupervised_ae_baseline[\"Category\"] = \"Unsupervised - Autoencoder Baseline\"\n",
    "unsupervised_ae_tuned[\"Category\"] = \"Unsupervised - Autoencoder Tuned\"\n",
    "\n",
    "# Align the columns for Isolation Forest\n",
    "unsupervised_iforest = unsupervised_iforest.rename(columns={\n",
    "    \"F1 Score\": \"F1 Score\",\n",
    "    \"Accuracy\": \"Accuracy\",\n",
    "    \"Precision\": \"Precision\",\n",
    "    \"Recall\": \"Recall\",\n",
    "    \"False Positives\": \"False Positives\",\n",
    "    \"False Negatives\": \"False Negatives\",\n",
    "    \"FP Rate (%)\": \"FP Rate (%)\",\n",
    "    \"FN Rate (%)\": \"FN Rate (%)\",\n",
    "    \"Train Time (s)\": \"Train Time (s)\",\n",
    "    \"Inference Time (ms/sample)\": \"Inference Time (ms/sample)\"\n",
    "}).assign(Model=\"IsolationForest (Tuned)\")\n",
    "\n",
    "# Add model column for autoencoder versions\n",
    "unsupervised_ae_baseline[\"Model\"] = \"Autoencoder (Baseline)\"\n",
    "unsupervised_ae_tuned[\"Model\"] = \"Autoencoder (Tuned)\"\n",
    "\n",
    "# Filter Isolation Forest to keep only the best tuned model (highest F1)\n",
    "best_iforest = unsupervised_iforest.sort_values(by=\"F1 Score\", ascending=False).head(1)\n",
    "\n",
    "# Combine all the datasets\n",
    "final_summary_df = pd.concat([\n",
    "    supervised_no_smote,\n",
    "    supervised_with_smote,\n",
    "    best_iforest,\n",
    "    unsupervised_ae_baseline,\n",
    "    unsupervised_ae_tuned\n",
    "], ignore_index=True)\n",
    "\n",
    "# Save the combined summary\n",
    "final_summary_path = os.path.join(\"results\", \"final_combined_model_results_summary.csv\")\n",
    "final_summary_df.to_csv(final_summary_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c6921f6-4cc4-4917-a539-3767222f511f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5d3c_row0_col7, #T_f5d3c_row1_col8, #T_f5d3c_row3_col7, #T_f5d3c_row4_col9, #T_f5d3c_row5_col6, #T_f5d3c_row7_col5 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_f5d3c_row2_col1, #T_f5d3c_row2_col4, #T_f5d3c_row5_col3, #T_f5d3c_row7_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5d3c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5d3c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_f5d3c_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_f5d3c_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_f5d3c_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_f5d3c_level0_col4\" class=\"col_heading level0 col4\" >F1 Score</th>\n",
       "      <th id=\"T_f5d3c_level0_col5\" class=\"col_heading level0 col5\" >FP Rate (%)</th>\n",
       "      <th id=\"T_f5d3c_level0_col6\" class=\"col_heading level0 col6\" >FN Rate (%)</th>\n",
       "      <th id=\"T_f5d3c_level0_col7\" class=\"col_heading level0 col7\" >Model Size (MB)</th>\n",
       "      <th id=\"T_f5d3c_level0_col8\" class=\"col_heading level0 col8\" >Train Time (s)</th>\n",
       "      <th id=\"T_f5d3c_level0_col9\" class=\"col_heading level0 col9\" >Inference Time (ms/sample)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5d3c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f5d3c_row0_col0\" class=\"data row0 col0\" >Logistic_Regressin</td>\n",
       "      <td id=\"T_f5d3c_row0_col1\" class=\"data row0 col1\" >0.982667</td>\n",
       "      <td id=\"T_f5d3c_row0_col2\" class=\"data row0 col2\" >0.996414</td>\n",
       "      <td id=\"T_f5d3c_row0_col3\" class=\"data row0 col3\" >0.939621</td>\n",
       "      <td id=\"T_f5d3c_row0_col4\" class=\"data row0 col4\" >0.967184</td>\n",
       "      <td id=\"T_f5d3c_row0_col5\" class=\"data row0 col5\" >0.126265</td>\n",
       "      <td id=\"T_f5d3c_row0_col6\" class=\"data row0 col6\" >6.037899</td>\n",
       "      <td id=\"T_f5d3c_row0_col7\" class=\"data row0 col7\" >0.001143</td>\n",
       "      <td id=\"T_f5d3c_row0_col8\" class=\"data row0 col8\" >9.686551</td>\n",
       "      <td id=\"T_f5d3c_row0_col9\" class=\"data row0 col9\" >0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5d3c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f5d3c_row1_col0\" class=\"data row1 col0\" >SGD Classifier</td>\n",
       "      <td id=\"T_f5d3c_row1_col1\" class=\"data row1 col1\" >0.975415</td>\n",
       "      <td id=\"T_f5d3c_row1_col2\" class=\"data row1 col2\" >0.985634</td>\n",
       "      <td id=\"T_f5d3c_row1_col3\" class=\"data row1 col3\" >0.923018</td>\n",
       "      <td id=\"T_f5d3c_row1_col4\" class=\"data row1 col4\" >0.953299</td>\n",
       "      <td id=\"T_f5d3c_row1_col5\" class=\"data row1 col5\" >0.502276</td>\n",
       "      <td id=\"T_f5d3c_row1_col6\" class=\"data row1 col6\" >7.698238</td>\n",
       "      <td id=\"T_f5d3c_row1_col7\" class=\"data row1 col7\" >0.001386</td>\n",
       "      <td id=\"T_f5d3c_row1_col8\" class=\"data row1 col8\" >5.191004</td>\n",
       "      <td id=\"T_f5d3c_row1_col9\" class=\"data row1 col9\" >0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5d3c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f5d3c_row2_col0\" class=\"data row2 col0\" >Random_Forest</td>\n",
       "      <td id=\"T_f5d3c_row2_col1\" class=\"data row2 col1\" >0.997821</td>\n",
       "      <td id=\"T_f5d3c_row2_col2\" class=\"data row2 col2\" >0.999449</td>\n",
       "      <td id=\"T_f5d3c_row2_col3\" class=\"data row2 col3\" >0.992531</td>\n",
       "      <td id=\"T_f5d3c_row2_col4\" class=\"data row2 col4\" >0.995978</td>\n",
       "      <td id=\"T_f5d3c_row2_col5\" class=\"data row2 col5\" >0.020425</td>\n",
       "      <td id=\"T_f5d3c_row2_col6\" class=\"data row2 col6\" >0.746863</td>\n",
       "      <td id=\"T_f5d3c_row2_col7\" class=\"data row2 col7\" >1.474755</td>\n",
       "      <td id=\"T_f5d3c_row2_col8\" class=\"data row2 col8\" >50.454203</td>\n",
       "      <td id=\"T_f5d3c_row2_col9\" class=\"data row2 col9\" >0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5d3c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f5d3c_row3_col0\" class=\"data row3 col0\" >Logistic_Regression_SMOTE</td>\n",
       "      <td id=\"T_f5d3c_row3_col1\" class=\"data row3 col1\" >0.970248</td>\n",
       "      <td id=\"T_f5d3c_row3_col2\" class=\"data row3 col2\" >0.936100</td>\n",
       "      <td id=\"T_f5d3c_row3_col3\" class=\"data row3 col3\" >0.955802</td>\n",
       "      <td id=\"T_f5d3c_row3_col4\" class=\"data row3 col4\" >0.945848</td>\n",
       "      <td id=\"T_f5d3c_row3_col5\" class=\"data row3 col5\" >2.435869</td>\n",
       "      <td id=\"T_f5d3c_row3_col6\" class=\"data row3 col6\" >4.419835</td>\n",
       "      <td id=\"T_f5d3c_row3_col7\" class=\"data row3 col7\" >0.001143</td>\n",
       "      <td id=\"T_f5d3c_row3_col8\" class=\"data row3 col8\" >10.738022</td>\n",
       "      <td id=\"T_f5d3c_row3_col9\" class=\"data row3 col9\" >0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5d3c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f5d3c_row4_col0\" class=\"data row4 col0\" >SGD Classifier_SMOTE</td>\n",
       "      <td id=\"T_f5d3c_row4_col1\" class=\"data row4 col1\" >0.966852</td>\n",
       "      <td id=\"T_f5d3c_row4_col2\" class=\"data row4 col2\" >0.934644</td>\n",
       "      <td id=\"T_f5d3c_row4_col3\" class=\"data row4 col3\" >0.944081</td>\n",
       "      <td id=\"T_f5d3c_row4_col4\" class=\"data row4 col4\" >0.939339</td>\n",
       "      <td id=\"T_f5d3c_row4_col5\" class=\"data row4 col5\" >2.464650</td>\n",
       "      <td id=\"T_f5d3c_row4_col6\" class=\"data row4 col6\" >5.591936</td>\n",
       "      <td id=\"T_f5d3c_row4_col7\" class=\"data row4 col7\" >0.001386</td>\n",
       "      <td id=\"T_f5d3c_row4_col8\" class=\"data row4 col8\" >5.864219</td>\n",
       "      <td id=\"T_f5d3c_row4_col9\" class=\"data row4 col9\" >0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5d3c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f5d3c_row5_col0\" class=\"data row5 col0\" >Random_Forest_SMOTE</td>\n",
       "      <td id=\"T_f5d3c_row5_col1\" class=\"data row5 col1\" >0.995906</td>\n",
       "      <td id=\"T_f5d3c_row5_col2\" class=\"data row5 col2\" >0.985162</td>\n",
       "      <td id=\"T_f5d3c_row5_col3\" class=\"data row5 col3\" >1.000000</td>\n",
       "      <td id=\"T_f5d3c_row5_col4\" class=\"data row5 col4\" >0.992525</td>\n",
       "      <td id=\"T_f5d3c_row5_col5\" class=\"data row5 col5\" >0.562314</td>\n",
       "      <td id=\"T_f5d3c_row5_col6\" class=\"data row5 col6\" >0.000000</td>\n",
       "      <td id=\"T_f5d3c_row5_col7\" class=\"data row5 col7\" >2.156518</td>\n",
       "      <td id=\"T_f5d3c_row5_col8\" class=\"data row5 col8\" >69.797611</td>\n",
       "      <td id=\"T_f5d3c_row5_col9\" class=\"data row5 col9\" >0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5d3c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f5d3c_row6_col0\" class=\"data row6 col0\" >IsolationForest (Tuned)</td>\n",
       "      <td id=\"T_f5d3c_row6_col1\" class=\"data row6 col1\" >0.905499</td>\n",
       "      <td id=\"T_f5d3c_row6_col2\" class=\"data row6 col2\" >0.876375</td>\n",
       "      <td id=\"T_f5d3c_row6_col3\" class=\"data row6 col3\" >0.759517</td>\n",
       "      <td id=\"T_f5d3c_row6_col4\" class=\"data row6 col4\" >0.813773</td>\n",
       "      <td id=\"T_f5d3c_row6_col5\" class=\"data row6 col5\" >4.000017</td>\n",
       "      <td id=\"T_f5d3c_row6_col6\" class=\"data row6 col6\" >24.048270</td>\n",
       "      <td id=\"T_f5d3c_row6_col7\" class=\"data row6 col7\" >nan</td>\n",
       "      <td id=\"T_f5d3c_row6_col8\" class=\"data row6 col8\" >111.180085</td>\n",
       "      <td id=\"T_f5d3c_row6_col9\" class=\"data row6 col9\" >0.012598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5d3c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_f5d3c_row7_col0\" class=\"data row7 col0\" >Autoencoder (Baseline)</td>\n",
       "      <td id=\"T_f5d3c_row7_col1\" class=\"data row7 col1\" >0.778149</td>\n",
       "      <td id=\"T_f5d3c_row7_col2\" class=\"data row7 col2\" >1.000000</td>\n",
       "      <td id=\"T_f5d3c_row7_col3\" class=\"data row7 col3\" >0.183924</td>\n",
       "      <td id=\"T_f5d3c_row7_col4\" class=\"data row7 col4\" >0.310702</td>\n",
       "      <td id=\"T_f5d3c_row7_col5\" class=\"data row7 col5\" >0.000000</td>\n",
       "      <td id=\"T_f5d3c_row7_col6\" class=\"data row7 col6\" >81.607650</td>\n",
       "      <td id=\"T_f5d3c_row7_col7\" class=\"data row7 col7\" >0.087400</td>\n",
       "      <td id=\"T_f5d3c_row7_col8\" class=\"data row7 col8\" >154.514615</td>\n",
       "      <td id=\"T_f5d3c_row7_col9\" class=\"data row7 col9\" >0.032508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5d3c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_f5d3c_row8_col0\" class=\"data row8 col0\" >Autoencoder (Tuned)</td>\n",
       "      <td id=\"T_f5d3c_row8_col1\" class=\"data row8 col1\" >0.908162</td>\n",
       "      <td id=\"T_f5d3c_row8_col2\" class=\"data row8 col2\" >0.981317</td>\n",
       "      <td id=\"T_f5d3c_row8_col3\" class=\"data row8 col3\" >0.675027</td>\n",
       "      <td id=\"T_f5d3c_row8_col4\" class=\"data row8 col4\" >0.799852</td>\n",
       "      <td id=\"T_f5d3c_row8_col5\" class=\"data row8 col5\" >0.479809</td>\n",
       "      <td id=\"T_f5d3c_row8_col6\" class=\"data row8 col6\" >32.497335</td>\n",
       "      <td id=\"T_f5d3c_row8_col7\" class=\"data row8 col7\" >0.087400</td>\n",
       "      <td id=\"T_f5d3c_row8_col8\" class=\"data row8 col8\" >154.514615</td>\n",
       "      <td id=\"T_f5d3c_row8_col9\" class=\"data row8 col9\" >0.032508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ceb8fc72c0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the results so far\n",
    "\n",
    "final_results_path = os.path.join(\"results\", \"final_combined_model_results_summary.csv\")\n",
    "final_results = pd.read_csv(final_results_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    \"False Positives\", \"False Negatives\", \"Category\",\n",
    "    \"Contamination\", \"Max Samples\", \"Threshold\"\n",
    "]\n",
    "final_results_display = final_results.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "# Display with highlighting\n",
    "styled_results = (\n",
    "    final_results_display.style\n",
    "    .highlight_max(\n",
    "        subset=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"],\n",
    "        color=\"lightgreen\",\n",
    "        axis=0\n",
    "    )\n",
    "    .highlight_min(\n",
    "        subset=[\n",
    "            \"FP Rate (%)\", \"FN Rate (%)\", \"Train Time (s)\",\n",
    "            \"Model Size (MB)\", \"Inference Time (ms/sample)\"\n",
    "        ],\n",
    "        color=\"lightblue\",\n",
    "        axis=0\n",
    "    )\n",
    ")\n",
    "\n",
    "styled_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8264fc6-a3f4-49be-a431-c22fd5ed0a7c",
   "metadata": {},
   "source": [
    "# Final Model Comparison Summary\n",
    "\n",
    "This final comparison combines the performance of both **Supervised** and **Unsupervised** models trained on the *Edge-IIoT Surveillance Dataset*.\n",
    "\n",
    "## Key Findings from the Experiments\n",
    "\n",
    "- **Random Forest (Supervised + SMOTE)** consistently achieved the highest **Recall** and **F1 Score** with low **FP** and **FN** rates, making it the best candidate for centralized deployment.  \n",
    "- **Autoencoder (Tuned)** provided solid anomaly detection performance with high **Precision** and competitive **Recall**, making it a suitable choice for **Federated Unsupervised IDS**.  \n",
    "- **Isolation Forest (Tuned)** showed decent recall but suffered from higher **FP rates**, confirming earlier observations.  \n",
    "- **Model Sizes** for both Autoencoder and Isolation Forest are lightweight (< 1 MB), supporting their use on edge devices.  \n",
    "- **Training and Inference Times** remain acceptable across all models, with supervised models training faster.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AR-iForest)",
   "language": "python",
   "name": "ar_iforest_fl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
