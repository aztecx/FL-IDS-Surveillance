{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967f1c04-b078-4545-b75e-b20bd82d4a1a",
   "metadata": {},
   "source": [
    "# Notebook 02: Model Development (Supervised & Unsupervised)\n",
    "\n",
    "**Scope.** Build, tune, and evaluate supervised and unsupervised baselines for the FL-IDS (IIoT surveillance). Results here feed later federated experiments and the thesis comparison tables. This notebook reads the processed datasets created earlier and saves reproducible artifacts (metrics, models). It does not upload any data to the repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96bb3a8-6cff-4e6d-b37c-a35d1144a7b5",
   "metadata": {},
   "source": [
    "## Objectives and Structure\n",
    "\n",
    "**Objectives**\n",
    "- Train and evaluate supervised baselines (Logistic Regression, SGD Classifier, Random Forest).\n",
    "- Train and evaluate unsupervised baselines (Isolation Forest, Autoencoder).\n",
    "- Record accuracy, precision, recall, F1, FP/FN (rates and counts), model sizes, and timing.\n",
    "- Save artifacts for later use (metrics CSVs, model binaries, thresholds).\n",
    "\n",
    "**Structure**\n",
    "1) Supervised model development (with and without SMOTE)  \n",
    "2) Unsupervised model development (Isolation Forest tuning, Autoencoder + threshold tuning)  \n",
    "3) Final summary and export of a combined comparison table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f0ee5-26ee-47a9-b2a2-0bb598fb099e",
   "metadata": {},
   "source": [
    "## Reproducibility and Output Folders\n",
    "\n",
    "- All experiments use a fixed `SEED` for `random`, `numpy`, and model initializers when supported.\n",
    "- Output folders (created automatically) keep models and metrics separate for clarity:\n",
    "  - `results/models/supervised/{no_smote|with_smote}/`\n",
    "  - `results/models/unsupervised/`\n",
    "  - `results/*.csv` (experiment metrics and summaries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57f82f-501b-496a-9687-df6422805798",
   "metadata": {},
   "source": [
    "## 1. Supervised Model Development & Evaluation\n",
    "\n",
    "We evaluate three classifiers on two data variants:\n",
    "- **No-SMOTE**: original 80/20 stratified split  \n",
    "- **With-SMOTE**: same split, then SMOTE applied **only on the training set**\n",
    "\n",
    "Features are standardised (`StandardScaler`) per variant to avoid leakage between sets.\n",
    "Metrics are computed on the untouched test set. Models are saved for size measurement and reuse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f74d81-5c97-4c31-b924-623eaab6b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported, Random Seed set, all good\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries and Setting Global Random Seed in order to have the work reproducable\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os \n",
    "import joblib\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,classification_report)\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Setting the random seed for reproducability purposes\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "#Define the model output Directory\n",
    "os.makedirs('results/models/baselines/supervised', exist_ok = True)\n",
    "print(\"Libraries imported, Random Seed set, all good\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8770cd0d-41b3-4263-9ad2-0e481844a22d",
   "metadata": {},
   "source": [
    "### 1.1 Data Loading & Preprocessing (No-SMOTE and With-SMOTE)\n",
    "\n",
    "- Read `no_smote/train.csv` and `test.csv`, then standardise features with a scaler **fit on the training data only**.  \n",
    "- Read `with_smote/train.csv` and `test.csv`, then standardise features again (separate scaler).  \n",
    "- Target column is `Attack_label`. Non-numeric artifacts from earlier steps have already been removed or encoded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d1a714-1ce7-4ff7-b31b-756fece09066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No SMote - Train: (1775067, 42), and for Testing: (443767, 42)\n"
     ]
    }
   ],
   "source": [
    "#Loadind the Preprocessed Data (for No SMOTE)\n",
    "no_smote_path = r\"D:\\August-Thesis\\FL-IDS-Surveillance\\data\\processed\\surv_supervised\\80_20\\no_smote\"\n",
    "train_no_smote = pd.read_csv(f\"{no_smote_path}\\\\train.csv\", low_memory= False)\n",
    "test_no_smote = pd.read_csv(f\"{no_smote_path}\\\\test.csv\", low_memory = False)\n",
    "\n",
    "X_train_ns = train_no_smote.drop(columns = ['Attack_label'])\n",
    "y_train_ns = train_no_smote['Attack_label']\n",
    "\n",
    "X_test_ns = test_no_smote.drop(columns = ['Attack_label'])\n",
    "y_test_ns = test_no_smote['Attack_label']\n",
    "\n",
    "#Checking\n",
    "print(f\"No SMote - Train: {X_train_ns.shape}, and for Testing: {X_test_ns.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4146608-2862-4fec-9476-f2efdf47efb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With SMOTE- Train: (2585028, 42), Test: (443767, 42)\n"
     ]
    }
   ],
   "source": [
    "#Loading the Preprocessed Data ( for SMOTE version)\n",
    "with_smote_path = r\"D:\\August-Thesis\\FL-IDS-Surveillance\\data\\processed\\surv_supervised\\80_20\\with_smote\"\n",
    "train_with_smote = pd.read_csv(f\"{with_smote_path}\\\\train.csv\", low_memory = False)\n",
    "test_with_smote = pd.read_csv(f\"{with_smote_path}\\\\test.csv\", low_memory = False)\n",
    "\n",
    "X_train_ws = train_with_smote.drop(columns=['Attack_label'])\n",
    "y_train_ws = train_with_smote[\"Attack_label\"]\n",
    "\n",
    "X_test_ws = test_with_smote.drop(columns=[\"Attack_label\"])\n",
    "y_test_ws = test_with_smote[\"Attack_label\"]\n",
    "\n",
    "#Checking\n",
    "print(f\"With SMOTE- Train: {X_train_ws.shape}, Test: {X_test_ws.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43a6267-efaf-4afa-8886-5c1e7f355b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Scaling : Applied successfully\n"
     ]
    }
   ],
   "source": [
    "#Using the StandardScaler for both datasets\n",
    "scaler_ns = StandardScaler()\n",
    "X_train_ns_scaled = scaler_ns.fit_transform(X_train_ns)\n",
    "X_test_ns_scaled = scaler_ns.transform(X_test_ns)\n",
    "\n",
    "scaler_ws = StandardScaler()\n",
    "X_train_ws_scaled = scaler_ws.fit_transform(X_train_ws)\n",
    "X_test_ws_scaled = scaler_ws.transform(X_test_ws)\n",
    "\n",
    "print('Feature Scaling : Applied successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981a25d4-b09f-4642-8abe-9551985d028e",
   "metadata": {},
   "source": [
    "### 1.2 Models and Training Setup\n",
    "\n",
    "We train the following baselines with sensible defaults:\n",
    "- **Logistic Regression** (`max_iter=1000`)\n",
    "- **SGD Classifier** (linear baseline)\n",
    "- **Random Forest** (parallel, `n_jobs=-1`)\n",
    "\n",
    "For each model and data variant:\n",
    "- Fit on the training split, predict on the test split.\n",
    "- Record metrics, FP/FN counts, FP/FN rates, model size (MB), train time (s), and inference time (ms/sample).\n",
    "- Save the fitted model under `results/models/supervised/{no_smote|with_smote}/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8dc91f0-2ccd-4661-842d-98fde7a8a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, model_name, X_train, y_train, X_test, y_test, save_dir):\n",
    "    results = {}\n",
    "\n",
    "    #Training Phase\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_train\n",
    "\n",
    "    #Predicting Phase\n",
    "    start_test = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_time = time.time() - start_test\n",
    "    inference_time_per_sample = test_time / len(X_test)\n",
    "\n",
    "    #Defining the metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    fp_rate = 100 * fp / (fp + tn)\n",
    "    fn_rate = 100 * fn / (fn + tp)\n",
    "\n",
    "    #Saving Model for measuring the size and possibly using later on ...etc\n",
    "    os.makedirs(save_dir, exist_ok = True)\n",
    "    save_path = os.path.join(save_dir, f\"{model_name}.pkl\")\n",
    "    joblib.dump(model, save_path)\n",
    "    model_size_mb = os.path.getsize(save_path) / (1024 * 1024)\n",
    "\n",
    "    #Collecting results for the thesis\n",
    "    results.update({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1 Score': f1,\n",
    "        'False Positives': fp,\n",
    "        'False Negatives': fn,\n",
    "        'FP Rate (%)': fp_rate,\n",
    "        'FN Rate (%)': fn_rate,\n",
    "        'Model Size (MB)': model_size_mb,\n",
    "        'Train Time (s)': train_time,\n",
    "        'Inference Time (ms/sample)': inference_time_per_sample * 1000\n",
    "     })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aea0eb1-0d3c-45ba-b788-50707e721ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_expirenments (models_dict, X_train, y_train, X_test, y_test, save_dir):\n",
    "    all_resluts = []\n",
    "    for name, model in models_dict.items():\n",
    "        print(f\"Training {name} in progress . . .\")\n",
    "        result = train_and_evaluate(model, name, X_train, y_train, X_test, y_test, save_dir)\n",
    "        all_resluts.append(result)\n",
    "    return pd.DataFrame(all_resluts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2dd78b5-e640-42d8-adaf-67309f14d412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic_Regressin in progress . . .\n",
      "Training SGD Classifier in progress . . .\n",
      "Training Random_Forest in progress . . .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d11d5_row2_col1, #T_d11d5_row2_col2, #T_d11d5_row2_col3, #T_d11d5_row2_col4 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d11d5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d11d5_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_d11d5_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_d11d5_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_d11d5_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_d11d5_level0_col4\" class=\"col_heading level0 col4\" >F1 Score</th>\n",
       "      <th id=\"T_d11d5_level0_col5\" class=\"col_heading level0 col5\" >False Positives</th>\n",
       "      <th id=\"T_d11d5_level0_col6\" class=\"col_heading level0 col6\" >False Negatives</th>\n",
       "      <th id=\"T_d11d5_level0_col7\" class=\"col_heading level0 col7\" >FP Rate (%)</th>\n",
       "      <th id=\"T_d11d5_level0_col8\" class=\"col_heading level0 col8\" >FN Rate (%)</th>\n",
       "      <th id=\"T_d11d5_level0_col9\" class=\"col_heading level0 col9\" >Model Size (MB)</th>\n",
       "      <th id=\"T_d11d5_level0_col10\" class=\"col_heading level0 col10\" >Train Time (s)</th>\n",
       "      <th id=\"T_d11d5_level0_col11\" class=\"col_heading level0 col11\" >Inference Time (ms/sample)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d11d5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d11d5_row0_col0\" class=\"data row0 col0\" >Logistic_Regressin</td>\n",
       "      <td id=\"T_d11d5_row0_col1\" class=\"data row0 col1\" >0.982667</td>\n",
       "      <td id=\"T_d11d5_row0_col2\" class=\"data row0 col2\" >0.996414</td>\n",
       "      <td id=\"T_d11d5_row0_col3\" class=\"data row0 col3\" >0.939621</td>\n",
       "      <td id=\"T_d11d5_row0_col4\" class=\"data row0 col4\" >0.967184</td>\n",
       "      <td id=\"T_d11d5_row0_col5\" class=\"data row0 col5\" >408</td>\n",
       "      <td id=\"T_d11d5_row0_col6\" class=\"data row0 col6\" >7284</td>\n",
       "      <td id=\"T_d11d5_row0_col7\" class=\"data row0 col7\" >0.126265</td>\n",
       "      <td id=\"T_d11d5_row0_col8\" class=\"data row0 col8\" >6.037899</td>\n",
       "      <td id=\"T_d11d5_row0_col9\" class=\"data row0 col9\" >0.001143</td>\n",
       "      <td id=\"T_d11d5_row0_col10\" class=\"data row0 col10\" >9.686551</td>\n",
       "      <td id=\"T_d11d5_row0_col11\" class=\"data row0 col11\" >0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d11d5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d11d5_row1_col0\" class=\"data row1 col0\" >SGD Classifier</td>\n",
       "      <td id=\"T_d11d5_row1_col1\" class=\"data row1 col1\" >0.975415</td>\n",
       "      <td id=\"T_d11d5_row1_col2\" class=\"data row1 col2\" >0.985634</td>\n",
       "      <td id=\"T_d11d5_row1_col3\" class=\"data row1 col3\" >0.923018</td>\n",
       "      <td id=\"T_d11d5_row1_col4\" class=\"data row1 col4\" >0.953299</td>\n",
       "      <td id=\"T_d11d5_row1_col5\" class=\"data row1 col5\" >1623</td>\n",
       "      <td id=\"T_d11d5_row1_col6\" class=\"data row1 col6\" >9287</td>\n",
       "      <td id=\"T_d11d5_row1_col7\" class=\"data row1 col7\" >0.502276</td>\n",
       "      <td id=\"T_d11d5_row1_col8\" class=\"data row1 col8\" >7.698238</td>\n",
       "      <td id=\"T_d11d5_row1_col9\" class=\"data row1 col9\" >0.001386</td>\n",
       "      <td id=\"T_d11d5_row1_col10\" class=\"data row1 col10\" >5.191004</td>\n",
       "      <td id=\"T_d11d5_row1_col11\" class=\"data row1 col11\" >0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d11d5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d11d5_row2_col0\" class=\"data row2 col0\" >Random_Forest</td>\n",
       "      <td id=\"T_d11d5_row2_col1\" class=\"data row2 col1\" >0.997821</td>\n",
       "      <td id=\"T_d11d5_row2_col2\" class=\"data row2 col2\" >0.999449</td>\n",
       "      <td id=\"T_d11d5_row2_col3\" class=\"data row2 col3\" >0.992531</td>\n",
       "      <td id=\"T_d11d5_row2_col4\" class=\"data row2 col4\" >0.995978</td>\n",
       "      <td id=\"T_d11d5_row2_col5\" class=\"data row2 col5\" >66</td>\n",
       "      <td id=\"T_d11d5_row2_col6\" class=\"data row2 col6\" >901</td>\n",
       "      <td id=\"T_d11d5_row2_col7\" class=\"data row2 col7\" >0.020425</td>\n",
       "      <td id=\"T_d11d5_row2_col8\" class=\"data row2 col8\" >0.746863</td>\n",
       "      <td id=\"T_d11d5_row2_col9\" class=\"data row2 col9\" >1.474755</td>\n",
       "      <td id=\"T_d11d5_row2_col10\" class=\"data row2 col10\" >50.454203</td>\n",
       "      <td id=\"T_d11d5_row2_col11\" class=\"data row2 col11\" >0.001066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cb273f7b30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_to_train = {\n",
    "    'Logistic_Regressin' : LogisticRegression(max_iter = 1000, random_state = SEED),\n",
    "    'SGD Classifier' : SGDClassifier(random_state = SEED),\n",
    "    'Random_Forest' : RandomForestClassifier(n_jobs = -1, random_state = SEED)\n",
    "}\n",
    "\n",
    "results_no_smote = run_expirenments(\n",
    "    models_to_train,\n",
    "    X_train_ns_scaled, y_train_ns,\n",
    "    X_test_ns_scaled, y_test_ns,\n",
    "    \"results/models/supervised/no_smote\"\n",
    ")\n",
    "\n",
    "results_no_smote.to_csv(\"results/supervised_results_no_smote.csv\", index = False)\n",
    "results_no_smote.style.highlight_max(subset=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"], color=\"lightgreen\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "718c9a62-d9e1-4025-860b-fbdc494ee745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic_Regression_SMOTE in progress . . .\n",
      "Training SGD Classifier_SMOTE in progress . . .\n",
      "Training Random_Forest_SMOTE in progress . . .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9e77c_row0_col9, #T_9e77c_row1_col10, #T_9e77c_row1_col11, #T_9e77c_row2_col7, #T_9e77c_row2_col8 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "#T_9e77c_row2_col1, #T_9e77c_row2_col2, #T_9e77c_row2_col3, #T_9e77c_row2_col4 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9e77c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9e77c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_9e77c_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_9e77c_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_9e77c_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_9e77c_level0_col4\" class=\"col_heading level0 col4\" >F1 Score</th>\n",
       "      <th id=\"T_9e77c_level0_col5\" class=\"col_heading level0 col5\" >False Positives</th>\n",
       "      <th id=\"T_9e77c_level0_col6\" class=\"col_heading level0 col6\" >False Negatives</th>\n",
       "      <th id=\"T_9e77c_level0_col7\" class=\"col_heading level0 col7\" >FP Rate (%)</th>\n",
       "      <th id=\"T_9e77c_level0_col8\" class=\"col_heading level0 col8\" >FN Rate (%)</th>\n",
       "      <th id=\"T_9e77c_level0_col9\" class=\"col_heading level0 col9\" >Model Size (MB)</th>\n",
       "      <th id=\"T_9e77c_level0_col10\" class=\"col_heading level0 col10\" >Train Time (s)</th>\n",
       "      <th id=\"T_9e77c_level0_col11\" class=\"col_heading level0 col11\" >Inference Time (ms/sample)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9e77c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9e77c_row0_col0\" class=\"data row0 col0\" >Logistic_Regression_SMOTE</td>\n",
       "      <td id=\"T_9e77c_row0_col1\" class=\"data row0 col1\" >0.970248</td>\n",
       "      <td id=\"T_9e77c_row0_col2\" class=\"data row0 col2\" >0.936100</td>\n",
       "      <td id=\"T_9e77c_row0_col3\" class=\"data row0 col3\" >0.955802</td>\n",
       "      <td id=\"T_9e77c_row0_col4\" class=\"data row0 col4\" >0.945848</td>\n",
       "      <td id=\"T_9e77c_row0_col5\" class=\"data row0 col5\" >7871</td>\n",
       "      <td id=\"T_9e77c_row0_col6\" class=\"data row0 col6\" >5332</td>\n",
       "      <td id=\"T_9e77c_row0_col7\" class=\"data row0 col7\" >2.435869</td>\n",
       "      <td id=\"T_9e77c_row0_col8\" class=\"data row0 col8\" >4.419835</td>\n",
       "      <td id=\"T_9e77c_row0_col9\" class=\"data row0 col9\" >0.001143</td>\n",
       "      <td id=\"T_9e77c_row0_col10\" class=\"data row0 col10\" >10.738022</td>\n",
       "      <td id=\"T_9e77c_row0_col11\" class=\"data row0 col11\" >0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e77c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9e77c_row1_col0\" class=\"data row1 col0\" >SGD Classifier_SMOTE</td>\n",
       "      <td id=\"T_9e77c_row1_col1\" class=\"data row1 col1\" >0.966852</td>\n",
       "      <td id=\"T_9e77c_row1_col2\" class=\"data row1 col2\" >0.934644</td>\n",
       "      <td id=\"T_9e77c_row1_col3\" class=\"data row1 col3\" >0.944081</td>\n",
       "      <td id=\"T_9e77c_row1_col4\" class=\"data row1 col4\" >0.939339</td>\n",
       "      <td id=\"T_9e77c_row1_col5\" class=\"data row1 col5\" >7964</td>\n",
       "      <td id=\"T_9e77c_row1_col6\" class=\"data row1 col6\" >6746</td>\n",
       "      <td id=\"T_9e77c_row1_col7\" class=\"data row1 col7\" >2.464650</td>\n",
       "      <td id=\"T_9e77c_row1_col8\" class=\"data row1 col8\" >5.591936</td>\n",
       "      <td id=\"T_9e77c_row1_col9\" class=\"data row1 col9\" >0.001386</td>\n",
       "      <td id=\"T_9e77c_row1_col10\" class=\"data row1 col10\" >5.864219</td>\n",
       "      <td id=\"T_9e77c_row1_col11\" class=\"data row1 col11\" >0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e77c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9e77c_row2_col0\" class=\"data row2 col0\" >Random_Forest_SMOTE</td>\n",
       "      <td id=\"T_9e77c_row2_col1\" class=\"data row2 col1\" >0.995906</td>\n",
       "      <td id=\"T_9e77c_row2_col2\" class=\"data row2 col2\" >0.985162</td>\n",
       "      <td id=\"T_9e77c_row2_col3\" class=\"data row2 col3\" >1.000000</td>\n",
       "      <td id=\"T_9e77c_row2_col4\" class=\"data row2 col4\" >0.992525</td>\n",
       "      <td id=\"T_9e77c_row2_col5\" class=\"data row2 col5\" >1817</td>\n",
       "      <td id=\"T_9e77c_row2_col6\" class=\"data row2 col6\" >0</td>\n",
       "      <td id=\"T_9e77c_row2_col7\" class=\"data row2 col7\" >0.562314</td>\n",
       "      <td id=\"T_9e77c_row2_col8\" class=\"data row2 col8\" >0.000000</td>\n",
       "      <td id=\"T_9e77c_row2_col9\" class=\"data row2 col9\" >2.156518</td>\n",
       "      <td id=\"T_9e77c_row2_col10\" class=\"data row2 col10\" >69.797611</td>\n",
       "      <td id=\"T_9e77c_row2_col11\" class=\"data row2 col11\" >0.001177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cb274053a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With SMOTE Applied now\n",
    "models_to_train_smote = {\n",
    "    'Logistic_Regression_SMOTE' : LogisticRegression(max_iter = 1000, random_state = SEED),\n",
    "    'SGD Classifier_SMOTE' : SGDClassifier(random_state = SEED),\n",
    "    'Random_Forest_SMOTE' : RandomForestClassifier(n_jobs = -1, random_state = SEED)\n",
    "}\n",
    "\n",
    "results_ws_smote = run_expirenments(\n",
    "    models_to_train_smote,\n",
    "    X_train_ws_scaled, y_train_ws,\n",
    "    X_test_ws_scaled, y_test_ws,\n",
    "    \"results/models/supervised/with_smote\"\n",
    ")\n",
    "\n",
    "results_ws_smote.to_csv(\"results/supervised_results_with_smote.csv\", index = False)\n",
    "results_ws_smote.style.highlight_max(subset=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"], color=\"lightgreen\", axis=0).highlight_min(subset=[\"FP Rate (%)\",\n",
    "                                                                                                                                               \"FN Rate (%)\",\n",
    "                                                                                                                                               \"Train Time (s)\",\n",
    "                                                                                                                                               \"Model Size (MB)\",\n",
    "                                                                                                                                               \"Inference Time (ms/sample)\"],\n",
    "                                                                                                                                       color=\"lightblue\",\n",
    "                                                                                                                                       axis=0\n",
    "                                                                                                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b97ba-f11c-4275-950a-0b14c2edaba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AR-iForest)",
   "language": "python",
   "name": "ar_iforest_fl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
