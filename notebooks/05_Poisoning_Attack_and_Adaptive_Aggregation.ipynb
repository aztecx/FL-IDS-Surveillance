{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b8b3d08-da64-4839-b445-288b9e92b13e",
   "metadata": {},
   "source": [
    "# 05 Advanced Model Poisoning Attacks and Adaptive Aggregation Strategies\n",
    "\n",
    "This notebook extends the Federated Learning-based Intrusion Detection System (FL-IDS) for Industrial IoT (IIoT) by implementing advanced model update poisoning attacks and adaptive aggregation strategies.\n",
    "\n",
    "---\n",
    "\n",
    "### Objectives:\n",
    "- **Simulate Advanced Model Update Poisoning Attacks:**\n",
    "  - Sign Flipping Attack\n",
    "  - Scaling Attack\n",
    "  - Sybil Attack (Coordinated Attackers)\n",
    "  - Adaptive Gradient-based Attack\n",
    "\n",
    "- **Implement Adaptive Aggregation Strategies:**\n",
    "  - Drift-Aware Weighting of Client Updates\n",
    "  - Performance Feedback-based Aggregation\n",
    "\n",
    "- **Simulate Realistic FL Scenarios:**\n",
    "  - Client Dropout Simulation\n",
    "  - Data and Computational Heterogeneity\n",
    "\n",
    "- **Evaluate System Resilience under Adversarial Conditions**\n",
    "  - Impact on Global Autoencoder Performance\n",
    "  - Comparative Analysis with Robust Aggregation Methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c31f02-5e46-42f5-82d9-fa6a11339d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The setup is  complete:\n",
      "- Loaded model: final_federated_autoencoder_20rounds.h5\n",
      "- Clients: ['client_1', 'client_2', 'client_3', 'client_4', 'client_5']\n",
      "- Test samples: 2218834\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, clone_model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import joblib\n",
    "\n",
    "# For reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# === Defining Paths ===\n",
    "base_path = \"D:/August-Thesis/FL-IDS-Surveillance\"\n",
    "results_path = os.path.join(base_path, \"notebooks/results\")\n",
    "\n",
    "model_path = os.path.join(results_path, \"models/unsupervised/federated/final_federated_autoencoder_20rounds.h5\")\n",
    "scaler_path = os.path.join(results_path, \"scalers/minmax_scaler_client_3.pkl\")  \n",
    "\n",
    "data_path = os.path.join(base_path, \"data/processed/federated/unsupervised\")\n",
    "test_path = os.path.join(base_path, \"data/processed/surv_unsupervised/test_mixed.csv\")\n",
    "\n",
    "client_ids = [f\"client_{i}\" for i in range(1, 6)]\n",
    "\n",
    "# === Loading the model (uncompiled) ===\n",
    "global_model = load_model(model_path, compile=False)\n",
    "global_model.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "\n",
    "# === Loading necessary Scaler ===\n",
    "minmax_scaler = joblib.load(scaler_path)\n",
    "\n",
    "feature_cols = list(minmax_scaler.feature_names_in_)\n",
    "\n",
    "\n",
    "# === Load Client Data ===\n",
    "client_dfs = {\n",
    "    cid: pd.read_csv(os.path.join(data_path, cid, \"train.csv\")) \n",
    "    for cid in client_ids\n",
    "}\n",
    "\n",
    "# === Load Testing Set ===\n",
    "test_df = pd.read_csv(test_path, low_memory = False)\n",
    "X_test = test_df[feature_cols].astype(float)\n",
    "y_true = test_df[\"Attack_label\"].values\n",
    "X_test_scaled = minmax_scaler.transform(test_df[feature_cols])\n",
    "\n",
    "print(\"The setup is  complete:\")\n",
    "print(f\"- Loaded model: {os.path.basename(model_path)}\")\n",
    "print(f\"- Clients: {client_ids}\")\n",
    "print(f\"- Test samples: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f731b79-8c89-4bed-b912-ab3283949438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Performance Before Attack:\n",
      "- F1 Score:      0.8373\n",
      "- Precision:     0.9877\n",
      "- Recall:        0.7266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Use the best threshold from Notebook 03\n",
    "threshold = 0.000639\n",
    "\n",
    "# Baseline evaluation to establish \n",
    "reconstructed = global_model.predict(X_test_scaled, verbose=0)\n",
    "reconstruction_errors = np.mean(np.square(X_test_scaled - reconstructed), axis=1)\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)\n",
    "\n",
    "# the Metrics\n",
    "f1_baseline = f1_score(y_true, y_pred)\n",
    "precision_baseline = precision_score(y_true, y_pred)\n",
    "recall_baseline = recall_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Baseline Performance Before Attack:\")\n",
    "print(f\"- F1 Score:      {f1_baseline:.4f}\")\n",
    "print(f\"- Precision:     {precision_baseline:.4f}\")\n",
    "print(f\"- Recall:        {recall_baseline:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50583f45-52d7-4773-b6df-dfa4859f68bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_flipping_attack(global_weights, local_weights, scale_factor=1.0):\n",
    "    \"\"\"\n",
    "    Inverts and scales the difference between local and global weights.\n",
    "    \n",
    "    Arguments:\n",
    "        global_weights: List of global model weights\n",
    "        local_weights: List of local model weights from attacker\n",
    "        scale_factor: Multiplier for amplification (default = 1.0)\n",
    "    \n",
    "    Returns:\n",
    "        poisoned_weights: List of poisoned weights to submit\n",
    "    \"\"\"\n",
    "    poisoned_weights = []\n",
    "    for gw, lw in zip(global_weights, local_weights):\n",
    "        delta = lw - gw\n",
    "        flipped = gw - scale_factor * delta\n",
    "        poisoned_weights.append(flipped)\n",
    "    return poisoned_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acb9bfba-3701-4c4f-a3f7-28d55a4344a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_attack(global_weights, local_weights, scale_factor=10.0):\n",
    "    \"\"\"\n",
    "    Amplifies the local update from an attacker before submission.\n",
    "\n",
    "    Args:\n",
    "        global_weights: List of global model weights\n",
    "        local_weights: List of attacker's local weights\n",
    "        scale_factor: Multiplier to exaggerate the delta (default = 10.0)\n",
    "\n",
    "    Returns:\n",
    "        poisoned_weights: List of exaggerated weights\n",
    "    \"\"\"\n",
    "    poisoned_weights = []\n",
    "    for gw, lw in zip(global_weights, local_weights):\n",
    "        delta = lw - gw\n",
    "        scaled = gw + scale_factor * delta\n",
    "        poisoned_weights.append(scaled)\n",
    "    return poisoned_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae7ecd6-8f64-4cc1-887d-5ea1d18f5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sybil_updates(poisoned_weights, num_sybil_nodes):\n",
    "    \"\"\"\n",
    "    Creates multiple identical poisoned updates for Sybil clients.\n",
    "\n",
    "    Args:\n",
    "        poisoned_weights: List of weights from the attacking client\n",
    "        num_sybil_nodes: Number of fake clients to simulate\n",
    "\n",
    "    Returns:\n",
    "        List of poisoned updates (one per Sybil node)\n",
    "    \"\"\"\n",
    "    return [poisoned_weights for _ in range(num_sybil_nodes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18005f8-2927-48f4-9f5e-fdcd4b6115a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_gradient_attack(global_weights, local_weights, learning_rate=1.0, noise_std=0.0):\n",
    "    \"\"\"\n",
    "    Computes a crafted adversarial update using the difference between local and global weights.\n",
    "\n",
    "    Args:\n",
    "        global_weights: List of global model weights\n",
    "        local_weights: List of local attacker model weights\n",
    "        learning_rate: Scalar to amplify attack strength\n",
    "        noise_std: Standard deviation of noise added to gradient which is optional and set to 0.0 \n",
    "\n",
    "    Returns:\n",
    "        poisoned_weights: List of adversarially crafted model weights\n",
    "    \"\"\"\n",
    "    poisoned_weights = []\n",
    "    for gw, lw in zip(global_weights, local_weights):\n",
    "        gradient = lw-gw\n",
    "        if noise_std > 0:\n",
    "            noise = np.random.normal(loc=0.0, scale=noise_std,size=gradient.shape)\n",
    "            gradient = gradient + noise\n",
    "        adversarial_update = gw +learning_rate * gradient\n",
    "        poisoned_weights.append(adversarial_update)\n",
    "    return poisoned_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67b2ad-c8c2-4346-93aa-f2f19e8a6d7c",
   "metadata": {},
   "source": [
    "## Testing the Attacks' effects now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9a86ec8-e18f-44a0-bbe9-ae17ae7a8da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45fc0b73-a4bc-4ead-91e7-befe4279b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def run_sign_flipping_attack_simulation(\n",
    "    global_model,\n",
    "    client_dfs,\n",
    "    scaler,\n",
    "    feature_names,\n",
    "    X_test_scaled,\n",
    "    y_true,\n",
    "    threshold=0.000639,\n",
    "    attacker_id=\"client_3\",\n",
    "    attack_round=6,\n",
    "    scale_factor=1.5,\n",
    "    save_path=\"D:/August-Thesis/FL-IDS-Surveillance/notebooks/results/poisoning_sign_flipping_attack.csv\"\n",
    "):\n",
    "    model_copy = clone_model(global_model)\n",
    "    model_copy.set_weights(global_model.get_weights())\n",
    "    model_copy.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "\n",
    "    f1_list, precision_list, recall_list = [], [], []\n",
    "    fp_rates, fn_rates = [], []\n",
    "\n",
    "    for round_num in range(1, 21):\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in client_ids:\n",
    "            df = client_dfs[cid]\n",
    "            X_local = df[feature_names].astype(float)\n",
    "            X_scaled = scaler.transform(X_local)\n",
    "\n",
    "            local_model = clone_model(model_copy)\n",
    "            local_model.set_weights(model_copy.get_weights())\n",
    "            local_model.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "            local_model.fit(X_scaled, X_scaled, epochs=1, batch_size=256, verbose=0)\n",
    "\n",
    "            weights = local_model.get_weights()\n",
    "\n",
    "            # Apply attack if this is the attacker and attack round started\n",
    "            if cid == attacker_id and round_num >= attack_round:\n",
    "                weights = sign_flipping_attack(model_copy.get_weights(), weights, scale_factor=scale_factor)\n",
    "\n",
    "            local_weights.append(weights)\n",
    "\n",
    "        # the FedAvg\n",
    "        averaged_weights = [\n",
    "            np.mean([w[i] for w in local_weights], axis=0)\n",
    "            for i in range(len(local_weights[0]))\n",
    "        ]\n",
    "        model_copy.set_weights(averaged_weights)\n",
    "\n",
    "        # Evaluation\n",
    "        preds = model_copy.predict(X_test_scaled, verbose=0)\n",
    "        recon_errors = np.mean(np.square(X_test_scaled - preds), axis=1)\n",
    "        y_pred = (recon_errors > threshold).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred)\n",
    "        rec = recall_score(y_true, y_pred)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        fp_rate = fp / (fp + tn + 1e-6)\n",
    "        fn_rate = fn / (fn + tp + 1e-6)\n",
    "\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        fp_rates.append(fp_rate)\n",
    "        fn_rates.append(fn_rate)\n",
    "\n",
    "        print(f\"SignFlip | Round {round_num:02d} | F1: {f1:.4f} | P: {prec:.4f} | R: {rec:.4f} | FP Rate: {fp_rate:.4f} | FN Rate: {fn_rate:.4f}\")\n",
    "\n",
    "    # Saving results and exporting it to csv\n",
    "    df_out = pd.DataFrame({\n",
    "        \"Round\": list(range(1, 21)),\n",
    "        \"F1\": f1_list,\n",
    "        \"Precision\": precision_list,\n",
    "        \"Recall\": recall_list,\n",
    "        \"FP Rate\": fp_rates,\n",
    "        \"FN Rate\": fn_rates\n",
    "    })\n",
    "    df_out.to_csv(save_path, index=False)\n",
    "    print(f\"\\nResults saved to: {save_path}\")\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08da3251-d2aa-4825-9f44-14afe2d5bcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignFlip | Round 01 | F1: 0.8368 | P: 0.9878 | R: 0.7258 | FP Rate: 0.0034 | FN Rate: 0.2742\n",
      "SignFlip | Round 02 | F1: 0.8363 | P: 0.9879 | R: 0.7250 | FP Rate: 0.0033 | FN Rate: 0.2750\n",
      "SignFlip | Round 03 | F1: 0.8356 | P: 0.9879 | R: 0.7240 | FP Rate: 0.0033 | FN Rate: 0.2760\n",
      "SignFlip | Round 04 | F1: 0.8350 | P: 0.9879 | R: 0.7231 | FP Rate: 0.0033 | FN Rate: 0.2769\n",
      "SignFlip | Round 05 | F1: 0.8348 | P: 0.9879 | R: 0.7227 | FP Rate: 0.0033 | FN Rate: 0.2773\n",
      "SignFlip | Round 06 | F1: 0.8356 | P: 0.9879 | R: 0.7240 | FP Rate: 0.0033 | FN Rate: 0.2760\n",
      "SignFlip | Round 07 | F1: 0.8360 | P: 0.9877 | R: 0.7247 | FP Rate: 0.0034 | FN Rate: 0.2753\n",
      "SignFlip | Round 08 | F1: 0.8364 | P: 0.9877 | R: 0.7253 | FP Rate: 0.0034 | FN Rate: 0.2747\n",
      "SignFlip | Round 09 | F1: 0.8370 | P: 0.9877 | R: 0.7262 | FP Rate: 0.0034 | FN Rate: 0.2738\n",
      "SignFlip | Round 10 | F1: 0.8363 | P: 0.9885 | R: 0.7248 | FP Rate: 0.0032 | FN Rate: 0.2752\n",
      "SignFlip | Round 11 | F1: 0.8354 | P: 0.9886 | R: 0.7233 | FP Rate: 0.0031 | FN Rate: 0.2767\n",
      "SignFlip | Round 12 | F1: 0.8345 | P: 0.9887 | R: 0.7220 | FP Rate: 0.0031 | FN Rate: 0.2780\n",
      "SignFlip | Round 13 | F1: 0.8337 | P: 0.9887 | R: 0.7207 | FP Rate: 0.0031 | FN Rate: 0.2793\n",
      "SignFlip | Round 14 | F1: 0.8326 | P: 0.9885 | R: 0.7192 | FP Rate: 0.0031 | FN Rate: 0.2808\n",
      "SignFlip | Round 15 | F1: 0.8321 | P: 0.9884 | R: 0.7185 | FP Rate: 0.0031 | FN Rate: 0.2815\n",
      "SignFlip | Round 16 | F1: 0.8315 | P: 0.9884 | R: 0.7176 | FP Rate: 0.0032 | FN Rate: 0.2824\n",
      "SignFlip | Round 17 | F1: 0.8310 | P: 0.9883 | R: 0.7168 | FP Rate: 0.0032 | FN Rate: 0.2832\n",
      "SignFlip | Round 18 | F1: 0.8305 | P: 0.9883 | R: 0.7162 | FP Rate: 0.0032 | FN Rate: 0.2838\n",
      "SignFlip | Round 19 | F1: 0.8301 | P: 0.9883 | R: 0.7156 | FP Rate: 0.0032 | FN Rate: 0.2844\n",
      "SignFlip | Round 20 | F1: 0.8300 | P: 0.9883 | R: 0.7154 | FP Rate: 0.0032 | FN Rate: 0.2846\n",
      "\n",
      "Results saved to: D:/August-Thesis/FL-IDS-Surveillance/notebooks/results/poisoning_sign_flipping_attack.csv\n"
     ]
    }
   ],
   "source": [
    "results_sign_flip = run_sign_flipping_attack_simulation(\n",
    "    global_model,\n",
    "    client_dfs,\n",
    "    minmax_scaler,\n",
    "    feature_names,\n",
    "    X_test_scaled,\n",
    "    y_true\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da4ea284-88c5-4541-bf78-5c2621a9ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def run_scaling_attack_simulation(\n",
    "    global_model,\n",
    "    client_dfs,\n",
    "    scaler,\n",
    "    feature_names,\n",
    "    X_test_scaled,\n",
    "    y_true,\n",
    "    threshold=0.000639,\n",
    "    malicious_clients=[\"client_3\", \"client_4\"],\n",
    "    attack_round=6,\n",
    "    scale_factor=10.0,\n",
    "    save_path=\"D:/August-Thesis/FL-IDS-Surveillance/notebooks/results/poisoning_scaling_attack.csv\"\n",
    "):\n",
    "    model_copy = clone_model(global_model)\n",
    "    model_copy.set_weights(global_model.get_weights())\n",
    "    model_copy.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "\n",
    "    f1_list, precision_list, recall_list = [], [], []\n",
    "    fp_rates, fn_rates = [], []\n",
    "\n",
    "    for round_num in range(1, 21):\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in client_ids:\n",
    "            df = client_dfs[cid]\n",
    "            X_local = df[feature_names].astype(float)\n",
    "            X_scaled = scaler.transform(X_local)\n",
    "\n",
    "            local_model = clone_model(model_copy)\n",
    "            local_model.set_weights(model_copy.get_weights())\n",
    "            local_model.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "            local_model.fit(X_scaled, X_scaled, epochs=1, batch_size=256, verbose=0)\n",
    "\n",
    "            weights = local_model.get_weights()\n",
    "\n",
    "            # Apply scaling attack if client is malicious after attack_round\n",
    "            if cid in malicious_clients and round_num >= attack_round:\n",
    "                weights = scaling_attack(model_copy.get_weights(), weights, scale_factor=scale_factor)\n",
    "\n",
    "            local_weights.append(weights)\n",
    "\n",
    "        # FedAvg Aggregation\n",
    "        averaged_weights = [\n",
    "            np.mean([w[i] for w in local_weights], axis=0)\n",
    "            for i in range(len(local_weights[0]))\n",
    "        ]\n",
    "        model_copy.set_weights(averaged_weights)\n",
    "\n",
    "        # Evaluate global model\n",
    "        preds = model_copy.predict(X_test_scaled, verbose=0)\n",
    "        recon_errors = np.mean(np.square(X_test_scaled - preds), axis=1)\n",
    "        y_pred = (recon_errors > threshold).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred)\n",
    "        rec = recall_score(y_true, y_pred)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        fp_rate = fp / (fp + tn + 1e-6)\n",
    "        fn_rate = fn / (fn + tp + 1e-6)\n",
    "\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        fp_rates.append(fp_rate)\n",
    "        fn_rates.append(fn_rate)\n",
    "\n",
    "        print(f\"ScalingAttack | Round {round_num:02d} | F1: {f1:.4f} | P: {prec:.4f} | R: {rec:.4f} | FP Rate: {fp_rate:.4f} | FN Rate: {fn_rate:.4f}\")\n",
    "\n",
    "    # Saving results\n",
    "    df_out = pd.DataFrame({\n",
    "        \"Round\": list(range(1, 21)),\n",
    "        \"F1\": f1_list,\n",
    "        \"Precision\": precision_list,\n",
    "        \"Recall\": recall_list,\n",
    "        \"FP Rate\": fp_rates,\n",
    "        \"FN Rate\": fn_rates\n",
    "    })\n",
    "    df_out.to_csv(save_path, index=False)\n",
    "    print(f\"\\nResults saved to: {save_path}\")\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "638d7b4b-aa17-463c-b8dd-71f66090699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScalingAttack | Round 01 | F1: 0.8368 | P: 0.9878 | R: 0.7258 | FP Rate: 0.0034 | FN Rate: 0.2742\n",
      "ScalingAttack | Round 02 | F1: 0.8363 | P: 0.9879 | R: 0.7250 | FP Rate: 0.0033 | FN Rate: 0.2750\n",
      "ScalingAttack | Round 03 | F1: 0.8356 | P: 0.9879 | R: 0.7240 | FP Rate: 0.0033 | FN Rate: 0.2760\n",
      "ScalingAttack | Round 04 | F1: 0.8350 | P: 0.9879 | R: 0.7231 | FP Rate: 0.0033 | FN Rate: 0.2769\n",
      "ScalingAttack | Round 05 | F1: 0.8348 | P: 0.9879 | R: 0.7227 | FP Rate: 0.0033 | FN Rate: 0.2773\n",
      "ScalingAttack | Round 06 | F1: 0.8270 | P: 0.9877 | R: 0.7113 | FP Rate: 0.0033 | FN Rate: 0.2887\n",
      "ScalingAttack | Round 07 | F1: 0.7509 | P: 0.7231 | R: 0.7809 | FP Rate: 0.1117 | FN Rate: 0.2191\n",
      "ScalingAttack | Round 08 | F1: 0.4391 | P: 0.2822 | R: 0.9885 | FP Rate: 0.9386 | FN Rate: 0.0115\n",
      "ScalingAttack | Round 09 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "ScalingAttack | Round 10 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "ScalingAttack | Round 11 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "ScalingAttack | Round 12 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "ScalingAttack | Round 13 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "ScalingAttack | Round 14 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "ScalingAttack | Round 15 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "ScalingAttack | Round 16 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "ScalingAttack | Round 17 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "ScalingAttack | Round 18 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "ScalingAttack | Round 19 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "ScalingAttack | Round 20 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "\n",
      "Results saved to: D:/August-Thesis/FL-IDS-Surveillance/notebooks/results/poisoning_scaling_attack.csv\n"
     ]
    }
   ],
   "source": [
    "results_scaling_attack = run_scaling_attack_simulation(\n",
    "    global_model,\n",
    "    client_dfs,\n",
    "    minmax_scaler,\n",
    "    feature_names,\n",
    "    X_test_scaled,\n",
    "    y_true\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6307873a-7140-45e8-abb8-75d646110222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sybil_attack_simulation(\n",
    "    global_model,\n",
    "    client_dfs,\n",
    "    scaler,\n",
    "    feature_names,\n",
    "    X_test_scaled,\n",
    "    y_true,\n",
    "    base_malicious_client=\"client_3\",\n",
    "    num_sybil=3,\n",
    "    attack_round=6,\n",
    "    scale_factor=10.0,\n",
    "    threshold=0.000639,\n",
    "    save_path=\"D:/August-Thesis/FL-IDS-Surveillance/notebooks/results/poisoning_sybil_attack.csv\"\n",
    "):\n",
    "    model_copy = clone_model(global_model)\n",
    "    model_copy.set_weights(global_model.get_weights())\n",
    "    model_copy.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "\n",
    "    f1_list, precision_list, recall_list = [], [], []\n",
    "    fp_rates, fn_rates = [], []\n",
    "\n",
    "    client_ids = list(client_dfs.keys())\n",
    "    sybil_ids = [f\"sybil_{i}\" for i in range(num_sybil)]\n",
    "\n",
    "    for round_num in range(1, 21):\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in client_ids:\n",
    "            df = client_dfs[cid]\n",
    "            X_local = df[feature_names].astype(float)\n",
    "            X_scaled = scaler.transform(X_local)\n",
    "\n",
    "            local_model = clone_model(model_copy)\n",
    "            local_model.set_weights(model_copy.get_weights())\n",
    "            local_model.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "            local_model.fit(X_scaled, X_scaled, epochs=1, batch_size=256, verbose=0)\n",
    "\n",
    "            weights = local_model.get_weights()\n",
    "\n",
    "            if cid == base_malicious_client and round_num >= attack_round:\n",
    "                poisoned_weights = scaling_attack(model_copy.get_weights(), weights, scale_factor=scale_factor)\n",
    "                for _ in sybil_ids:\n",
    "                    local_weights.append(poisoned_weights)\n",
    "            else:\n",
    "                local_weights.append(weights)\n",
    "\n",
    "        averaged_weights = [\n",
    "            np.mean([w[i] for w in local_weights], axis=0)\n",
    "            for i in range(len(local_weights[0]))\n",
    "        ]\n",
    "        model_copy.set_weights(averaged_weights)\n",
    "\n",
    "        preds = model_copy.predict(X_test_scaled, verbose=0)\n",
    "        recon_errors = np.mean(np.square(X_test_scaled - preds), axis=1)\n",
    "        y_pred = (recon_errors > threshold).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred)\n",
    "        rec = recall_score(y_true, y_pred)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        fp_rate = fp / (fp + tn + 1e-6)\n",
    "        fn_rate = fn / (fn + tp + 1e-6)\n",
    "\n",
    "        print(f\"SybilAttack | Round {round_num:02d} | F1: {f1:.4f} | P: {prec:.4f} | R: {rec:.4f} | FP Rate: {fp_rate:.4f} | FN Rate: {fn_rate:.4f}\")\n",
    "\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        fp_rates.append(fp_rate)\n",
    "        fn_rates.append(fn_rate)\n",
    "\n",
    "    df_out = pd.DataFrame({\n",
    "        \"Round\": list(range(1, 21)),\n",
    "        \"F1\": f1_list,\n",
    "        \"Precision\": precision_list,\n",
    "        \"Recall\": recall_list,\n",
    "        \"FP Rate\": fp_rates,\n",
    "        \"FN Rate\": fn_rates\n",
    "    })\n",
    "\n",
    "    df_out.to_csv(save_path, index=False)\n",
    "    print(f\"\\nTheResults saved to: {save_path}\")\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d30a46f-faa8-47c3-8bb5-1ad67791a300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SybilAttack | Round 01 | F1: 0.8368 | P: 0.9878 | R: 0.7258 | FP Rate: 0.0034 | FN Rate: 0.2742\n",
      "SybilAttack | Round 02 | F1: 0.8363 | P: 0.9879 | R: 0.7250 | FP Rate: 0.0033 | FN Rate: 0.2750\n",
      "SybilAttack | Round 03 | F1: 0.8356 | P: 0.9879 | R: 0.7240 | FP Rate: 0.0033 | FN Rate: 0.2760\n",
      "SybilAttack | Round 04 | F1: 0.8350 | P: 0.9879 | R: 0.7231 | FP Rate: 0.0033 | FN Rate: 0.2769\n",
      "SybilAttack | Round 05 | F1: 0.8348 | P: 0.9879 | R: 0.7227 | FP Rate: 0.0033 | FN Rate: 0.2773\n",
      "SybilAttack | Round 06 | F1: 0.8263 | P: 0.9876 | R: 0.7102 | FP Rate: 0.0033 | FN Rate: 0.2898\n",
      "SybilAttack | Round 07 | F1: 0.6929 | P: 0.5974 | R: 0.8248 | FP Rate: 0.2075 | FN Rate: 0.1752\n",
      "SybilAttack | Round 08 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "SybilAttack | Round 09 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "SybilAttack | Round 10 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "SybilAttack | Round 11 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "SybilAttack | Round 12 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "SybilAttack | Round 13 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "SybilAttack | Round 14 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "SybilAttack | Round 15 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "SybilAttack | Round 16 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "SybilAttack | Round 17 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "SybilAttack | Round 18 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "SybilAttack | Round 19 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "SybilAttack | Round 20 | F1: 0.4275 | P: 0.2719 | R: 1.0000 | FP Rate: 1.0000 | FN Rate: 0.0000\n",
      "\n",
      "TheResults saved to: D:/August-Thesis/FL-IDS-Surveillance/notebooks/results/poisoning_sybil_attack.csv\n"
     ]
    }
   ],
   "source": [
    "results_sybil_attack = run_sybil_attack_simulation(\n",
    "    global_model,\n",
    "    client_dfs,\n",
    "    minmax_scaler,\n",
    "    feature_names,\n",
    "    X_test_scaled,\n",
    "    y_true\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1de2c6d-bdb3-49e1-988b-aad41831ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_adaptive_gradient_attack(\n",
    "    global_model,\n",
    "    client_dfs,\n",
    "    scaler,\n",
    "    feature_names,\n",
    "    X_test_scaled,\n",
    "    y_true,\n",
    "    attacker_id=\"client_3\",\n",
    "    attack_round=6,\n",
    "    learning_rate=5.0,\n",
    "    noise_std=0.0,\n",
    "    threshold=0.000639,\n",
    "    save_path=\"D:/August-Thesis/FL-IDS-Surveillance/notebooks/results/poisoning_adaptive_gradient_attack.csv\"\n",
    "):\n",
    "    model_copy = clone_model(global_model)\n",
    "    model_copy.set_weights(global_model.get_weights())\n",
    "    model_copy.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "\n",
    "    f1_list, precision_list, recall_list = [], [], []\n",
    "    fp_rates, fn_rates = [], []\n",
    "\n",
    "    client_ids = list(client_dfs.keys())\n",
    "\n",
    "    for round_num in range(1, 21):\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in client_ids:\n",
    "            df = client_dfs[cid]\n",
    "            X_local = df[feature_names].astype(float)\n",
    "            X_scaled = scaler.transform(X_local)\n",
    "\n",
    "            local_model = clone_model(model_copy)\n",
    "            local_model.set_weights(model_copy.get_weights())\n",
    "            local_model.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "            local_model.fit(X_scaled, X_scaled, epochs=1, batch_size=256, verbose=0)\n",
    "\n",
    "            weights = local_model.get_weights()\n",
    "\n",
    "            if cid == attacker_id and round_num >= attack_round:\n",
    "                poisoned_weights = adaptive_gradient_attack(\n",
    "                    global_weights=model_copy.get_weights(),\n",
    "                    local_weights=weights,\n",
    "                    learning_rate=learning_rate,\n",
    "                    noise_std=noise_std\n",
    "                )\n",
    "                local_weights.append(poisoned_weights)\n",
    "            else:\n",
    "                local_weights.append(weights)\n",
    "\n",
    "        averaged_weights = [\n",
    "            np.mean([w[i] for w in local_weights], axis=0)\n",
    "            for i in range(len(local_weights[0]))\n",
    "        ]\n",
    "        model_copy.set_weights(averaged_weights)\n",
    "\n",
    "        preds = model_copy.predict(X_test_scaled, verbose=0)\n",
    "        recon_errors = np.mean(np.square(X_test_scaled - preds), axis=1)\n",
    "        y_pred = (recon_errors > threshold).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred)\n",
    "        rec = recall_score(y_true, y_pred)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        fp_rate = fp / (fp + tn + 1e-6)\n",
    "        fn_rate = fn / (fn + tp + 1e-6)\n",
    "\n",
    "        print(f\"AdaptiveGradAttack | Round {round_num:02d} | F1: {f1:.4f} | P: {prec:.4f} | R: {rec:.4f} | FP Rate: {fp_rate:.4f} | FN Rate: {fn_rate:.4f}\")\n",
    "\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        fp_rates.append(fp_rate)\n",
    "        fn_rates.append(fn_rate)\n",
    "\n",
    "    df_out = pd.DataFrame({\n",
    "        \"Round\": list(range(1, 21)),\n",
    "        \"F1\": f1_list,\n",
    "        \"Precision\": precision_list,\n",
    "        \"Recall\": recall_list,\n",
    "        \"FP Rate\": fp_rates,\n",
    "        \"FN Rate\": fn_rates\n",
    "    })\n",
    "\n",
    "    df_out.to_csv(save_path, index=False)\n",
    "    print(f\"\\nResults saved to: {save_path}\")\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19d6d8b7-bcc5-4939-b268-821b2d750eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaptiveGradAttack | Round 01 | F1: 0.8368 | P: 0.9878 | R: 0.7258 | FP Rate: 0.0034 | FN Rate: 0.2742\n",
      "AdaptiveGradAttack | Round 02 | F1: 0.8363 | P: 0.9879 | R: 0.7250 | FP Rate: 0.0033 | FN Rate: 0.2750\n",
      "AdaptiveGradAttack | Round 03 | F1: 0.8356 | P: 0.9879 | R: 0.7240 | FP Rate: 0.0033 | FN Rate: 0.2760\n",
      "AdaptiveGradAttack | Round 04 | F1: 0.8350 | P: 0.9879 | R: 0.7231 | FP Rate: 0.0033 | FN Rate: 0.2769\n",
      "AdaptiveGradAttack | Round 05 | F1: 0.8348 | P: 0.9879 | R: 0.7227 | FP Rate: 0.0033 | FN Rate: 0.2773\n",
      "AdaptiveGradAttack | Round 06 | F1: 0.8330 | P: 0.9879 | R: 0.7201 | FP Rate: 0.0033 | FN Rate: 0.2799\n",
      "AdaptiveGradAttack | Round 07 | F1: 0.8333 | P: 0.9877 | R: 0.7207 | FP Rate: 0.0034 | FN Rate: 0.2793\n",
      "AdaptiveGradAttack | Round 08 | F1: 0.8339 | P: 0.9876 | R: 0.7216 | FP Rate: 0.0034 | FN Rate: 0.2784\n",
      "AdaptiveGradAttack | Round 09 | F1: 0.8264 | P: 0.9878 | R: 0.7103 | FP Rate: 0.0033 | FN Rate: 0.2897\n",
      "AdaptiveGradAttack | Round 10 | F1: 0.8308 | P: 0.9877 | R: 0.7169 | FP Rate: 0.0033 | FN Rate: 0.2831\n",
      "AdaptiveGradAttack | Round 11 | F1: 0.8264 | P: 0.9880 | R: 0.7102 | FP Rate: 0.0032 | FN Rate: 0.2898\n",
      "AdaptiveGradAttack | Round 12 | F1: 0.8282 | P: 0.9881 | R: 0.7129 | FP Rate: 0.0032 | FN Rate: 0.2871\n",
      "AdaptiveGradAttack | Round 13 | F1: 0.8264 | P: 0.9881 | R: 0.7101 | FP Rate: 0.0032 | FN Rate: 0.2899\n",
      "AdaptiveGradAttack | Round 14 | F1: 0.8269 | P: 0.9884 | R: 0.7107 | FP Rate: 0.0031 | FN Rate: 0.2893\n",
      "AdaptiveGradAttack | Round 15 | F1: 0.8277 | P: 0.9890 | R: 0.7116 | FP Rate: 0.0030 | FN Rate: 0.2884\n",
      "AdaptiveGradAttack | Round 16 | F1: 0.8273 | P: 0.9885 | R: 0.7113 | FP Rate: 0.0031 | FN Rate: 0.2887\n",
      "AdaptiveGradAttack | Round 17 | F1: 0.8285 | P: 0.9893 | R: 0.7127 | FP Rate: 0.0029 | FN Rate: 0.2873\n",
      "AdaptiveGradAttack | Round 18 | F1: 0.8280 | P: 0.9892 | R: 0.7120 | FP Rate: 0.0029 | FN Rate: 0.2880\n",
      "AdaptiveGradAttack | Round 19 | F1: 0.8289 | P: 0.9893 | R: 0.7133 | FP Rate: 0.0029 | FN Rate: 0.2867\n",
      "AdaptiveGradAttack | Round 20 | F1: 0.8295 | P: 0.9894 | R: 0.7141 | FP Rate: 0.0029 | FN Rate: 0.2859\n",
      "\n",
      "Results saved to: D:/August-Thesis/FL-IDS-Surveillance/notebooks/results/poisoning_adaptive_gradient_attack.csv\n"
     ]
    }
   ],
   "source": [
    "adaptive_results = run_adaptive_gradient_attack(\n",
    "    global_model,\n",
    "    client_dfs,\n",
    "    minmax_scaler,\n",
    "    feature_names,\n",
    "    X_test_scaled,\n",
    "    y_true\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7393f2-74c5-4a9f-b823-f03a3119d831",
   "metadata": {},
   "source": [
    "## Summary: Advanced Model Poisoning Attacks (Autoencoder-based FL-IDS)\n",
    "\n",
    "This section summarizes the impact of four advanced model poisoning attacks on the Federated Autoencoder Intrusion Detection System.\n",
    "\n",
    "| **Attack Type**       | **Malicious Client(s)** | **Peak FP Rate** | **Peak FN Rate** | **Lowest F1 Score** | **Notes** |\n",
    "|-----------------------|-------------------------|------------------|------------------|---------------------|-----------|\n",
    "| **Sign Flipping**     | `client_3`              | 0.0034           | 0.2832           | ~0.8310             | Very mild impact, surprising resilience, possibly due to low magnitude or model saturation |\n",
    "| **Scaling Attack**    | `client_3`              | 1.0000           | 0.0000           | **0.4275**          | Catastrophic collapse, full failure from Round 8 onward |\n",
    "| **Sybil Attack**      | `client_3` + 2 Sybils   | 1.0000           | 0.0000           | **0.4275**          | Immediate collapse after Round 7, behavior identical to scaling |\n",
    "| **Adaptive Gradient** | `client_3`              | 0.0034           | 0.2899           | ~0.8264             | Steady drift, moderate degradation, stealthy and hard to detect |\n",
    "\n",
    "---\n",
    "\n",
    "### Observations:\n",
    "- **Scaling and Sybil Attacks** are the most dangerous — causing full misclassification behavior and 100% false positives.\n",
    "- **Adaptive Gradient** is subtle and harder to detect, but still deteriorates performance gradually.\n",
    "- **Sign Flipping** had limited impact in this context — possibly due to lower learning momentum or robust initial state.\n",
    "\n",
    "---\n",
    "\n",
    "Next, we proceed to implement **defense strategies**, starting with:\n",
    "- **Performance Feedback Aggregation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be89860a-d546-4544-a838-9db94e855c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_aggregation(client_weights_list):\n",
    "    \"\"\"\n",
    "    Performs element-wise median aggregation across client weights.\n",
    "    \n",
    "    Args:\n",
    "        client_weights_list: List of weight lists from all clients\n",
    "    Returns:\n",
    "        aggregated_weights: List of aggregated weights (same shape as client_weights)\n",
    "    \"\"\"\n",
    "    num_layers = len(client_weights_list[0])\n",
    "    aggregated_weights = []\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        # Stack weights for this layer from all clients\n",
    "        stacked_layer_weights = np.stack([client[layer_idx] for client in client_weights_list], axis=0)\n",
    "        # Compute median across clients (axis=0)\n",
    "        layer_median = np.median(stacked_layer_weights, axis=0)\n",
    "        aggregated_weights.append(layer_median)\n",
    "\n",
    "    return aggregated_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c99bf66-6cbb-4086-877c-a5d233700cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling_MedianDef | Round 01 | F1: 0.8372 | P: 0.9878 | R: 0.7264 | FP Rate: 0.0024 | FN Rate: 0.0744\n",
      "Scaling_MedianDef | Round 02 | F1: 0.8376 | P: 0.9880 | R: 0.7270 | FP Rate: 0.0024 | FN Rate: 0.0742\n",
      "Scaling_MedianDef | Round 03 | F1: 0.8362 | P: 0.9879 | R: 0.7249 | FP Rate: 0.0024 | FN Rate: 0.0748\n",
      "Scaling_MedianDef | Round 04 | F1: 0.8349 | P: 0.9879 | R: 0.7229 | FP Rate: 0.0024 | FN Rate: 0.0753\n",
      "Scaling_MedianDef | Round 05 | F1: 0.8350 | P: 0.9879 | R: 0.7231 | FP Rate: 0.0024 | FN Rate: 0.0753\n",
      "Scaling_MedianDef | Round 06 | F1: 0.8350 | P: 0.9879 | R: 0.7231 | FP Rate: 0.0024 | FN Rate: 0.0753\n",
      "Scaling_MedianDef | Round 07 | F1: 0.8350 | P: 0.9884 | R: 0.7229 | FP Rate: 0.0023 | FN Rate: 0.0753\n",
      "Scaling_MedianDef | Round 08 | F1: 0.8322 | P: 0.9883 | R: 0.7186 | FP Rate: 0.0023 | FN Rate: 0.0765\n",
      "Scaling_MedianDef | Round 09 | F1: 0.8302 | P: 0.9885 | R: 0.7157 | FP Rate: 0.0023 | FN Rate: 0.0773\n",
      "Scaling_MedianDef | Round 10 | F1: 0.8286 | P: 0.9885 | R: 0.7132 | FP Rate: 0.0022 | FN Rate: 0.0780\n",
      "Scaling_MedianDef | Round 11 | F1: 0.8286 | P: 0.9886 | R: 0.7132 | FP Rate: 0.0022 | FN Rate: 0.0780\n",
      "Scaling_MedianDef | Round 12 | F1: 0.8286 | P: 0.9886 | R: 0.7132 | FP Rate: 0.0022 | FN Rate: 0.0780\n",
      "Scaling_MedianDef | Round 13 | F1: 0.8272 | P: 0.9885 | R: 0.7111 | FP Rate: 0.0022 | FN Rate: 0.0785\n",
      "Scaling_MedianDef | Round 14 | F1: 0.8275 | P: 0.9885 | R: 0.7116 | FP Rate: 0.0022 | FN Rate: 0.0784\n",
      "Scaling_MedianDef | Round 15 | F1: 0.8255 | P: 0.9885 | R: 0.7086 | FP Rate: 0.0022 | FN Rate: 0.0792\n",
      "Scaling_MedianDef | Round 16 | F1: 0.8262 | P: 0.9885 | R: 0.7096 | FP Rate: 0.0022 | FN Rate: 0.0789\n",
      "Scaling_MedianDef | Round 17 | F1: 0.8255 | P: 0.9885 | R: 0.7086 | FP Rate: 0.0022 | FN Rate: 0.0792\n",
      "Scaling_MedianDef | Round 18 | F1: 0.8256 | P: 0.9885 | R: 0.7087 | FP Rate: 0.0022 | FN Rate: 0.0792\n",
      "Scaling_MedianDef | Round 19 | F1: 0.8261 | P: 0.9885 | R: 0.7095 | FP Rate: 0.0022 | FN Rate: 0.0790\n",
      "Scaling_MedianDef | Round 20 | F1: 0.8253 | P: 0.9885 | R: 0.7084 | FP Rate: 0.0022 | FN Rate: 0.0793\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattack_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Round \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mround_num\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | P: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | R: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | FP Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfp_rate\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | FN Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn_rate\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     65\u001b[39m df_metrics = pd.DataFrame(metrics_log)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m results_path = os.path.join(\u001b[43mresults_dir\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mdefense_median_scaling_attack.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m df_metrics.to_csv(results_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     68\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResults saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'results_dir' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "NUM_ROUNDS = 20\n",
    "malicious_client_id = \"client_3\"\n",
    "attack_type = \"Scaling_MedianDef\"\n",
    "scaling_factor = 100  # strong attack\n",
    "threshold = 0.000639  \n",
    "results_path = \"D:/August-Thesis/FL-IDS-Surveillance/notebooks/results/defense_median_scaling_attack.csv\"\n",
    "\n",
    "# Initialize a fresh global model\n",
    "global_model_defended = clone_model(global_model)\n",
    "global_model_defended.set_weights(global_model.get_weights())\n",
    "global_model_defended.compile(optimizer='adam', loss=MeanSquaredError())\n",
    "\n",
    "metrics_log = []\n",
    "\n",
    "for round_num in range(1, NUM_ROUNDS + 1):\n",
    "    collected_weights = []\n",
    "\n",
    "    for client_id, client_data in client_dfs.items():\n",
    "        local_model = clone_model(global_model_defended)\n",
    "        local_model.set_weights(global_model_defended.get_weights())\n",
    "        local_model.compile(optimizer='adam', loss=MeanSquaredError())\n",
    "\n",
    "        X_scaled = minmax_scaler.transform(client_data[feature_cols])\n",
    "        local_model.fit(X_scaled, X_scaled, epochs=1, batch_size=256, verbose=0)\n",
    "\n",
    "        local_weights = local_model.get_weights()\n",
    "\n",
    "        # Apply scaling attack on malicious client\n",
    "        if client_id == malicious_client_id:\n",
    "            local_weights = [w + scaling_factor * (w - gw) \n",
    "                             for w, gw in zip(local_weights, global_model_defended.get_weights())]\n",
    "\n",
    "        collected_weights.append(local_weights)\n",
    "\n",
    "    # Median Aggregation\n",
    "    aggregated_weights = median_aggregation(collected_weights)\n",
    "    global_model_defended.set_weights(aggregated_weights)\n",
    "\n",
    "    # Evaluate\n",
    "    reconstructed = global_model_defended.predict(X_test_scaled, verbose=0)\n",
    "    reconstruction_errors = np.mean(np.square(X_test_scaled - reconstructed), axis=1)\n",
    "    y_pred = (reconstruction_errors > threshold).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    p = precision_score(y_true, y_pred)\n",
    "    r = recall_score(y_true, y_pred)\n",
    "\n",
    "    fp_rate = np.mean((y_pred == 1) & (y_true == 0))\n",
    "    fn_rate = np.mean((y_pred == 0) & (y_true == 1))\n",
    "\n",
    "    metrics_log.append({\n",
    "        \"Round\": round_num,\n",
    "        \"F1\": f1,\n",
    "        \"Precision\": p,\n",
    "        \"Recall\": r,\n",
    "        \"FP Rate\": fp_rate,\n",
    "        \"FN Rate\": fn_rate\n",
    "    })\n",
    "\n",
    "    print(f\"{attack_type} | Round {round_num:02d} | F1: {f1:.4f} | P: {p:.4f} | R: {r:.4f} | FP Rate: {fp_rate:.4f} | FN Rate: {fn_rate:.4f}\")\n",
    "\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_log)\n",
    "results_path = os.path.join(results_dir, \"defense_median_scaling_attack.csv\")\n",
    "df_metrics.to_csv(results_path, index=False)\n",
    "print(f\"\\nResults saved to: {results_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0847200f-29e9-4ebf-aed6-1ec7239cb184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to: D:/August-Thesis/FL-IDS-Surveillance/notebooks/results/defense_median_scaling_attack.csv\n"
     ]
    }
   ],
   "source": [
    "# Savint eh results\n",
    "results_path = \"D:/August-Thesis/FL-IDS-Surveillance/notebooks/results/defense_median_scaling_attack.csv\"\n",
    "df_metrics = pd.DataFrame(metrics_log)\n",
    "df_metrics.to_csv(results_path, index=False)\n",
    "print(f\"\\nResults saved to: {results_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f33e51f2-1eab-4eb6-8c5a-f5feb88a821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASSEM\\AppData\\Local\\Temp\\ipykernel_18956\\3755555227.py:22: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_df = pd.read_csv(test_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8372996201343141\n",
      "Precision: 0.987711770830047\n",
      "Recall: 0.7266437993935586\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === Paths ===\n",
    "base_path = \"D:/August-Thesis/FL-IDS-Surveillance\"\n",
    "results_dir = os.path.join(base_path, \"notebooks/results\")\n",
    "model_path = os.path.join(results_dir, \"models/unsupervised/federated/final_federated_autoencoder_20rounds.h5\")\n",
    "scaler_path = os.path.join(results_dir, \"scalers/minmax_scaler_client_3.pkl\")\n",
    "test_path = os.path.join(base_path, \"data/processed/surv_unsupervised/test_mixed.csv\")\n",
    "\n",
    "# === Load model and scaler\n",
    "global_model = load_model(model_path, compile=False)\n",
    "global_model.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "minmax_scaler = joblib.load(scaler_path)\n",
    "\n",
    "# === Loading test set\n",
    "test_df = pd.read_csv(test_path)\n",
    "feature_cols = list(minmax_scaler.feature_names_in_)\n",
    "X_test_scaled = minmax_scaler.transform(test_df[feature_cols])\n",
    "y_true = test_df[\"Attack_label\"].values\n",
    "\n",
    "# === Evaluate the baseline\n",
    "reconstructed = global_model.predict(X_test_scaled, verbose=0)\n",
    "reconstruction_errors = np.mean(np.square(X_test_scaled - reconstructed), axis=1)\n",
    "threshold = 0.000639  # validated threshold\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)\n",
    "\n",
    "print(\"F1:\", f1_score(y_true, y_pred))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c10bcad-7bed-4377-a6f4-82a277246c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krum_Scaling | Round 01 | F1: 0.8385 | P: 0.9878 | R: 0.7284 | FP Rate: 0.0024 | FN Rate: 0.0738\n",
      "Krum_Scaling | Round 02 | F1: 0.8379 | P: 0.9879 | R: 0.7275 | FP Rate: 0.0024 | FN Rate: 0.0741\n",
      "Krum_Scaling | Round 03 | F1: 0.8383 | P: 0.9880 | R: 0.7280 | FP Rate: 0.0024 | FN Rate: 0.0739\n",
      "Krum_Scaling | Round 04 | F1: 0.8373 | P: 0.9880 | R: 0.7265 | FP Rate: 0.0024 | FN Rate: 0.0743\n",
      "Krum_Scaling | Round 05 | F1: 0.8367 | P: 0.9880 | R: 0.7256 | FP Rate: 0.0024 | FN Rate: 0.0746\n",
      "Krum_Scaling | Round 06 | F1: 0.8369 | P: 0.9880 | R: 0.7259 | FP Rate: 0.0024 | FN Rate: 0.0745\n",
      "Krum_Scaling | Round 07 | F1: 0.8366 | P: 0.9880 | R: 0.7254 | FP Rate: 0.0024 | FN Rate: 0.0746\n",
      "Krum_Scaling | Round 08 | F1: 0.8359 | P: 0.9879 | R: 0.7245 | FP Rate: 0.0024 | FN Rate: 0.0749\n",
      "Krum_Scaling | Round 09 | F1: 0.8339 | P: 0.9884 | R: 0.7212 | FP Rate: 0.0023 | FN Rate: 0.0758\n",
      "Krum_Scaling | Round 10 | F1: 0.8323 | P: 0.9884 | R: 0.7188 | FP Rate: 0.0023 | FN Rate: 0.0765\n",
      "Krum_Scaling | Round 11 | F1: 0.8323 | P: 0.9886 | R: 0.7188 | FP Rate: 0.0023 | FN Rate: 0.0765\n",
      "Krum_Scaling | Round 12 | F1: 0.8287 | P: 0.9886 | R: 0.7133 | FP Rate: 0.0022 | FN Rate: 0.0779\n",
      "Krum_Scaling | Round 13 | F1: 0.8275 | P: 0.9885 | R: 0.7116 | FP Rate: 0.0022 | FN Rate: 0.0784\n",
      "Krum_Scaling | Round 14 | F1: 0.8276 | P: 0.9885 | R: 0.7117 | FP Rate: 0.0022 | FN Rate: 0.0784\n",
      "Krum_Scaling | Round 15 | F1: 0.8301 | P: 0.9886 | R: 0.7154 | FP Rate: 0.0022 | FN Rate: 0.0774\n",
      "Krum_Scaling | Round 16 | F1: 0.8264 | P: 0.9885 | R: 0.7100 | FP Rate: 0.0022 | FN Rate: 0.0788\n",
      "Krum_Scaling | Round 17 | F1: 0.8269 | P: 0.9885 | R: 0.7106 | FP Rate: 0.0022 | FN Rate: 0.0787\n",
      "Krum_Scaling | Round 18 | F1: 0.8255 | P: 0.9885 | R: 0.7086 | FP Rate: 0.0022 | FN Rate: 0.0792\n",
      "Krum_Scaling | Round 19 | F1: 0.8265 | P: 0.9885 | R: 0.7101 | FP Rate: 0.0022 | FN Rate: 0.0788\n",
      "Krum_Scaling | Round 20 | F1: 0.8272 | P: 0.9885 | R: 0.7112 | FP Rate: 0.0022 | FN Rate: 0.0785\n",
      "\n",
      "Results saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks/results\\defense_krum_scaling_attack.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# === Krum Aggregation ===\n",
    "def krum_aggregation(weights_list, f):\n",
    "    n = len(weights_list)\n",
    "    scores = []\n",
    "    for i in range(n):\n",
    "        distances = []\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                dist = sum(np.sum((w1 - w2) ** 2) for w1, w2 in zip(weights_list[i], weights_list[j]))\n",
    "                distances.append(dist)\n",
    "        distances.sort()\n",
    "        score = sum(distances[:n - f - 2])\n",
    "        scores.append(score)\n",
    "    selected_idx = np.argmin(scores)\n",
    "    return weights_list[selected_idx]\n",
    "\n",
    "# === Scaling Attack ===\n",
    "def scaling_attack(global_weights, local_weights, scale_factor=10.0):\n",
    "    return [gw + scale_factor * (lw - gw) for gw, lw in zip(global_weights, local_weights)]\n",
    "\n",
    "# === Simulation ===\n",
    "NUM_ROUNDS = 20\n",
    "malicious_client_id = \"client_3\"\n",
    "attack_start_round = 6\n",
    "threshold = 0.000639\n",
    "f = 1  # 1 attacker\n",
    "\n",
    "global_model_krum = clone_model(global_model)\n",
    "global_model_krum.set_weights(global_model.get_weights())\n",
    "global_model_krum.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "\n",
    "metrics_log = []\n",
    "\n",
    "for round_num in range(1, NUM_ROUNDS + 1):\n",
    "    collected_weights = []\n",
    "\n",
    "    for cid in client_ids:\n",
    "        local_model = clone_model(global_model_krum)\n",
    "        local_model.set_weights(global_model_krum.get_weights())\n",
    "        local_model.compile(optimizer=\"adam\", loss=MeanSquaredError())\n",
    "\n",
    "        X_scaled = minmax_scaler.transform(client_dfs[cid][feature_cols]) \n",
    "        local_model.fit(X_scaled, X_scaled, epochs=1, batch_size=256, verbose=0)\n",
    "        local_weights = local_model.get_weights()\n",
    "\n",
    "        if cid == malicious_client_id and round_num >= attack_start_round:\n",
    "            local_weights = scaling_attack(global_model_krum.get_weights(), local_weights)\n",
    "\n",
    "        collected_weights.append(local_weights)\n",
    "\n",
    "    aggregated_weights = krum_aggregation(collected_weights, f if round_num >= attack_start_round else 0)\n",
    "    global_model_krum.set_weights(aggregated_weights)\n",
    "\n",
    "    # Evaluate\n",
    "    preds = global_model_krum.predict(X_test_scaled, verbose=0)\n",
    "    errors = np.mean(np.square(X_test_scaled - preds), axis=1)\n",
    "    y_pred = (errors > threshold).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    p = precision_score(y_true, y_pred)\n",
    "    r = recall_score(y_true, y_pred)\n",
    "    fp_rate = np.mean((y_true == 0) & (y_pred == 1))\n",
    "    fn_rate = np.mean((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    print(f\"Krum_Scaling | Round {round_num:02d} | F1: {f1:.4f} | P: {p:.4f} | R: {r:.4f} | FP Rate: {fp_rate:.4f} | FN Rate: {fn_rate:.4f}\")\n",
    "\n",
    "    metrics_log.append({\n",
    "        \"Round\": round_num, \"F1\": f1, \"Precision\": p, \"Recall\": r,\n",
    "        \"FP Rate\": fp_rate, \"FN Rate\": fn_rate\n",
    "    })\n",
    "\n",
    "# Save results\n",
    "df_metrics = pd.DataFrame(metrics_log)\n",
    "save_path = os.path.join(results_dir, \"defense_krum_scaling_attack.csv\")\n",
    "df_metrics.to_csv(save_path, index=False)\n",
    "print(f\"\\nResults saved to: {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AR-iForest)",
   "language": "python",
   "name": "ar_iforest_fl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
