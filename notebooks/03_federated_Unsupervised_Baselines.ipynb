{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930a7240-f5b4-41a4-8acd-7bd305c52512",
   "metadata": {},
   "source": [
    "# Notebook 03: Federated Unsupervised Baselines (IF & AE)\n",
    "\n",
    "**Goal.** Build and evaluate unsupervised baselines in a federated setting for IIoT surveillance data. We compare (a) centralized/global models, (b) client-local models, and (c) a simple Federated Averaging (FedAvg) Autoencoder, all evaluated on a shared mixed test set.\n",
    "\n",
    "**What this notebook does**\n",
    "- Load each client’s **normal-only** training data and a centralized **mixed** test set.\n",
    "- Evaluate a **pre-trained global Isolation Forest** on each client’s data (diagnostic baseline).\n",
    "- Train **local Isolation Forests** per client and evaluate all of them on the same mixed test set.\n",
    "- Train **local Autoencoders** per client (with MinMax scaling); pick a **threshold** on reconstruction errors to convert to binary labels; evaluate on the mixed test set.\n",
    "- Construct a **federated Autoencoder (FedAvg)** by averaging client weights; evaluate it on the mixed test set.\n",
    "- Record metrics: Accuracy, Precision, Recall, F1, FP/FN counts, FP/FN rates, model size, and inference time.\n",
    "\n",
    "**Scope / assumptions**\n",
    "- Data paths are repo-relative; raw/processed data remain local and git-ignored.\n",
    "- This notebook **does not** alter raw data; it trains/evaluates models and writes metrics/models to `results/`.\n",
    "- Reproducibility: fixed random seeds; same preprocessing per client (StandardScaler for IF, MinMaxScaler for AE).\n",
    "- Threshold selection for AEs is performed on validation logic described in the code and then fixed for reporting.\n",
    "\n",
    "**Outputs (for later use)**\n",
    "- CSVs with per-client and federated results (unsupervised IF and AE).\n",
    "- Saved models (local IF/AE, federated AE) and any thresholds used for AE decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7daf33e-cfcb-4ac9-a0c4-b6820ac10828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_1's shape is: (323128, 42)\n",
      "client_2's shape is: (323128, 42)\n",
      "client_3's shape is: (323128, 42)\n",
      "client_4's shape is: (323128, 42)\n",
      "client_5's shape is: (323131, 42)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#Base Path for the federetad client data\n",
    "base_path = r\"D:\\August-Thesis\\FL-IDS-Surveillance\\data\\processed\\federated\\unsupervised\"\n",
    "\n",
    "#Loading the client dataset\n",
    "client_data = {}\n",
    "for i in range (1,6):\n",
    "    client_id = f\"client_{i}\"\n",
    "    file_path = os.path.join(base_path, client_id, \"train.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    client_data[client_id] = df\n",
    "    print(f\"{client_id}'s shape is: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee0a903-de19-4d8f-a835-8640b2d27fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaler Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "#Loading the training data\n",
    "train_path = r\"D:\\August-Thesis\\FL-IDS-Surveillance\\data\\processed\\surv_unsupervised\\train_normal_only.csv\"\n",
    "train_df = pd.read_csv(train_path, low_memory = False)\n",
    "\n",
    "#Dropping the label and the httprequest method feature as well\n",
    "X_train = train_df.drop(columns = ['Attack_label','http.request.method'], errors=\"ignore\")\n",
    "X_train = X_train.select_dtypes(include=\"number\")\n",
    "\n",
    "#Fit the scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "scaler_save_path = r\"results\\scalers\\std_scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_save_path)\n",
    "print(\"Standard Scaler Saved Successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad5544-e5d3-46c6-a5bb-1c0ba1b2c3b0",
   "metadata": {},
   "source": [
    "### Part1: Evaluate Global Isolation Forest Model on Each Client\n",
    "\n",
    "In this step, we evaluate the pre-trained **global Isolation Forest model** on each client’s local dataset.  \n",
    "This allows us to assess **how well the centralized model generalizes across the diverse data distributions** observed by clients.\n",
    "\n",
    "#### Purpose:\n",
    "- Establish a sort of baseline performance for the global model on decentralized data.\n",
    "- Identify how well the global model detects anomalies across different client datasets.\n",
    "\n",
    "#### Evaluation Plan:\n",
    "- Use the previously trained global model: **`isolation_forest_best.pkl`**.\n",
    "- For each client:\n",
    "  - Drop the `Attack_label` column before inference.\n",
    "  - The model outputs:\n",
    "    - `-1`=> anomaly (mapped to **1 = attack**)  \n",
    "    - `1` => normal (mapped to **0 = no attack**)  \n",
    "  - Compare predictions against the true labels to compute:\n",
    "    - **Accuracy**, **Precision**, **Recall**, **F1 Score**\n",
    "    - **False Positives (FP)**, **False Negatives (FN)**, **FP Rate**, **FN Rate**\n",
    "\n",
    "This step provides a baseline understanding of how well the **global Isolation Forest** performs on each client’s local dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a3b4066-e0b2-4218-9056-cbb23eb048a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>FP Rate (%)</th>\n",
       "      <th>FN Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>client_1</th>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12904.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9935</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_2</th>\n",
       "      <td>0.9597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0281</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_3</th>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12881.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9863</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_4</th>\n",
       "      <td>0.9603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12833.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9715</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_5</th>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12992.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0207</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy  Precision  Recall  F1 Score  False Positives  \\\n",
       "client_1    0.9601        0.0     0.0       0.0          12904.0   \n",
       "client_2    0.9597        0.0     0.0       0.0          13016.0   \n",
       "client_3    0.9601        0.0     0.0       0.0          12881.0   \n",
       "client_4    0.9603        0.0     0.0       0.0          12833.0   \n",
       "client_5    0.9598        0.0     0.0       0.0          12992.0   \n",
       "\n",
       "          False Negatives  FP Rate (%)  FN Rate (%)  \n",
       "client_1              0.0       3.9935          0.0  \n",
       "client_2              0.0       4.0281          0.0  \n",
       "client_3              0.0       3.9863          0.0  \n",
       "client_4              0.0       3.9715          0.0  \n",
       "client_5              0.0       4.0207          0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the pre-trained model and saved scaler\n",
    "model_path = r\"results\\models\\unsupervised\\isolation_forest_best.pkl\"\n",
    "scaler_path = r\"results\\scalers\\std_scaler.pkl\"\n",
    "\n",
    "global_model = joblib.load(model_path)\n",
    "scaler = joblib.load(scaler_path)\n",
    "\n",
    "#Load training data to get expected columns, and drop problematic columns\n",
    "train_df = pd.read_csv(\n",
    "    r\"D:\\August-Thesis\\FL-IDS-Surveillance\\data\\processed\\surv_unsupervised\\train_normal_only.csv\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "X_train = train_df.drop(columns=[\"Attack_label\", \"http.request.method\"], errors=\"ignore\").select_dtypes(include=\"number\")\n",
    "expected_columns = X_train.columns  \n",
    "\n",
    "# Evaluate on each client\n",
    "client_results = {}\n",
    "for client_id, df in client_data.items():\n",
    "    # Drop label and problematic columns from client data\n",
    "    X = df.drop(columns=[\"Attack_label\", \"http.request.method\"], errors=\"ignore\").select_dtypes(include=\"number\")\n",
    "    \n",
    "    # Align columns with training columns\n",
    "    X = X[expected_columns]\n",
    "    y_true = df[\"Attack_label\"]\n",
    "\n",
    "    # Scale features\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    # Predict using global Isolation Forest model\n",
    "    y_pred = global_model.predict(X_scaled)\n",
    "\n",
    "    # Convert predictions: -1 = anomaly=>1 (attack), 1 = normal => 0\n",
    "    y_pred_mapped = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "\n",
    "    # Calculate the metrics for evaluation\n",
    "    acc = accuracy_score(y_true, y_pred_mapped)\n",
    "    prec = precision_score(y_true, y_pred_mapped, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred_mapped, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred_mapped, zero_division=0)\n",
    "    fp = sum((y_true == 0) & (pd.Series(y_pred_mapped) == 1))\n",
    "    fn = sum((y_true == 1) & (pd.Series(y_pred_mapped) == 0))\n",
    "    fp_rate = 100 * fp / len(y_true)\n",
    "    fn_rate = 100 * fn / len(y_true)\n",
    "\n",
    "    # Storing the results\n",
    "    client_results[client_id] = {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1,\n",
    "        \"False Positives\": fp,\n",
    "        \"False Negatives\": fn,\n",
    "        \"FP Rate (%)\": fp_rate,\n",
    "        \"FN Rate (%)\": fn_rate\n",
    "    }\n",
    "\n",
    "# Converts results to DataFrame and display\n",
    "results_df = pd.DataFrame(client_results).T\n",
    "results_df = results_df.round(4)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487a79e-2ca7-4803-9c5d-8d29528fada0",
   "metadata": {},
   "source": [
    "## Part2: Evaluation of Pre-trained Global Isolation Forest on Client Data\n",
    "\n",
    "In this step, we evaluated the pre-trained **global Isolation Forest model** (trained on mixed normal and attack traffic) on each client’s local dataset.\n",
    "\n",
    "### Purpose:\n",
    "To test how well the centralized model generalizes to distributed, normal-only client data.\n",
    "\n",
    "### Setup:\n",
    "- Each client dataset contained only **normal traffic**.\n",
    "- The model was trained on a mix of normal and attack traffic.\n",
    "- Features were scaled using a **StandardScaler** fitted on the original training data.\n",
    "- Predictions were made using the Isolation Forest, where `-1 = anomaly`, `1 = normal`.\n",
    "\n",
    "### Results:\n",
    "| Metric              | Observation                                                   |\n",
    "|---------------------|---------------------------------------------------------------|\n",
    "| Accuracy            | ~95%, since most data was correctly labeled as normal.        |\n",
    "| Precision / Recall / F1 | All 0.0 — because there were no attack samples, so no true positives possible. |\n",
    "| False Positives     | ~5% of normal samples were flagged as anomalies.              |\n",
    "| False Negatives     | 0 — expected, since there were no attack samples.             |\n",
    "\n",
    "### Why This Result Is Expected:\n",
    "- Isolation Forest always flags a certain fraction of samples as anomalies (default contamination is **0.1**).\n",
    "- Since the client datasets only contain normal traffic, any flagged anomaly is a **false positive**.\n",
    "- This highlights a limitation of applying a globally trained unsupervised model to unseen client distributions.\n",
    "\n",
    "### Conclusion\n",
    "This experiment served as a **diagnostic baseline**, but it does not represent true federated learning.  \n",
    "In a proper FL setup:\n",
    "- Each client must train its own local model on its private data.\n",
    "- The global model should be formed from **aggregating or analyzing these local models**.\n",
    "\n",
    "We now proceed to train local Isolation Forest models on each client to simulate an actual federated learning scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "467137d4-0df6-4766-af58-5c438f34567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for client_1...\n",
      "Training model for client_2...\n",
      "Training model for client_3...\n",
      "Training model for client_4...\n",
      "Training model for client_5...\n",
      "Local training complete for all clients.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Store models and scalers by client ID\n",
    "local_models = {}\n",
    "local_scalers = {}\n",
    "\n",
    "# Define the model hyperparameters (same for all clients for fairness)\n",
    "isoforest_params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"contamination\": 0.1,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "# Train a local Isolation Forest per each client\n",
    "for client_id, df in client_data.items():\n",
    "    print(f\"Training model for {client_id}...\")\n",
    "    \n",
    "    # Drop label and non-numeric/problematic columns\n",
    "    X = df.drop(columns=[\"Attack_label\", \"http.request.method\"], errors=\"ignore\").select_dtypes(include=\"number\")\n",
    "    \n",
    "    # Fitting local StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Train the isolation Forest\n",
    "    model = IsolationForest(**isoforest_params)\n",
    "    model.fit(X_scaled)\n",
    "    \n",
    "    # Store the model and scaler\n",
    "    local_models[client_id] = model\n",
    "    local_scalers[client_id] = scaler\n",
    "\n",
    "print(\"Local training complete for all clients.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa48a6-489c-4d88-ab92-13ccf79861cb",
   "metadata": {},
   "source": [
    "## Part3:  Evaluate Each Local Model on a Common Centralized Test Set\n",
    "\n",
    "In this step, we evaluate how well each locally trained Isolation Forest model generalizes to a shared, centralized test dataset that contains both normal and attack traffic.\n",
    "\n",
    "### Purpose:\n",
    "This evaluation helps us understand:\n",
    "- Whether local models can detect attacks they have never seen  \n",
    "- How generalizable each model is to a broader data distribution  \n",
    "- Which clients produce stronger or weaker models in terms of anomaly detection  \n",
    "\n",
    "### Evaluation Plan:\n",
    "- Use the same test set (`test_mixed.csv`) for all clients  \n",
    "- Apply each client’s local **StandardScaler** to preprocess the test data  \n",
    "- Use each client’s **Isolation Forest** model to make predictions  \n",
    "- Convert Isolation Forest output to binary format:  \n",
    "  - `-1 → anomaly (mapped to 1 = attack)`  \n",
    "  - `1 → normal (mapped to 0 = no attack)`  \n",
    "- Calculate standard classification metrics:  \n",
    "  - **Accuracy, Precision, Recall, F1 Score**  \n",
    "  - **False Positives (FP), False Negatives (FN), FP Rate, FN Rate**  \n",
    "\n",
    "This will provide a side-by-side comparison of model performance across all clients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da3e3dca-fe35-46e4-9652-4cc58464fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>FP Rate (%)</th>\n",
       "      <th>FN Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>client_1</th>\n",
       "      <td>0.7231</td>\n",
       "      <td>0.4820</td>\n",
       "      <td>0.2492</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>161560.0</td>\n",
       "      <td>452847.0</td>\n",
       "      <td>7.2813</td>\n",
       "      <td>20.4092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_2</th>\n",
       "      <td>0.6769</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>0.1177</td>\n",
       "      <td>161446.0</td>\n",
       "      <td>555399.0</td>\n",
       "      <td>7.2762</td>\n",
       "      <td>25.0311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_3</th>\n",
       "      <td>0.6784</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>160536.0</td>\n",
       "      <td>553061.0</td>\n",
       "      <td>7.2352</td>\n",
       "      <td>24.9257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_4</th>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.2537</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>162618.0</td>\n",
       "      <td>547918.0</td>\n",
       "      <td>7.3290</td>\n",
       "      <td>24.6940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_5</th>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>161538.0</td>\n",
       "      <td>561486.0</td>\n",
       "      <td>7.2803</td>\n",
       "      <td>25.3055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy  Precision  Recall  F1 Score  False Positives  \\\n",
       "client_1    0.7231     0.4820  0.2492    0.3286         161560.0   \n",
       "client_2    0.6769     0.2284  0.0792    0.1177         161446.0   \n",
       "client_3    0.6784     0.2380  0.0831    0.1232         160536.0   \n",
       "client_4    0.6798     0.2537  0.0916    0.1346         162618.0   \n",
       "client_5    0.6741     0.2052  0.0691    0.1034         161538.0   \n",
       "\n",
       "          False Negatives  FP Rate (%)  FN Rate (%)  \n",
       "client_1         452847.0       7.2813      20.4092  \n",
       "client_2         555399.0       7.2762      25.0311  \n",
       "client_3         553061.0       7.2352      24.9257  \n",
       "client_4         547918.0       7.3290      24.6940  \n",
       "client_5         561486.0       7.2803      25.3055  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#Loading the centralized dataset\n",
    "test_data_path = r\"D:\\August-Thesis\\FL-IDS-Surveillance\\data\\processed\\surv_unsupervised\\test_mixed.csv\"\n",
    "df_test = pd.read_csv(test_data_path, low_memory=False)\n",
    "\n",
    "#Drop the non-numeric/problematic columns \n",
    "df_test = df_test.drop(columns=[\"http.request.method\"], errors=\"ignore\")\n",
    "\n",
    "# make the features and labels\n",
    "X_test_full = df_test.drop(columns=[\"Attack_label\"]).select_dtypes(include=\"number\")\n",
    "y_true = df_test[\"Attack_label\"]\n",
    "\n",
    "#Store the evaluation results\n",
    "evaluation_results = {}\n",
    "\n",
    "for client_id in local_models.keys():\n",
    "    model = local_models[client_id]\n",
    "    scaler = local_scalers[client_id]\n",
    "\n",
    "    #Align test set columns to the client's expected features \n",
    "    expected_columns = scaler.feature_names_in_\n",
    "    X_test = X_test_full[expected_columns]\n",
    "\n",
    "    # Scale test data using client's scaler\n",
    "    X_scaled = scaler.transform(X_test)\n",
    "\n",
    "    #Predict using client's model\n",
    "    y_pred_raw = model.predict(X_scaled)\n",
    "    y_pred = np.where(y_pred_raw == -1, 1, 0)  # -1 => 1 (attack), 1 => 0 (normal)\n",
    "\n",
    "    #Compute metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    fp = ((y_pred == 1) & (y_true == 0)).sum()\n",
    "    fn = ((y_pred == 0) & (y_true == 1)).sum()\n",
    "    fp_rate = 100 * fp / len(y_true)\n",
    "    fn_rate = 100 * fn / len(y_true)\n",
    "\n",
    "    #Store results\n",
    "    evaluation_results[client_id] = {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1,\n",
    "        \"False Positives\": fp,\n",
    "        \"False Negatives\": fn,\n",
    "        \"FP Rate (%)\": fp_rate,\n",
    "        \"FN Rate (%)\": fn_rate\n",
    "    }\n",
    "\n",
    "#Convert to DataFrame and save\n",
    "results_df_local_eval = pd.DataFrame(evaluation_results).T\n",
    "results_df_local_eval = results_df_local_eval.round(4)\n",
    "\n",
    "# Save to CSV\n",
    "results_save_path = r\"results\\local_model_evaluation_iForest.csv\"\n",
    "results_df_local_eval.to_csv(results_save_path)\n",
    "\n",
    "results_df_local_eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf40c29-adc9-4ba7-a591-f022776a0c03",
   "metadata": {},
   "source": [
    "## Part4: Reflection on Why Local Models Performed Worse than the Global Model\n",
    "\n",
    "Although both the global and local Isolation Forest models were trained on data from the same source (`train_normal_only.csv`), the global model significantly outperformed the local models when evaluated on a mixed (attack + normal) test set.\n",
    "\n",
    "### Key Insight\n",
    "The only difference between the global and local models is the **amount of training data** they were exposed to.\n",
    "\n",
    "| Factor               | Global Model                           | Local Models                                  |\n",
    "|-----------------------|----------------------------------------|-----------------------------------------------|\n",
    "| Training data size    | Entire dataset (~1.6 million samples)  | ~320,000 samples per client                   |\n",
    "| View of “normal”      | Full variety across all clients        | Narrower, client-specific normal behavior      |\n",
    "| Isolation Forest trees| Deeper, richer structure               | Shallower, more overfit to local variance     |\n",
    "| Contamination (0.1)   | Spread over more data → balanced       | Compressed into smaller sample → more misclassification |\n",
    "\n",
    "### Why This Matters\n",
    "- Isolation Forest relies on randomly partitioning the feature space.\n",
    "- With more data, the model can better separate dense vs. sparse regions (i.e., normal vs. anomalous).\n",
    "- Local models, trained on smaller samples, had a narrower statistical view of what “normal” is, which led to:\n",
    "  - More false positives (flagging unseen normal as anomalies)  \n",
    "  - More false negatives (failing to detect subtle anomalies near local patterns)\n",
    "\n",
    "### Conclusion\n",
    "Even though the data distribution was the same, the limited data size per client resulted in less generalizable models.  \n",
    "This highlights a core trade-off in federated unsupervised learning: **decentralization may reduce data diversity and model robustness unless compensated by smarter aggregation or adaptation strategies.**\n",
    "\n",
    "---\n",
    "\n",
    "## Train Local Autoencoder Models on Each Client\n",
    "\n",
    "In this step, we extend the federated learning setup to use **Autoencoders** — a neural network–based unsupervised method for anomaly detection.\n",
    "\n",
    "### Why Autoencoders?\n",
    "Autoencoders are well-suited for detecting anomalies by learning to reconstruct normal input patterns.  \n",
    "If the reconstruction error for a new sample is high, it is likely anomalous.\n",
    "\n",
    "Unlike Isolation Forests, Autoencoders are:\n",
    "- Parametric (learn weights via backpropagation)\n",
    "- Sensitive to input scale and distribution\n",
    "- More expressive in modeling nonlinear patterns\n",
    "\n",
    "### Key Differences in Preprocessing\n",
    "- We use `MinMaxScaler()` instead of `StandardScaler`, because neural networks benefit from input features scaled to the `[0, 1]` range.\n",
    "- We still drop the non-numeric or irrelevant column: `http.request.method`.\n",
    "\n",
    "### Local Training Plan\n",
    "Each client will:\n",
    "- Drop the `Attack_label` and `http.request.method` columns (if present)\n",
    "- Fit a `MinMaxScaler` on its local features\n",
    "- Train a deep Autoencoder on the scaled normal-only data\n",
    "- Store the model and scaler separately for evaluation or comparison\n",
    "\n",
    "This step mirrors the Isolation Forest setup but uses a neural architecture and preprocessing tailored for deep learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bc613ff-0a0e-421b-b9c5-86551aecd2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_autoencoder(input_dim):\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Encoder\n",
    "    encoded = Dense(32, activation='relu')(input_layer)\n",
    "    encoded = Dense(16, activation='relu')(encoded)\n",
    "    encoded = Dense(8, activation='relu')(encoded)\n",
    "    \n",
    "    # Decoder\n",
    "    decoded = Dense(16, activation='relu')(encoded)\n",
    "    decoded = Dense(32, activation='relu')(decoded)\n",
    "    output_layer = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "    \n",
    "    # Autoencoder model\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    \n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f23fcaa7-cf89-452f-bba2-3780594a764d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Autoencode for client_1 . . .\n",
      "Epoch 1/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0556  \n",
      "Epoch 2/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - loss: 0.0120\n",
      "Epoch 3/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - loss: 0.0118\n",
      "Epoch 4/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - loss: 0.0116\n",
      "Epoch 5/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - loss: 0.0116\n",
      "Epoch 6/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - loss: 0.0115\n",
      "Epoch 7/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0115\n",
      "Epoch 8/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116\n",
      "Epoch 9/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0116\n",
      "Epoch 10/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116\n",
      "Epoch 11/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - loss: 0.0115\n",
      "Epoch 12/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - loss: 0.0114\n",
      "Epoch 13/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - loss: 0.0115\n",
      "Epoch 14/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - loss: 0.0115\n",
      "Epoch 15/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - loss: 0.0115\n",
      "Epoch 16/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - loss: 0.0113\n",
      "Epoch 17/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step - loss: 0.0114\n",
      "Epoch 18/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step - loss: 0.0114\n",
      "Epoch 19/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968us/step - loss: 0.0115\n",
      "Epoch 20/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - loss: 0.0114\n",
      "Epoch 21/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - loss: 0.0114\n",
      "Epoch 22/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - loss: 0.0114\n",
      "Epoch 23/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0114  \n",
      "Epoch 24/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - loss: 0.0114\n",
      "Epoch 25/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - loss: 0.0113\n",
      "Epoch 26/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - loss: 0.0114\n",
      "Epoch 27/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - loss: 0.0113\n",
      "Epoch 28/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0114\n",
      "Epoch 29/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - loss: 0.0115\n",
      "Epoch 30/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0114  \n",
      "Epoch 31/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - loss: 0.0114\n",
      "Epoch 32/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - loss: 0.0114\n",
      "Epoch 33/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - loss: 0.0114\n",
      "Epoch 34/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - loss: 0.0115\n",
      "Epoch 35/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0114  \n",
      "Epoch 36/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - loss: 0.0114\n",
      "Epoch 37/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968us/step - loss: 0.0114\n",
      "Epoch 38/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - loss: 0.0114\n",
      "Epoch 39/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - loss: 0.0114\n",
      "Epoch 40/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - loss: 0.0115\n",
      "Epoch 41/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - loss: 0.0115\n",
      "Epoch 42/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - loss: 0.0114\n",
      "Epoch 43/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - loss: 0.0114\n",
      "Epoch 44/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - loss: 0.0101\n",
      "Epoch 45/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0093  \n",
      "Epoch 46/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - loss: 0.0092\n",
      "Epoch 47/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - loss: 0.0092\n",
      "Epoch 48/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - loss: 0.0092\n",
      "Epoch 49/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0092\n",
      "Epoch 50/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0092\n",
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Autoencode for client_2 . . .\n",
      "Epoch 1/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.0589\n",
      "Epoch 2/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0079\n",
      "Epoch 3/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0078\n",
      "Epoch 4/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0078\n",
      "Epoch 5/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0077\n",
      "Epoch 6/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0074\n",
      "Epoch 7/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0051\n",
      "Epoch 8/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0052\n",
      "Epoch 9/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0052\n",
      "Epoch 10/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0051\n",
      "Epoch 11/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0051\n",
      "Epoch 12/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030\n",
      "Epoch 13/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030\n",
      "Epoch 14/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030\n",
      "Epoch 15/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - loss: 0.0030\n",
      "Epoch 16/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030\n",
      "Epoch 17/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - loss: 0.0029\n",
      "Epoch 18/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030\n",
      "Epoch 19/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0030\n",
      "Epoch 20/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030\n",
      "Epoch 21/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 22/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017  \n",
      "Epoch 23/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - loss: 0.0017\n",
      "Epoch 24/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 25/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - loss: 0.0017\n",
      "Epoch 26/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - loss: 0.0017\n",
      "Epoch 27/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017  \n",
      "Epoch 28/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - loss: 0.0017\n",
      "Epoch 29/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017  \n",
      "Epoch 30/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - loss: 0.0017\n",
      "Epoch 31/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017  \n",
      "Epoch 32/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 33/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 34/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 35/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 36/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 37/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017  \n",
      "Epoch 38/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 39/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 40/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017  \n",
      "Epoch 41/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 42/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 43/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 44/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 45/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0017  \n",
      "Epoch 46/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0016\n",
      "Epoch 47/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0016\n",
      "Epoch 48/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0016\n",
      "Epoch 49/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0016\n",
      "Epoch 50/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0016\n",
      "Restoring model weights from the end of the best epoch: 49.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Autoencode for client_3 . . .\n",
      "Epoch 1/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0602  \n",
      "Epoch 2/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0169\n",
      "Epoch 3/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - loss: 0.0165\n",
      "Epoch 12/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977us/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0153  \n",
      "Epoch 21/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - loss: 0.0153\n",
      "Epoch 22/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - loss: 0.0152\n",
      "Epoch 23/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0153  \n",
      "Epoch 24/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - loss: 0.0153\n",
      "Epoch 25/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0153  \n",
      "Epoch 26/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0152  \n",
      "Epoch 28/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0153  \n",
      "Epoch 30/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - loss: 0.0153\n",
      "Epoch 31/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - loss: 0.0153\n",
      "Epoch 32/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0153  \n",
      "Epoch 33/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977us/step - loss: 0.0153\n",
      "Epoch 34/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - loss: 0.0152\n",
      "Epoch 36/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0153  \n",
      "Epoch 37/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0153\n",
      "Epoch 38/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0153  \n",
      "Epoch 39/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - loss: 0.0151\n",
      "Epoch 40/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0152  \n",
      "Epoch 41/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - loss: 0.0151\n",
      "Epoch 42/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - loss: 0.0151\n",
      "Epoch 43/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0152  \n",
      "Epoch 44/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0152  \n",
      "Epoch 45/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0151  \n",
      "Epoch 48/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0152  \n",
      "Epoch 49/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0152\n",
      "Epoch 50/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0138  \n",
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Autoencode for client_4 . . .\n",
      "Epoch 1/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 980us/step - loss: 0.0477\n",
      "Epoch 2/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - loss: 0.0146\n",
      "Epoch 3/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - loss: 0.0144\n",
      "Epoch 4/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step - loss: 0.0144\n",
      "Epoch 5/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0143\n",
      "Epoch 6/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0143\n",
      "Epoch 7/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - loss: 0.0144\n",
      "Epoch 8/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0143\n",
      "Epoch 9/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0142\n",
      "Epoch 10/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0140\n",
      "Epoch 11/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0130\n",
      "Epoch 12/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - loss: 0.0130\n",
      "Epoch 13/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0130\n",
      "Epoch 14/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0130\n",
      "Epoch 15/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - loss: 0.0130\n",
      "Epoch 16/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0130  \n",
      "Epoch 17/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0129\n",
      "Epoch 18/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - loss: 0.0129\n",
      "Epoch 19/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0130\n",
      "Epoch 20/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0130\n",
      "Epoch 21/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0130\n",
      "Epoch 22/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0130\n",
      "Epoch 23/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0128\n",
      "Epoch 24/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0130  \n",
      "Epoch 25/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0123\n",
      "Epoch 26/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116  \n",
      "Epoch 27/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0117\n",
      "Epoch 28/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0118\n",
      "Epoch 29/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0117\n",
      "Epoch 30/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0117\n",
      "Epoch 31/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0117\n",
      "Epoch 32/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0118\n",
      "Epoch 33/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0117\n",
      "Epoch 34/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0116\n",
      "Epoch 35/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0104\n",
      "Epoch 36/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0103\n",
      "Epoch 37/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0093\n",
      "Epoch 38/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0093\n",
      "Epoch 39/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0092\n",
      "Epoch 40/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0091\n",
      "Epoch 41/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0079\n",
      "Epoch 42/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0079\n",
      "Epoch 43/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0079\n",
      "Epoch 44/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0079\n",
      "Epoch 45/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0067\n",
      "Epoch 46/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0067\n",
      "Epoch 47/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0066\n",
      "Epoch 48/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0067\n",
      "Epoch 49/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0067  \n",
      "Epoch 50/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0066\n",
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Autoencode for client_5 . . .\n",
      "Epoch 1/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0573  \n",
      "Epoch 2/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0168  \n",
      "Epoch 3/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0167  \n",
      "Epoch 4/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0157  \n",
      "Epoch 5/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0157  \n",
      "Epoch 6/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0156  \n",
      "Epoch 7/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0134\n",
      "Epoch 8/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - loss: 0.0130\n",
      "Epoch 9/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - loss: 0.0129\n",
      "Epoch 10/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0129  \n",
      "Epoch 11/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - loss: 0.0129\n",
      "Epoch 12/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0129\n",
      "Epoch 13/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - loss: 0.0122\n",
      "Epoch 14/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0117  \n",
      "Epoch 15/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0117\n",
      "Epoch 16/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - loss: 0.0117\n",
      "Epoch 17/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116  \n",
      "Epoch 18/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116\n",
      "Epoch 19/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - loss: 0.0116\n",
      "Epoch 20/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116\n",
      "Epoch 21/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116  \n",
      "Epoch 22/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - loss: 0.0116\n",
      "Epoch 23/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116\n",
      "Epoch 24/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1000us/step - loss: 0.0116\n",
      "Epoch 25/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0117\n",
      "Epoch 26/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0117  \n",
      "Epoch 27/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0115\n",
      "Epoch 28/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0117  \n",
      "Epoch 29/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116\n",
      "Epoch 30/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116  \n",
      "Epoch 31/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0116  \n",
      "Epoch 32/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0115\n",
      "Epoch 33/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0104\n",
      "Epoch 34/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0091\n",
      "Epoch 35/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0091  \n",
      "Epoch 36/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0090\n",
      "Epoch 37/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0080\n",
      "Epoch 38/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0077\n",
      "Epoch 39/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0078\n",
      "Epoch 40/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0077\n",
      "Epoch 41/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0078\n",
      "Epoch 42/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0078\n",
      "Epoch 43/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0077\n",
      "Epoch 44/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0078\n",
      "Epoch 45/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0077\n",
      "Epoch 46/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0078\n",
      "Epoch 47/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0078\n",
      "Epoch 48/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0077\n",
      "Epoch 49/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0078\n",
      "Epoch 50/50\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0077\n",
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for all clients.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#Store the trained model and scaler for each client\n",
    "local_autoencoders = {}\n",
    "local_minmax_scalers = {}\n",
    "\n",
    "#Train parameters\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "patience = 5\n",
    "\n",
    "for client_id, df in client_data.items():\n",
    "    print(f\"Training the Autoencode for {client_id} . . .\")\n",
    "    X = df.drop(columns=[\"Attack_label\", \"http.request.method\"],errors=\"ignore\").select_dtypes(include=\"number\")\n",
    "\n",
    "    #Fit the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    #Buuild the Autoencoder based on input shape\n",
    "    input_dim = X_scaled.shape[1]\n",
    "    model = build_autoencoder(input_dim)\n",
    "\n",
    "    #Early stopping \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor = 'loss',\n",
    "        patience = patience,\n",
    "        restore_best_weights = True,\n",
    "        verbose = 1\n",
    "    )\n",
    "\n",
    "    #train Model\n",
    "    model.fit(\n",
    "        X_scaled, X_scaled, epochs = epochs,\n",
    "        batch_size = batch_size, shuffle = True,\n",
    "        callbacks = [early_stop], verbose = 1\n",
    "    )\n",
    "    model.save(f\"results/models/unsupervised/clients/autoencoder_client_{client_id}.h5\")\n",
    "    local_autoencoders[client_id] = model\n",
    "    local_minmax_scalers[client_id] = scaler\n",
    "print(\"Training complete for all clients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04313603-0046-4301-866d-1e30266b691e",
   "metadata": {},
   "source": [
    "## Part5: Evaluate Each Local Autoencoder on a Common Centralized Test Set\n",
    "\n",
    "In this step, we evaluate the performance of each locally trained Autoencoder on a shared test dataset (`test_mixed.csv`) that contains both normal and attack traffic.\n",
    "\n",
    "### Why This Matters\n",
    "This evaluation allows us to assess how well each client’s model, trained only on its local view of normal traffic, generalizes to unseen and more diverse data. Specifically, we measure the model’s ability to:  \n",
    "\n",
    "- Reconstruct normal inputs accurately  \n",
    "- Flag abnormal inputs based on reconstruction error  \n",
    "\n",
    "### Evaluation Procedure\n",
    "For each client:  \n",
    "\n",
    "1. Load the centralized test set  \n",
    "2. Drop the `http.request.method` column  \n",
    "3. Extract and preprocess features using the client’s own `MinMaxScaler`  \n",
    "4. Run the test data through the client’s Autoencoder to reconstruct inputs  \n",
    "5. Compute reconstruction error (Mean Squared Error)  \n",
    "6. Tune a threshold on reconstruction error to maximize F1 Score  \n",
    "7. Classify anomalies: reconstruction error > threshold → anomaly  \n",
    "8. Compare predicted labels to true `Attack_label` and compute:  \n",
    "   - Accuracy  \n",
    "   - Precision  \n",
    "   - Recall  \n",
    "   - F1 Score  \n",
    "   - False Positives (FP)  \n",
    "   - False Negatives (FN)  \n",
    "   - FP Rate and FN Rate  \n",
    "\n",
    "This provides insight into which clients produce more generalizable anomaly detectors, despite only seeing a limited view of the system during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41392401-90be-4a73-a92b-0c95d70d3d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>FP Rate (%)</th>\n",
       "      <th>FN Rate (%)</th>\n",
       "      <th>Inference Time (s)</th>\n",
       "      <th>Time per Sample (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>client_1</th>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.8529</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.4593</td>\n",
       "      <td>0.6292</td>\n",
       "      <td>318.0</td>\n",
       "      <td>326154.0</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>54.0714</td>\n",
       "      <td>48.1185</td>\n",
       "      <td>0.0217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_2</th>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>5089.0</td>\n",
       "      <td>244391.0</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>40.5164</td>\n",
       "      <td>50.6459</td>\n",
       "      <td>0.0228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_3</th>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.8524</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.4584</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>875.0</td>\n",
       "      <td>326711.0</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>54.1638</td>\n",
       "      <td>50.1541</td>\n",
       "      <td>0.0226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_4</th>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>291555.0</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>48.3354</td>\n",
       "      <td>50.7439</td>\n",
       "      <td>0.0229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_5</th>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.8535</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.4623</td>\n",
       "      <td>0.6318</td>\n",
       "      <td>693.0</td>\n",
       "      <td>324311.0</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>53.7659</td>\n",
       "      <td>49.8854</td>\n",
       "      <td>0.0225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Best Threshold  Accuracy  Precision  Recall  F1 Score  \\\n",
       "client_1          0.1002    0.8529     0.9989  0.4593    0.6292   \n",
       "client_2          0.0246    0.8876     0.9860  0.5948    0.7420   \n",
       "client_3          0.1002    0.8524     0.9968  0.4584    0.6280   \n",
       "client_4          0.0489    0.8681     0.9961  0.5166    0.6804   \n",
       "client_5          0.0738    0.8535     0.9975  0.4623    0.6318   \n",
       "\n",
       "          False Positives  False Negatives  FP Rate (%)  FN Rate (%)  \\\n",
       "client_1            318.0         326154.0       0.0197      54.0714   \n",
       "client_2           5089.0         244391.0       0.3150      40.5164   \n",
       "client_3            875.0         326711.0       0.0542      54.1638   \n",
       "client_4           1220.0         291555.0       0.0755      48.3354   \n",
       "client_5            693.0         324311.0       0.0429      53.7659   \n",
       "\n",
       "          Inference Time (s)  Time per Sample (ms)  \n",
       "client_1             48.1185                0.0217  \n",
       "client_2             50.6459                0.0228  \n",
       "client_3             50.1541                0.0226  \n",
       "client_4             50.7439                0.0229  \n",
       "client_5             49.8854                0.0225  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "#Load centralized test set\n",
    "test_data_path = r\"D:\\August-Thesis\\FL-IDS-Surveillance\\data\\processed\\surv_unsupervised\\test_mixed.csv\"\n",
    "df_test = pd.read_csv(test_data_path, low_memory=False)\n",
    "\n",
    "# Drop the non-numeric/problematic columns\n",
    "df_test = df_test.drop(columns=[\"http.request.method\"], errors=\"ignore\")\n",
    "\n",
    "#Take the labels\n",
    "y_true = df_test[\"Attack_label\"].copy()\n",
    "\n",
    "ae_local_results = {}\n",
    "\n",
    "for client_id in local_autoencoders.keys():\n",
    "    model = local_autoencoders[client_id]\n",
    "    scaler = local_minmax_scalers[client_id]\n",
    "\n",
    "    #  Extract and align test features\n",
    "    test_columns = scaler.feature_names_in_\n",
    "    X_test = df_test[test_columns].copy()\n",
    "\n",
    "    #Clean and fill any missing values just in case \n",
    "    for col in X_test.columns:\n",
    "        if X_test[col].dtype == 'object' or X_test[col].dtype.name == 'category':\n",
    "            X_test[col] = pd.to_numeric(X_test[col], errors='coerce')\n",
    "        if X_test[col].dtype in ['float64', 'int64']:\n",
    "            X_test[col] = X_test[col].fillna(X_test[col].mean())\n",
    "\n",
    "    # Scale test data using client's scaler \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Run reconstruction and compute reconstruction errors\n",
    "    start_time = time.time()\n",
    "    X_reconstructed = model.predict(X_test_scaled, verbose=0)\n",
    "    end_time = time.time()\n",
    "    reconstruction_errors = np.mean(np.square(X_test_scaled - X_reconstructed), axis=1)\n",
    "\n",
    "    #Tune threshold for best F1 score\n",
    "    thresholds = np.percentile(reconstruction_errors, np.arange(80, 100, 0.1))\n",
    "    best_f1 = 0\n",
    "    best_threshold = None\n",
    "    best_pred = None\n",
    "    for thresh in thresholds:\n",
    "        preds = (reconstruction_errors > thresh).astype(int)\n",
    "        f1 = f1_score(y_true, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = thresh\n",
    "            best_pred = preds\n",
    "\n",
    "    # Final metrics\n",
    "    accuracy = accuracy_score(y_true, best_pred)\n",
    "    precision = precision_score(y_true, best_pred)\n",
    "    recall = recall_score(y_true, best_pred)\n",
    "    f1 = best_f1\n",
    "    cm = confusion_matrix(y_true, best_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fp_rate = fp / (fp + tn) * 100\n",
    "    fn_rate = fn / (fn + tp) * 100\n",
    "    total_time = end_time - start_time\n",
    "    inference_time_per_sample = (total_time / len(X_test_scaled)) * 1000\n",
    "\n",
    "    #Store the metrics \n",
    "    ae_local_results[client_id] = {\n",
    "        \"Best Threshold\": best_threshold,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"False Positives\": fp,\n",
    "        \"False Negatives\": fn,\n",
    "        \"FP Rate (%)\": fp_rate,\n",
    "        \"FN Rate (%)\": fn_rate,\n",
    "        \"Inference Time (s)\": total_time,\n",
    "        \"Time per Sample (ms)\": inference_time_per_sample\n",
    "    }\n",
    "\n",
    "#Convert results to DataFrame and save\n",
    "ae_local_results_df = pd.DataFrame(ae_local_results).T.round(4)\n",
    "save_path = r\"results\\local_model_evaluation_autoencoder.csv\"\n",
    "ae_local_results_df.to_csv(save_path, index=True)\n",
    "ae_local_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99c5e472-1ce8-4d96-8bc5-955f682c28c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated Autoencoder saved to:\n",
      "results/models/unsupervised/federated/federated_autoencoder.h5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define the architecture\n",
    "def build_autoencoder(input_dim):\n",
    "    input_layer = tf.keras.Input(shape=(input_dim,))\n",
    "    # Encoder\n",
    "    encoded = tf.keras.layers.Dense(32, activation='relu')(input_layer)\n",
    "    encoded = tf.keras.layers.Dense(16, activation='relu')(encoded)\n",
    "    encoded = tf.keras.layers.Dense(8, activation='relu')(encoded)\n",
    "    # Decoder\n",
    "    decoded = tf.keras.layers.Dense(16, activation='relu')(encoded)\n",
    "    decoded = tf.keras.layers.Dense(32, activation='relu')(decoded)\n",
    "    output_layer = tf.keras.layers.Dense(input_dim, activation='linear')(decoded)\n",
    "    autoencoder = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "# Load all 5 client models \n",
    "client_model_paths = [\n",
    "    f\"D:/August-Thesis/FL-IDS-Surveillance/notebooks/results/models/unsupervised/clients/autoencoder_client_client_{i}.h5\"\n",
    "    for i in range(1, 6)\n",
    "]\n",
    "\n",
    "#Perform Federated Averaging\n",
    "client_models = [load_model(path, compile=False) for path in client_model_paths]\n",
    "client_weights = [model.get_weights() for model in client_models]\n",
    "\n",
    "avg_weights = []\n",
    "for weights_list_tuple in zip(*client_weights):\n",
    "    avg_layer_weights = np.mean(np.array(weights_list_tuple), axis=0)\n",
    "    avg_weights.append(avg_layer_weights)\n",
    "\n",
    "#Create a new model and set averaged weights\n",
    "input_dim = client_models[0].input_shape[1]\n",
    "federated_autoencoder = build_autoencoder(input_dim)\n",
    "federated_autoencoder.set_weights(avg_weights)\n",
    "\n",
    "#Save the federated model\n",
    "fed_model_path = r\"results/models/unsupervised/federated/federated_autoencoder.h5\"\n",
    "os.makedirs(os.path.dirname(fed_model_path), exist_ok=True)\n",
    "federated_autoencoder.save(fed_model_path)\n",
    "print(f\"Federated Autoencoder saved to:\\n{fed_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "541d5833-05c4-4e38-ba18-bf05b40448f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69339/69339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 553us/step\n",
      "Federated Autoencoder Evaluation\n",
      "Best Threshold: 23.134763\n",
      "Accuracy: 0.8381\n",
      "Precision: 0.9910\n",
      "Recall: 0.4083\n",
      "F1 Score: 0.5783\n",
      "False Positives: 2227 (0.14%)\n",
      "False Negatives: 356908 (59.17%)\n",
      "Inference Time: 51.45 s\n",
      "Inference Time per Sample: 0.023186 ms\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load federated autoencoder model\n",
    "fed_model_path = r\"results/models/unsupervised/federated/federated_autoencoder.h5\"\n",
    "federated_autoencoder = load_model(fed_model_path, compile=False)\n",
    "\n",
    "# Load test dataset\n",
    "test_path = r\"D:/August-Thesis/FL-IDS-Surveillance/data/processed/surv_unsupervised/test_mixed.csv\"\n",
    "df_test = pd.read_csv(test_path, low_memory=False)\n",
    "\n",
    "# Drop label and problematic/non-numeric columns\n",
    "X_test = df_test.drop(columns=[\"Attack_label\", \"http.request.method\"], errors=\"ignore\").select_dtypes(include=\"number\")\n",
    "y_true = df_test[\"Attack_label\"]\n",
    "\n",
    "# Scale test data using MinMaxScaler from client_1\n",
    "scaler = local_minmax_scalers[\"client_1\"]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Run reconstruction\n",
    "start_time = time.time()\n",
    "X_reconstructed = federated_autoencoder.predict(X_test_scaled)\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute reconstruction error\n",
    "reconstruction_errors = np.mean(np.square(X_test_scaled - X_reconstructed), axis=1)\n",
    "\n",
    "# Find optimal threshold for best F1 score\n",
    "thresholds = np.percentile(reconstruction_errors, np.arange(80, 100, 0.1))\n",
    "best_f1 = 0\n",
    "best_threshold = None\n",
    "best_pred = None\n",
    "for thresh in thresholds:\n",
    "    preds = (reconstruction_errors > thresh).astype(int)\n",
    "    f1 = f1_score(y_true, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = thresh\n",
    "        best_pred = preds\n",
    "\n",
    "# Compute final metrics\n",
    "accuracy = accuracy_score(y_true, best_pred)\n",
    "precision = precision_score(y_true, best_pred)\n",
    "recall = recall_score(y_true, best_pred)\n",
    "f1 = best_f1\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, best_pred).ravel()\n",
    "fp_rate = 100 * fp / (fp + tn)\n",
    "fn_rate = 100 * fn / (fn + tp)\n",
    "total_time = end_time - start_time\n",
    "per_sample_time = (total_time / len(X_test)) * 1000\n",
    "\n",
    "# Output results\n",
    "print(\"Federated Autoencoder Evaluation\")\n",
    "print(f\"Best Threshold: {best_threshold:.6f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"False Positives: {fp} ({fp_rate:.2f}%)\")\n",
    "print(f\"False Negatives: {fn} ({fn_rate:.2f}%)\")\n",
    "print(f\"Inference Time: {total_time:.2f} s\")\n",
    "print(f\"Inference Time per Sample: {per_sample_time:.6f} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3839cba-ec10-41f5-9c0b-411e86ca8b8f",
   "metadata": {},
   "source": [
    "### Part7: Now we do the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2158f27d-4bf9-41c5-8a8a-2a91aa95d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Setup & Constants\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Function for setting the random seed for reproducibility\n",
    "def set_random_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "# Paths & constants\n",
    "BASE_PATH = \"D:/August-Thesis/FL-IDS-Surveillance\"\n",
    "MODEL_DIR = os.path.join(BASE_PATH, \"notebooks\", \"results\", \"models\", \"unsupervised\", \"federated\")\n",
    "DATA_DIR = os.path.join(BASE_PATH, \"data\", \"processed\", \"federated\", \"unsupervised\")\n",
    "\n",
    "# Client identifiers\n",
    "CLIENT_IDS = [f\"client_{i}\" for i in range(1, 6)]\n",
    "NUM_CLIENTS = len(CLIENT_IDS)\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS_PER_ROUND = 1\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c65228e9-5a98-481e-88d9-37a0d83df437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def build_autoencoder(input_dim, latent_dims=[32, 16, 32], activation='relu', output_activation='sigmoid'):\n",
    "    \"\"\"\n",
    "    Build a deep autoencoder model with a configurable latent layer structure.\n",
    "\n",
    "    Parameters:\n",
    "    - input_dim: int, number of input features\n",
    "    - latent_dims: list of ints, hidden layer sizes [encoder..., decoder last layer]\n",
    "    - activation: activation function for hidden layers\n",
    "    - output_activation: activation function for the output layer\n",
    "\n",
    "    Returns:\n",
    "    - compiled Keras Model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = input_layer\n",
    "\n",
    "    # Encoder layers\n",
    "    for units in latent_dims[:-1]:\n",
    "        x = Dense(units, activation=activation)(x)\n",
    "\n",
    "    # Decoder last hidden layer\n",
    "    x = Dense(latent_dims[-1], activation=activation)(x)\n",
    "\n",
    "    # Output layer\n",
    "    output_layer = Dense(input_dim, activation=output_activation)(x)\n",
    "\n",
    "    # Build and compile model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "653c9fea-a78f-4775-b63b-a9cf78b32822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def load_and_preprocess_client_data(client_id, columns_to_drop=[\"Attack_label\", \"http.request.method\"]):\n",
    "    \"\"\"\n",
    "    Load a client's training data, drop unwanted columns, and scale numeric features.\n",
    "\n",
    "    Parameters:\n",
    "    - client_id: str, the client identifier\n",
    "    - columns_to_drop: list of str, columns to exclude from the features\n",
    "\n",
    "    Returns:\n",
    "    - X_scaled: np.ndarray, scaled features\n",
    "    - scaler: fitted MinMaxScaler instance\n",
    "    - feature_names: list of str, original feature column names\n",
    "    \"\"\"\n",
    "    # Construct file path for the client\n",
    "    path = os.path.join(DATA_DIR, client_id, \"train.csv\")\n",
    "    \n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    \n",
    "    # Drop unwanted columns\n",
    "    X = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "    X = X.select_dtypes(include=\"number\")  # Keep only numeric features\n",
    "    \n",
    "    # Fit MinMaxScaler on features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, scaler, X.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4195f98-6818-4848-9f6b-b535577d1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import clone_model\n",
    "import numpy as np\n",
    "\n",
    "def federated_training_round(global_model, client_ids=CLIENT_IDS, batch_size=BATCH_SIZE, epochs=EPOCHS_PER_ROUND):\n",
    "    \"\"\"\n",
    "    Perform one round of federated training by training the global model locally\n",
    "    on each client and averaging the weights.\n",
    "\n",
    "    Parameters:\n",
    "    - global_model: Keras Model, the current global model\n",
    "    - client_ids: list of str, client identifiers\n",
    "    - batch_size: int, batch size for local training\n",
    "    - epochs: int, number of local epochs per client\n",
    "\n",
    "    Returns:\n",
    "    - averaged_weights: list of numpy arrays, the federated-averaged weights\n",
    "    \"\"\"\n",
    "    local_weights = []\n",
    "\n",
    "    for client_id in client_ids:\n",
    "        print(f\"Training on {client_id}...\")\n",
    "\n",
    "        # Load & preprocess client data\n",
    "        X_client, _, _ = load_and_preprocess_client_data(client_id)\n",
    "\n",
    "        # Clone the global model for local training\n",
    "        local_model = clone_model(global_model)\n",
    "        local_model.set_weights(global_model.get_weights())\n",
    "        local_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        # Train the local model\n",
    "        local_model.fit(X_client, X_client, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "\n",
    "        # Collect local weights\n",
    "        local_weights.append(local_model.get_weights())\n",
    "\n",
    "    # Perform Federated Averaging\n",
    "    averaged_weights = [np.mean(layer_weights, axis=0) for layer_weights in zip(*local_weights)]\n",
    "\n",
    "    return averaged_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db4018ee-6127-43ea-9625-c8c53b0962e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import clone_model\n",
    "import numpy as np\n",
    "\n",
    "def federated_training_round(global_model, client_ids=CLIENT_IDS, batch_size=BATCH_SIZE, epochs=EPOCHS_PER_ROUND):\n",
    "    \"\"\"\n",
    "    Perform one round of federated training by training the global model locally\n",
    "    on each client and averaging the weights.\n",
    "\n",
    "    Parameters:\n",
    "    - global_model: Keras Model, the current global model\n",
    "    - client_ids: list of str, client identifiers\n",
    "    - batch_size: int, batch size for local training\n",
    "    - epochs: int, number of local epochs per client\n",
    "\n",
    "    Returns:\n",
    "    - averaged_weights: list of numpy arrays, the federated-averaged weights\n",
    "    \"\"\"\n",
    "    local_weights = []\n",
    "\n",
    "    for client_id in client_ids:\n",
    "        print(f\"Training on {client_id}...\")\n",
    "\n",
    "        # Load & preprocess client data\n",
    "        X_client, _, _ = load_and_preprocess_client_data(client_id)\n",
    "\n",
    "        # Clone the global model for local training\n",
    "        local_model = clone_model(global_model)\n",
    "        local_model.set_weights(global_model.get_weights())\n",
    "        local_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        # Train the local model\n",
    "        local_model.fit(X_client, X_client, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "\n",
    "        # Collect local weights\n",
    "        local_weights.append(local_model.get_weights())\n",
    "\n",
    "    # Perform Federated Averaging\n",
    "    averaged_weights = [np.mean(layer_weights, axis=0) for layer_weights in zip(*local_weights)]\n",
    "\n",
    "    return averaged_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c050b378-7c6f-427a-ba41-09ef9e776175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import clone_model\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def run_federated_training(input_dim, num_rounds, save_name, client_ids=CLIENT_IDS):\n",
    "    \"\"\"\n",
    "    Perform federated training over multiple rounds on all clients.\n",
    "\n",
    "    Parameters:\n",
    "    - input_dim: int, number of features for input\n",
    "    - num_rounds: int, total number of federated training rounds\n",
    "    - save_name: str, filename for saving the global model\n",
    "    - client_ids: list of str, identifiers of clients\n",
    "\n",
    "    Returns:\n",
    "    - model_save_path: str, path where the global model is saved\n",
    "    - global_model: trained Keras model after federated training\n",
    "    - scaler_client1: scaler fitted on client_1's data (first round)\n",
    "    \"\"\"\n",
    "    # Initialize global model\n",
    "    global_model = build_autoencoder(input_dim)\n",
    "    scaler_client1 = None\n",
    "\n",
    "    for round_num in range(1, num_rounds + 1):\n",
    "        print(f\"\\n--- Federated Round {round_num}/{num_rounds} ---\")\n",
    "        local_weights = []\n",
    "\n",
    "        for client_id in client_ids:\n",
    "            print(f\"Training on {client_id}...\")\n",
    "\n",
    "            # Load & preprocess client data\n",
    "            X_client, scaler, _ = load_and_preprocess_client_data(client_id)\n",
    "\n",
    "            # Save the scaler for client_1 (first round) for later use\n",
    "            if client_id == \"client_1\" and round_num == 1:\n",
    "                scaler_client1 = scaler\n",
    "\n",
    "            # Clone global model for local training\n",
    "            local_model = clone_model(global_model)\n",
    "            local_model.set_weights(global_model.get_weights())\n",
    "            local_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "            # Train locally\n",
    "            local_model.fit(X_client, X_client, epochs=EPOCHS_PER_ROUND,\n",
    "                            batch_size=BATCH_SIZE, verbose=0)\n",
    "\n",
    "            # Collect local weights\n",
    "            local_weights.append(local_model.get_weights())\n",
    "\n",
    "        # Federated Averaging\n",
    "        averaged_weights = [np.mean(weights, axis=0) for weights in zip(*local_weights)]\n",
    "        global_model.set_weights(averaged_weights)\n",
    "\n",
    "        # Save the updated global model after each round\n",
    "        model_save_path = os.path.join(MODEL_DIR, f\"{save_name}.h5\")\n",
    "        global_model.save(model_save_path)\n",
    "        print(f\"Model saved to: {model_save_path}\")\n",
    "\n",
    "    return model_save_path, global_model, scaler_client1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c510f-365e-419a-9739-35e5b99ccac9",
   "metadata": {},
   "source": [
    "### Part 8: One round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf84ed8e-f0d2-47b8-8ee6-777ad0359b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Federated Round 1/1 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_1round.h5\n"
     ]
    }
   ],
   "source": [
    "# Load client_1 data to determine input dimension\n",
    "X_client1, _, feature_names = load_and_preprocess_client_data(\"client_1\")\n",
    "input_dim = X_client1.shape[1]\n",
    "\n",
    "# Run 1 round of federated learning training\n",
    "model_path_1round, model_1round, scaler_client1 = run_federated_training(\n",
    "    input_dim=input_dim,\n",
    "    num_rounds=1,\n",
    "    save_name=\"federated_autoencoder_1round\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dc1a736-a494-4863-b55b-0d844a2216a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_autoencoder(model, X_test_scaled, y_true, thresholds=np.arange(80, 100, 0.1)):\n",
    "    # Compute reconstruction errors\n",
    "    X_reconstructed = model.predict(X_test_scaled, verbose=0)\n",
    "    reconstruction_errors = np.mean(np.square(X_test_scaled - X_reconstructed), axis=1)\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_threshold = None\n",
    "    best_metrics = {}\n",
    "\n",
    "    # Sweep thresholds to find best F1\n",
    "    for thresh in np.percentile(reconstruction_errors, thresholds):\n",
    "        preds = (reconstruction_errors > thresh).astype(int)\n",
    "        f1 = f1_score(y_true, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = thresh\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true, preds).ravel()\n",
    "            best_metrics = {\n",
    "                \"Best Threshold\": best_threshold,\n",
    "                \"Accuracy\": accuracy_score(y_true, preds),\n",
    "                \"Precision\": precision_score(y_true, preds, zero_division=0),\n",
    "                \"Recall\": recall_score(y_true, preds, zero_division=0),\n",
    "                \"F1 Score\": f1,\n",
    "                \"FP\": fp,\n",
    "                \"FN\": fn,\n",
    "                \"FP Rate (%)\": 100 * fp / (fp + tn),\n",
    "                \"FN Rate (%)\": 100 * fn / (fn + tp)\n",
    "            }\n",
    "\n",
    "    return best_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b6713c0-279d-4988-8f0a-7d0ecd7ceb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Thesis Project\\AR_iForest_FL\\Project\\AR_iForest_FL_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Best Threshold': np.float64(1.9747537200311827e+17), 'Accuracy': 0.5972911898772058, 'Precision': 0.17285422304948317, 'Recall': 0.12716867459892472, 'F1 Score': 0.14653309874894696, 'FP': np.int64(367060), 'FN': np.int64(526484), 'FP Rate (%)': np.float64(22.719127926156954), 'FN Rate (%)': np.float64(87.28313254010753)}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the centralized test dataset\n",
    "test_path = os.path.join(BASE_PATH, \"data\", \"processed\", \"surv_unsupervised\", \"test_mixed.csv\")\n",
    "df_test = pd.read_csv(test_path, low_memory=False)\n",
    "\n",
    "X_test = df_test.drop(columns=[\"Attack_label\", \"http.request.method\"], errors=\"ignore\")\n",
    "X_test = X_test.select_dtypes(include=\"number\")\n",
    "\n",
    "# Align test columns with training features\n",
    "X_test = X_test[feature_names]\n",
    "\n",
    "# Scale test data using MinMaxScaler fitted on client_1's data\n",
    "scaler_client1 = MinMaxScaler().fit(X_client1)\n",
    "X_test_scaled = scaler_client1.transform(X_test)\n",
    "\n",
    "# Extract true labels\n",
    "y_true = df_test[\"Attack_label\"].values\n",
    "\n",
    "# Evaluate the federated Autoencoder (1-round model)\n",
    "metrics_1round = evaluate_autoencoder(model_1round, X_test_scaled, y_true)\n",
    "print(metrics_1round)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab81d6-fdeb-4d4a-82e2-920157025894",
   "metadata": {},
   "source": [
    "### Part9: 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0b5d20f-0d94-48cd-a6ba-b7e30c5f380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "def train_and_evaluate_federated_model(num_rounds, save_name):\n",
    "    print(f\"\\n=== Starting Federated Training with {num_rounds} Rounds ===\")\n",
    "\n",
    "    # Train the federated model\n",
    "    model_path, trained_model, _ = run_federated_training(input_dim, num_rounds, save_name)\n",
    "\n",
    "    # Prepare centralized test data\n",
    "    test_path = os.path.join(BASE_PATH, \"data\", \"processed\", \"surv_unsupervised\", \"test_mixed.csv\")\n",
    "    df_test = pd.read_csv(test_path, low_memory=False)\n",
    "\n",
    "    # Drop label and problematic columns, select numeric features\n",
    "    X_test = df_test.drop(columns=[\"Attack_label\", \"http.request.method\"], errors=\"ignore\")\n",
    "    X_test = X_test.select_dtypes(include=\"number\")\n",
    "    X_test = X_test[feature_names]  # Align columns with training data\n",
    "\n",
    "    # Scale test data using client_1's scaler\n",
    "    scaler_client1 = MinMaxScaler().fit(X_client1)\n",
    "    X_test_scaled = scaler_client1.transform(X_test)\n",
    "\n",
    "    # True labels\n",
    "    y_true = df_test[\"Attack_label\"].values\n",
    "\n",
    "    # Evaluate model and measure inference time\n",
    "    start_time = time.time()\n",
    "    metrics = evaluate_autoencoder(trained_model, X_test_scaled, y_true)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Compute model size and per-sample inference time\n",
    "    model_size_mb = os.path.getsize(model_path) / (1024 ** 2)\n",
    "    inference_time = end_time - start_time\n",
    "    inference_time_per_sample = (inference_time / len(X_test_scaled)) * 1000\n",
    "\n",
    "    # Print report\n",
    "    print(f\"\\n=== Final Federated Autoencoder (FedAvg, {num_rounds} Rounds) ===\")\n",
    "    print(f\"Best Threshold: {metrics['Best Threshold']:.6f}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['Precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['Recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['F1 Score']:.4f}\")\n",
    "    print(f\"False Positives: {metrics['FP']} ({metrics['FP Rate (%)']:.2f}%)\")\n",
    "    print(f\"False Negatives: {metrics['FN']} ({metrics['FN Rate (%)']:.2f}%)\")\n",
    "    print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "    print(f\"Inference Time: {inference_time:.2f} seconds\")\n",
    "    print(f\"Inference Time per Sample: {inference_time_per_sample:.6f} ms\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebbba6e7-49af-4bda-8db5-f81f656c18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_and_report(model, model_path, X_test_scaled, y_true):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Compute reconstruction errors\n",
    "    X_reconstructed = model.predict(X_test_scaled, verbose=0)\n",
    "    reconstruction_errors = np.mean(np.square(X_test_scaled - X_reconstructed), axis=1)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Tune threshold for best F1 score\n",
    "    thresholds = np.percentile(reconstruction_errors, np.arange(80, 100, 0.1))\n",
    "    best_f1 = 0\n",
    "    best_metrics = {}\n",
    "    best_threshold = None\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        preds = (reconstruction_errors > thresh).astype(int)\n",
    "        f1 = f1_score(y_true, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = thresh\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true, preds).ravel()\n",
    "            best_metrics = {\n",
    "                \"Best Threshold\": best_threshold,\n",
    "                \"Accuracy\": accuracy_score(y_true, preds),\n",
    "                \"Precision\": precision_score(y_true, preds),\n",
    "                \"Recall\": recall_score(y_true, preds),\n",
    "                \"F1 Score\": f1,\n",
    "                \"FP\": fp,\n",
    "                \"FN\": fn,\n",
    "                \"FP Rate (%)\": 100 * fp / (fp + tn),\n",
    "                \"FN Rate (%)\": 100 * fn / (fn + tp)\n",
    "            }\n",
    "\n",
    "    # Model size and inference timing\n",
    "    model_size_mb = os.path.getsize(model_path) / (1024 ** 2)\n",
    "    total_time = end_time - start_time\n",
    "    per_sample_time = (total_time / len(X_test_scaled)) * 1000\n",
    "\n",
    "    # Print report\n",
    "    print(\"\\n=== Final Federated Autoencoder Evaluation ===\")\n",
    "    print(f\"Best Threshold: {best_metrics['Best Threshold']:.6f}\")\n",
    "    print(f\"Accuracy: {best_metrics['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: {best_metrics['Precision']:.4f}\")\n",
    "    print(f\"Recall: {best_metrics['Recall']:.4f}\")\n",
    "    print(f\"F1 Score: {best_metrics['F1 Score']:.4f}\")\n",
    "    print(f\"False Positives: {best_metrics['FP']} ({best_metrics['FP Rate (%)']:.2f}%)\")\n",
    "    print(f\"False Negatives: {best_metrics['FN']} ({best_metrics['FN Rate (%)']:.2f}%)\")\n",
    "    print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "    print(f\"Inference Time: {total_time:.2f} seconds\")\n",
    "    print(f\"Inference Time per Sample: {per_sample_time:.6f} ms\")\n",
    "\n",
    "    return best_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "652af7f6-7805-415e-a4a2-02f27f261bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Federated Round 1/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_10rounds.h5\n",
      "\n",
      "--- Federated Round 2/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_10rounds.h5\n",
      "\n",
      "--- Federated Round 3/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_10rounds.h5\n",
      "\n",
      "--- Federated Round 4/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_10rounds.h5\n",
      "\n",
      "--- Federated Round 5/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_10rounds.h5\n",
      "\n",
      "--- Federated Round 6/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_10rounds.h5\n",
      "\n",
      "--- Federated Round 7/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_10rounds.h5\n",
      "\n",
      "--- Federated Round 8/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_10rounds.h5\n",
      "\n",
      "--- Federated Round 9/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_10rounds.h5\n",
      "\n",
      "--- Federated Round 10/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_10rounds.h5\n",
      "\n",
      "=== Final Federated Autoencoder Evaluation ===\n",
      "Best Threshold: 0.025937\n",
      "Accuracy: 0.8735\n",
      "Precision: 0.9909\n",
      "Recall: 0.5395\n",
      "F1 Score: 0.6986\n",
      "False Positives: 2992 (0.19%)\n",
      "False Negatives: 277795 (46.05%)\n",
      "Model Size: 0.04 MB\n",
      "Inference Time: 44.96 seconds\n",
      "Inference Time per Sample: 0.020262 ms\n"
     ]
    }
   ],
   "source": [
    "# Train the federated autoencoder for 10 rounds and get the scaler\n",
    "model_path_10, model_10, scaler_client1 = run_federated_training(\n",
    "    input_dim,\n",
    "    num_rounds=10,\n",
    "    save_name=\"federated_autoencoder_10rounds\"\n",
    ")\n",
    "\n",
    "# Prepare centralized test data\n",
    "df_test = pd.read_csv(\n",
    "    os.path.join(BASE_PATH, \"data\", \"processed\", \"surv_unsupervised\", \"test_mixed.csv\"),\n",
    "    low_memory=False\n",
    ")\n",
    "X_test = df_test.drop(columns=[\"Attack_label\", \"http.request.method\"], errors=\"ignore\")\n",
    "X_test = X_test.select_dtypes(include=\"number\")\n",
    "X_test = X_test[feature_names]  # Align columns with training features\n",
    "X_test_scaled = scaler_client1.transform(X_test)\n",
    "y_true = df_test[\"Attack_label\"].values\n",
    "\n",
    "# Evaluate the trained model with a formatted report\n",
    "metrics_10 = evaluate_and_report(model_10, model_path_10, X_test_scaled, y_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693d43b-2e79-4ee7-968d-c2218bf7473a",
   "metadata": {},
   "source": [
    "### Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00ff79a0-d7c3-4049-b753-9e1f2f7569ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "def set_random_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "# === Constants & Paths ===\n",
    "BASE_PATH = \"D:/August-Thesis/FL-IDS-Surveillance\"\n",
    "MODEL_SAVE_PATH = os.path.join(BASE_PATH,\"notebooks\", \"results\",\"models\" ,\"unsupervised\",\"federated\", \"federated_autoencoder_fedavg_rounds.h5\")\n",
    "DATA_DIR = os.path.join(BASE_PATH, \"data\", \"processed\", \"federated\", \"unsupervised\")\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS_PER_ROUND = 1\n",
    "NUM_ROUNDS = 10\n",
    "CLIENT_IDS = [f\"client_{i}\" for i in range(1, 6)]\n",
    "\n",
    "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38c309d2-46db-4f24-99d0-1d3fec179e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(input_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(input_dim, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfed65a2-6664-4470-8f41-72430eac56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_federated_training_old_style(input_dim, num_rounds=NUM_ROUNDS, model_save_path=MODEL_SAVE_PATH):\n",
    "    global_model = build_autoencoder(input_dim)\n",
    "    scaler_client1 = None\n",
    "\n",
    "    for round_num in range(1, num_rounds + 1):\n",
    "        print(f\"\\n--- Federated Round {round_num}/{num_rounds} ---\")\n",
    "        local_weights = []\n",
    "\n",
    "        for client_id in CLIENT_IDS:\n",
    "            print(f\"Training on {client_id}...\")\n",
    "            df = pd.read_csv(os.path.join(DATA_DIR, client_id, \"train.csv\"), low_memory=False)\n",
    "            X = df.drop(columns=[\"Attack_label\", \"http.request.method\"], errors=\"ignore\").select_dtypes(include=\"number\")\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "            if client_id == \"client_1\" and round_num == 1:\n",
    "                scaler_client1 = scaler  # Save client 1's scaler after first round\n",
    "\n",
    "            local_model = clone_model(global_model)\n",
    "            local_model.set_weights(global_model.get_weights())\n",
    "            local_model.compile(optimizer='adam', loss='mse')\n",
    "            local_model.fit(X_scaled, X_scaled, batch_size=BATCH_SIZE, epochs=EPOCHS_PER_ROUND, verbose=0)\n",
    "\n",
    "            local_weights.append(local_model.get_weights())\n",
    "\n",
    "        averaged_weights = [np.mean(w, axis=0) for w in zip(*local_weights)]\n",
    "        global_model.set_weights(averaged_weights)\n",
    "\n",
    "    global_model.save(model_save_path)\n",
    "    print(f\"Model saved to: {model_save_path}\")\n",
    "\n",
    "    return global_model, scaler_client1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "255428b6-f859-4f83-8641-0b1147a2a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "def evaluate_and_report(model, model_path, X_test_scaled, y_true, fixed_threshold=None):\n",
    "    start_time = time.time()\n",
    "    reconstruction_errors = np.mean(np.square(X_test_scaled - model.predict(X_test_scaled)), axis=1)\n",
    "    end_time = time.time()\n",
    "\n",
    "    if fixed_threshold is None:\n",
    "        thresholds = np.percentile(reconstruction_errors, np.arange(80, 100, 0.1))\n",
    "        best_f1 = 0\n",
    "        best_metrics = {}\n",
    "        for thresh in thresholds:\n",
    "            preds = (reconstruction_errors > thresh).astype(int)\n",
    "            f1 = f1_score(y_true, preds)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                tn, fp, fn, tp = confusion_matrix(y_true, preds).ravel()\n",
    "                best_metrics = {\n",
    "                    \"Best Threshold\": thresh,\n",
    "                    \"Accuracy\": accuracy_score(y_true, preds),\n",
    "                    \"Precision\": precision_score(y_true, preds),\n",
    "                    \"Recall\": recall_score(y_true, preds),\n",
    "                    \"F1 Score\": f1,\n",
    "                    \"FP\": fp,\n",
    "                    \"FN\": fn,\n",
    "                    \"FP Rate (%)\": 100 * fp / (fp + tn),\n",
    "                    \"FN Rate (%)\": 100 * fn / (fn + tp)\n",
    "                }\n",
    "    else:\n",
    "        preds = (reconstruction_errors > fixed_threshold).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, preds).ravel()\n",
    "        best_metrics = {\n",
    "            \"Best Threshold\": fixed_threshold,\n",
    "            \"Accuracy\": accuracy_score(y_true, preds),\n",
    "            \"Precision\": precision_score(y_true, preds),\n",
    "            \"Recall\": recall_score(y_true, preds),\n",
    "            \"F1 Score\": f1_score(y_true, preds),\n",
    "            \"FP\": fp,\n",
    "            \"FN\": fn,\n",
    "            \"FP Rate (%)\": 100 * fp / (fp + tn),\n",
    "            \"FN Rate (%)\": 100 * fn / (fn + tp)\n",
    "        }\n",
    "\n",
    "    model_size_mb = os.path.getsize(model_path) / (1024 ** 2)\n",
    "    total_time = end_time - start_time\n",
    "    per_sample_time = (total_time / len(X_test_scaled)) * 1000\n",
    "\n",
    "    print(\"\\n=== Final Federated Autoencoder Evaluation ===\")\n",
    "    for k, v in best_metrics.items():\n",
    "        if isinstance(v, float):\n",
    "            print(f\"{k}: {v:.6f}\" if \"Threshold\" in k else f\"{k}: {v:.4f}\")\n",
    "        else:\n",
    "            print(f\"{k}: {v}\")\n",
    "    print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "    print(f\"Inference Time: {total_time:.2f} seconds\")\n",
    "    print(f\"Inference Time per Sample: {per_sample_time:.6f} ms\")\n",
    "\n",
    "    return best_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae432009-237d-48f1-81f7-0aba3d5b97bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Thesis Project\\AR_iForest_FL\\Project\\AR_iForest_FL_env\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Federated Round 1/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 2/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 3/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 4/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 5/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 6/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 7/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 8/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 9/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 10/10 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_fedavg_rounds.h5\n",
      "\u001b[1m69339/69339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 464us/step\n",
      "\n",
      "=== Final Federated Autoencoder Evaluation ===\n",
      "Best Threshold: 0.000958\n",
      "Accuracy: 0.9039\n",
      "Precision: 0.9394\n",
      "Recall: 0.6911\n",
      "F1 Score: 0.7964\n",
      "FP: 26876\n",
      "FN: 186300\n",
      "FP Rate (%): 1.6635\n",
      "FN Rate (%): 30.8857\n",
      "Model Size: 0.04 MB\n",
      "Inference Time: 52.60 seconds\n",
      "Inference Time per Sample: 0.023708 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Best Threshold': np.float64(0.0009578974776206702),\n",
       " 'Accuracy': 0.9039243134006419,\n",
       " 'Precision': 0.9394366863691983,\n",
       " 'Recall': 0.6911426065707214,\n",
       " 'F1 Score': 0.7963853373296732,\n",
       " 'FP': np.int64(26876),\n",
       " 'FN': np.int64(186300),\n",
       " 'FP Rate (%)': np.float64(1.6634863023576372),\n",
       " 'FN Rate (%)': np.float64(30.885739342927863)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get input_dim from client_1 (once at start)\n",
    "df_sample = pd.read_csv(os.path.join(DATA_DIR, \"client_1\", \"train.csv\"), low_memory=False)\n",
    "X_sample = df_sample.drop(columns=[\"Attack_label\", \"http.request.method\"], errors=\"ignore\").select_dtypes(include=\"number\")\n",
    "input_dim = X_sample.shape[1]\n",
    "\n",
    "# Train Model & Get Client 1 Scaler\n",
    "trained_model, scaler_client1 = run_federated_training_old_style(input_dim, num_rounds=10)\n",
    "\n",
    "# Prepare Test Data using Client 1 Scaler\n",
    "df_test = pd.read_csv(os.path.join(BASE_PATH, \"data\", \"processed\", \"surv_unsupervised\", \"test_mixed.csv\"), low_memory=False)\n",
    "X_test = df_test.drop(columns=[\"Attack_label\", \"http.request.method\"], errors=\"ignore\").select_dtypes(include=\"number\")\n",
    "X_test = X_test[X_sample.columns]  # Ensure column alignment\n",
    "X_test_scaled = scaler_client1.transform(X_test)\n",
    "y_true = df_test[\"Attack_label\"].values\n",
    "\n",
    "# Evaluate & Print Report\n",
    "evaluate_and_report(trained_model, MODEL_SAVE_PATH, X_test_scaled, y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61463b4a-787f-40ff-b5a0-f788ebfb5d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Thesis Project\\AR_iForest_FL\\Project\\AR_iForest_FL_env\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Federated Round 1/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 2/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 3/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 4/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 5/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 6/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 7/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 8/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 9/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 10/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 11/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 12/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 13/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 14/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 15/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 16/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 17/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 18/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 19/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n",
      "\n",
      "--- Federated Round 20/20 ---\n",
      "Training on client_1...\n",
      "Training on client_2...\n",
      "Training on client_3...\n",
      "Training on client_4...\n",
      "Training on client_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:/August-Thesis/FL-IDS-Surveillance\\notebooks\\results\\models\\unsupervised\\federated\\federated_autoencoder_fedavg_rounds.h5\n",
      "\u001b[1m69339/69339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 442us/step\n",
      "\n",
      "=== Final Federated Autoencoder Evaluation ===\n",
      "Best Threshold: 0.000639\n",
      "Accuracy: 0.9232\n",
      "Precision: 0.9877\n",
      "Recall: 0.7267\n",
      "F1 Score: 0.8373\n",
      "FP: 5453\n",
      "FN: 164877\n",
      "FP Rate (%): 0.3375\n",
      "FN Rate (%): 27.3341\n",
      "Model Size: 0.04 MB\n",
      "Inference Time: 43.92 seconds\n",
      "Inference Time per Sample: 0.019794 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Best Threshold': np.float64(0.0006388418611237216),\n",
       " 'Accuracy': 0.9232344555744143,\n",
       " 'Precision': 0.987712020046556,\n",
       " 'Recall': 0.7266587200405842,\n",
       " 'F1 Score': 0.8373096150943973,\n",
       " 'FP': np.int64(5453),\n",
       " 'FN': np.int64(164877),\n",
       " 'FP Rate (%)': np.float64(0.3375126807097855),\n",
       " 'FN Rate (%)': np.float64(27.334127995941586)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model for 20 Rounds & Get Scaler\n",
    "trained_model_20, scaler_client1_20 = run_federated_training_old_style(input_dim, num_rounds=20)\n",
    "\n",
    "#Prepare Test Data using Client 1 Scaler\n",
    "df_test = pd.read_csv(os.path.join(BASE_PATH, \"data\", \"processed\", \"surv_unsupervised\", \"test_mixed.csv\"), low_memory=False)\n",
    "X_test = df_test.drop(columns=[\"Attack_label\", \"http.request.method\"], errors=\"ignore\").select_dtypes(include=\"number\")\n",
    "X_test = X_test[X_sample.columns]  \n",
    "X_test_scaled_20 = scaler_client1_20.transform(X_test)\n",
    "y_true_20 = df_test[\"Attack_label\"].values\n",
    "\n",
    "# Evaluate & Print Report\n",
    "evaluate_and_report(trained_model_20, MODEL_SAVE_PATH, X_test_scaled_20, y_true_20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AR-iForest)",
   "language": "python",
   "name": "ar_iforest_fl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
